## 计算图优化    

例如LayerNorm本身为一个算子，但是ONNX导出会拆分为很多细小的算子，则必须用图优化将其合并回去。又比如ONNX不支持NHWC等数据格式，但是硬件部署往往又需要转换到硬件优化的NHWC或其他数据格式。另外，根据引擎和芯片的特殊性，往往也需要对模型进行一些针对性修改优化，例如一些引擎不支持超过5D的transpose计算。    

## 如何做图优化？  
* 第一个阶段在线优化，是直接对代码（网络的forward）进行修改，从而导出的模型直接具有优化后的特性。对于一些算法依赖，通用性并不是很强，或者底层实施图优化困难的优化可以考虑该方法。     
* 第二个阶段离线优化，是对导出的模型进行优化，例如对导出的ONNX模型进行优化。第三个阶段是在深度学习引擎内部运行时进行优化，可以结合硬件特点和输入shape对应的性能信息进行更加针对性和极致的优化。     


