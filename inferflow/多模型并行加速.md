

https://github.com/triton-inference-server/model_analyzer/blob/main/qa/L0_multi_model_profile/test.sh

https://docs.nvidia.com/deeplearning/triton-inference-server/archives/tensorrt_inference_server_090_beta/tensorrt-inference-server-guide/docs/architecture.html
