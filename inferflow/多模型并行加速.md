

https://github.com/triton-inference-server/model_analyzer/blob/main/qa/L0_multi_model_profile/test.sh

https://docs.nvidia.com/deeplearning/triton-inference-server/archives/tensorrt_inference_server_090_beta/tensorrt-inference-server-guide/docs/architecture.html


3 模型单线程（3 stream）串行推理 

3 模型3线程（3 stream）并行推理   





