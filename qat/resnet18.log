&&&& RUNNING TensorRT.trtexec [TensorRT v8510] # trtexec --onnx=.//qat_resnet18_quant_after_calib.onnx --verbose --best --dumpProfile --separateProfileRun --saveEngine=qat_resnet18_quant_after_calib_x86_best.plan --dumpOutput --exportOutput=qat_resnet18_quant_after_calib.json --dumpLayerInfo --exportProfile=qat_resnet18_quant_after_calib_layinfo.json --noDataTransfers --useCudaGraph --useSpinWait --profilingVerbosity=detailed
[08/20/2024-19:31:00] [I] === Model Options ===
[08/20/2024-19:31:00] [I] Format: ONNX
[08/20/2024-19:31:00] [I] Model: .//qat_resnet18_quant_after_calib.onnx
[08/20/2024-19:31:00] [I] Output:
[08/20/2024-19:31:00] [I] === Build Options ===
[08/20/2024-19:31:00] [I] Max batch: explicit batch
[08/20/2024-19:31:00] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default
[08/20/2024-19:31:00] [I] minTiming: 1
[08/20/2024-19:31:00] [I] avgTiming: 8
[08/20/2024-19:31:00] [I] Precision: FP32+FP16+INT8
[08/20/2024-19:31:00] [I] LayerPrecisions: 
[08/20/2024-19:31:00] [I] Layer Device Types: 
[08/20/2024-19:31:00] [I] Calibration: Dynamic
[08/20/2024-19:31:00] [I] Refit: Disabled
[08/20/2024-19:31:00] [I] Sparsity: Disabled
[08/20/2024-19:31:00] [I] Safe mode: Disabled
[08/20/2024-19:31:00] [I] DirectIO mode: Disabled
[08/20/2024-19:31:00] [I] Restricted mode: Disabled
[08/20/2024-19:31:00] [I] Build only: Disabled
[08/20/2024-19:31:00] [I] Save engine: qat_resnet18_quant_after_calib_x86_best.plan
[08/20/2024-19:31:00] [I] Load engine: 
[08/20/2024-19:31:00] [I] Profiling verbosity: 2
[08/20/2024-19:31:00] [I] Tactic sources: Using default tactic sources
[08/20/2024-19:31:00] [I] timingCacheMode: local
[08/20/2024-19:31:00] [I] timingCacheFile: 
[08/20/2024-19:31:00] [I] Heuristic: Disabled
[08/20/2024-19:31:00] [I] Preview Features: Use default preview flags.
[08/20/2024-19:31:00] [I] Input(s)s format: fp32:CHW
[08/20/2024-19:31:00] [I] Output(s)s format: fp32:CHW
[08/20/2024-19:31:00] [I] Input build shapes: model
[08/20/2024-19:31:00] [I] Input calibration shapes: model
[08/20/2024-19:31:00] [I] === System Options ===
[08/20/2024-19:31:00] [I] Device: 0
[08/20/2024-19:31:00] [I] DLACore: 
[08/20/2024-19:31:00] [I] Plugins:
[08/20/2024-19:31:00] [I] === Inference Options ===
[08/20/2024-19:31:00] [I] Batch: Explicit
[08/20/2024-19:31:00] [I] Input inference shapes: model
[08/20/2024-19:31:00] [I] Iterations: 10
[08/20/2024-19:31:00] [I] Duration: 3s (+ 200ms warm up)
[08/20/2024-19:31:00] [I] Sleep time: 0ms
[08/20/2024-19:31:00] [I] Idle time: 0ms
[08/20/2024-19:31:00] [I] Streams: 1
[08/20/2024-19:31:00] [I] ExposeDMA: Disabled
[08/20/2024-19:31:00] [I] Data transfers: Disabled
[08/20/2024-19:31:00] [I] Spin-wait: Enabled
[08/20/2024-19:31:00] [I] Multithreading: Disabled
[08/20/2024-19:31:00] [I] CUDA Graph: Enabled
[08/20/2024-19:31:00] [I] Separate profiling: Enabled
[08/20/2024-19:31:00] [I] Time Deserialize: Disabled
[08/20/2024-19:31:00] [I] Time Refit: Disabled
[08/20/2024-19:31:00] [I] NVTX verbosity: 2
[08/20/2024-19:31:00] [I] Persistent Cache Ratio: 0
[08/20/2024-19:31:00] [I] Inputs:
[08/20/2024-19:31:00] [I] === Reporting Options ===
[08/20/2024-19:31:00] [I] Verbose: Enabled
[08/20/2024-19:31:00] [I] Averages: 10 inferences
[08/20/2024-19:31:00] [I] Percentiles: 90,95,99
[08/20/2024-19:31:00] [I] Dump refittable layers:Disabled
[08/20/2024-19:31:00] [I] Dump output: Enabled
[08/20/2024-19:31:00] [I] Profile: Enabled
[08/20/2024-19:31:00] [I] Export timing to JSON file: 
[08/20/2024-19:31:00] [I] Export output to JSON file: qat_resnet18_quant_after_calib.json
[08/20/2024-19:31:00] [I] Export profile to JSON file: qat_resnet18_quant_after_calib_layinfo.json
[08/20/2024-19:31:00] [I] 
[08/20/2024-19:31:01] [I] === Device Information ===
[08/20/2024-19:31:01] [I] Selected Device: NVIDIA RTX 2000 Ada Generation Laptop GPU
[08/20/2024-19:31:01] [I] Compute Capability: 8.9
[08/20/2024-19:31:01] [I] SMs: 24
[08/20/2024-19:31:01] [I] Compute Clock Rate: 2.115 GHz
[08/20/2024-19:31:01] [I] Device Global Memory: 8187 MiB
[08/20/2024-19:31:01] [I] Shared Memory per SM: 100 KiB
[08/20/2024-19:31:01] [I] Memory Bus Width: 128 bits (ECC disabled)
[08/20/2024-19:31:01] [I] Memory Clock Rate: 8.001 GHz
[08/20/2024-19:31:01] [I] 
[08/20/2024-19:31:01] [I] TensorRT version: 8.5.10
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::BatchTilePlugin_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::CoordConvAC version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::CropAndResizeDynamic version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::CropAndResize version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::DecodeBbox3DPlugin version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::EfficientNMS_Explicit_TF_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::EfficientNMS_Implicit_TF_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::GenerateDetection_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 2
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::MultilevelCropAndResize_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::MultilevelProposeROI_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::MultiscaleDeformableAttnPlugin_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::NMSDynamic_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::PillarScatterPlugin version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::ProposalDynamic version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::Proposal version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::Region_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::ROIAlign_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::ScatterND version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::Split version 1
[08/20/2024-19:31:01] [V] [TRT] Registered plugin creator - ::VoxelGeneratorPlugin version 1
[08/20/2024-19:31:10] [I] [TRT] [MemUsageChange] Init CUDA: CPU +653, GPU +0, now: CPU 667, GPU 1216 (MiB)
[08/20/2024-19:31:10] [V] [TRT] Trying to load shared library libnvinfer_builder_resource.so.8.5.10
[08/20/2024-19:31:10] [V] [TRT] Loaded shared library libnvinfer_builder_resource.so.8.5.10
[08/20/2024-19:31:28] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +476, GPU +116, now: CPU 1170, GPU 1332 (MiB)
[08/20/2024-19:31:28] [I] Start parsing network model
[08/20/2024-19:31:29] [I] [TRT] ----------------------------------------------------------------
[08/20/2024-19:31:29] [I] [TRT] Input filename:   .//qat_resnet18_quant_after_calib.onnx
[08/20/2024-19:31:29] [I] [TRT] ONNX IR version:  0.0.7
[08/20/2024-19:31:29] [I] [TRT] Opset version:    13
[08/20/2024-19:31:29] [I] [TRT] Producer name:    pytorch
[08/20/2024-19:31:29] [I] [TRT] Producer version: 1.10
[08/20/2024-19:31:29] [I] [TRT] Domain:           
[08/20/2024-19:31:29] [I] [TRT] Model version:    0
[08/20/2024-19:31:29] [I] [TRT] Doc string:       
[08/20/2024-19:31:29] [I] [TRT] ----------------------------------------------------------------
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::BatchTilePlugin_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::Clip_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::CoordConvAC version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::CropAndResizeDynamic version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::DecodeBbox3DPlugin version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Explicit_TF_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Implicit_TF_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::GenerateDetection_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 2
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::MultilevelCropAndResize_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::MultilevelProposeROI_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::MultiscaleDeformableAttnPlugin_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::NMSDynamic_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::PillarScatterPlugin version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::ProposalDynamic version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::Proposal version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::ROIAlign_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::ScatterND version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::Split version 1
[08/20/2024-19:31:29] [V] [TRT] Plugin creator already registered - ::VoxelGeneratorPlugin version 1
[08/20/2024-19:31:29] [V] [TRT] Adding network input: inputs.1 with dtype: float32, dimensions: (1, 3, 224, 224)
[08/20/2024-19:31:29] [V] [TRT] Registering tensor: inputs.1 for ONNX tensor: inputs.1
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: conv1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: bn1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: bn1.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: bn1.running_mean
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: bn1.running_var
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer1.0.conv1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer1.0.bn1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer1.0.bn1.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer1.0.bn1.running_mean
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer1.0.bn1.running_var
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer1.0.conv2.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer1.0.bn2.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer1.0.bn2.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer1.0.bn2.running_mean
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer1.0.bn2.running_var
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer1.1.conv1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer1.1.bn1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer1.1.bn1.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer1.1.bn1.running_mean
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer1.1.bn1.running_var
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer1.1.conv2.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer1.1.bn2.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer1.1.bn2.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer1.1.bn2.running_mean
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer1.1.bn2.running_var
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.0.conv1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.0.bn1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.0.bn1.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.0.bn1.running_mean
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.0.bn1.running_var
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.0.conv2.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.0.bn2.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.0.bn2.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.0.bn2.running_mean
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.0.bn2.running_var
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.0.downsample.0.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.0.downsample.1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.0.downsample.1.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.0.downsample.1.running_mean
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.0.downsample.1.running_var
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.1.conv1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.1.bn1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.1.bn1.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.1.bn1.running_mean
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.1.bn1.running_var
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.1.conv2.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.1.bn2.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.1.bn2.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.1.bn2.running_mean
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer2.1.bn2.running_var
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.0.conv1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.0.bn1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.0.bn1.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.0.bn1.running_mean
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.0.bn1.running_var
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.0.conv2.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.0.bn2.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.0.bn2.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.0.bn2.running_mean
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.0.bn2.running_var
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.0.downsample.0.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.0.downsample.1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.0.downsample.1.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.0.downsample.1.running_mean
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.0.downsample.1.running_var
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.1.conv1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.1.bn1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.1.bn1.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.1.bn1.running_mean
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.1.bn1.running_var
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.1.conv2.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.1.bn2.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.1.bn2.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.1.bn2.running_mean
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer3.1.bn2.running_var
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.0.conv1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.0.bn1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.0.bn1.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.0.bn1.running_mean
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.0.bn1.running_var
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.0.conv2.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.0.bn2.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.0.bn2.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.0.bn2.running_mean
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.0.bn2.running_var
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.0.downsample.0.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.0.downsample.1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.0.downsample.1.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.0.downsample.1.running_mean
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.0.downsample.1.running_var
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.1.conv1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.1.bn1.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.1.bn1.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.1.bn1.running_mean
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.1.bn1.running_var
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.1.conv2.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.1.bn2.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.1.bn2.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.1.bn2.running_mean
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: layer4.1.bn2.running_var
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: fc.weight
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: fc.bias
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 529
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 530
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 531
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 532
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 533
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 534
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 535
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 536
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 537
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 538
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 539
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 540
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 541
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 542
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 543
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 544
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 545
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 546
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 547
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 548
[08/20/2024-19:31:29] [V] [TRT] Importing initializer: 549
[08/20/2024-19:31:29] [V] [TRT] Parsing node: Constant_0 [Constant]
[08/20/2024-19:31:29] [V] [TRT] Constant_0 [Constant] inputs: 
[08/20/2024-19:31:29] [V] [TRT] Constant_0 [Constant] outputs: [174 -> ()[FLOAT]], 
[08/20/2024-19:31:29] [V] [TRT] Parsing node: Constant_1 [Constant]
[08/20/2024-19:31:29] [V] [TRT] Constant_1 [Constant] inputs: 
[08/20/2024-19:31:29] [V] [TRT] Constant_1 [Constant] outputs: [175 -> ()[INT8]], 
[08/20/2024-19:31:29] [V] [TRT] Parsing node: QuantizeLinear_2 [QuantizeLinear]
[08/20/2024-19:31:29] [V] [TRT] Searching for input: inputs.1
[08/20/2024-19:31:29] [V] [TRT] Searching for input: 174
[08/20/2024-19:31:29] [V] [TRT] Searching for input: 175
[08/20/2024-19:31:29] [V] [TRT] QuantizeLinear_2 [QuantizeLinear] inputs: [inputs.1 -> (1, 3, 224, 224)[FLOAT]], [174 -> ()[FLOAT]], [175 -> ()[INT8]], 
[08/20/2024-19:31:29] [V] [TRT] Registering layer: 174 for ONNX node: 174
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 175 for ONNX node: 175
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 176 for ONNX tensor: 176
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_2 [QuantizeLinear] outputs: [176 -> (1, 3, 224, 224)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_3 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_3 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_3 [Constant] outputs: [177 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_4 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_4 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_4 [Constant] outputs: [178 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_5 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 176
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 177
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 178
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_5 [DequantizeLinear] inputs: [176 -> (1, 3, 224, 224)[FLOAT]], [177 -> ()[FLOAT]], [178 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 177 for ONNX node: 177
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 178 for ONNX node: 178
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 179 for ONNX tensor: 179
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_5 [DequantizeLinear] outputs: [179 -> (1, 3, 224, 224)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_6 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_6 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_6 [Constant] outputs: [180 -> (64)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_7 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: conv1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 180
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 529
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_7 [QuantizeLinear] inputs: [conv1.weight -> (64, 3, 7, 7)[FLOAT]], [180 -> (64)[FLOAT]], [529 -> (64)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: conv1.weight for ONNX node: conv1.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 180 for ONNX node: 180
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 529 for ONNX node: 529
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 183 for ONNX tensor: 183
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_7 [QuantizeLinear] outputs: [183 -> (64, 3, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_8 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 183
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 180
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 529
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_8 [DequantizeLinear] inputs: [183 -> (64, 3, 7, 7)[FLOAT]], [180 -> (64)[FLOAT]], [529 -> (64)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 184 for ONNX tensor: 184
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_8 [DequantizeLinear] outputs: [184 -> (64, 3, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Conv_9 [Conv]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 179
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 184
[08/20/2024-19:31:30] [V] [TRT] Conv_9 [Conv] inputs: [179 -> (1, 3, 224, 224)[FLOAT]], [184 -> (64, 3, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Conv_9 for ONNX node: Conv_9
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 185 for ONNX tensor: 185
[08/20/2024-19:31:30] [V] [TRT] Conv_9 [Conv] outputs: [185 -> (1, 64, 112, 112)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: BatchNormalization_10 [BatchNormalization]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 185
[08/20/2024-19:31:30] [V] [TRT] Searching for input: bn1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: bn1.bias
[08/20/2024-19:31:30] [V] [TRT] Searching for input: bn1.running_mean
[08/20/2024-19:31:30] [V] [TRT] Searching for input: bn1.running_var
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_10 [BatchNormalization] inputs: [185 -> (1, 64, 112, 112)[FLOAT]], [bn1.weight -> (64)[FLOAT]], [bn1.bias -> (64)[FLOAT]], [bn1.running_mean -> (64)[FLOAT]], [bn1.running_var -> (64)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: BatchNormalization_10 for ONNX node: BatchNormalization_10
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 186 for ONNX tensor: 186
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_10 [BatchNormalization] outputs: [186 -> (1, 64, 112, 112)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Relu_11 [Relu]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 186
[08/20/2024-19:31:30] [V] [TRT] Relu_11 [Relu] inputs: [186 -> (1, 64, 112, 112)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Relu_11 for ONNX node: Relu_11
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 187 for ONNX tensor: 187
[08/20/2024-19:31:30] [V] [TRT] Relu_11 [Relu] outputs: [187 -> (1, 64, 112, 112)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: MaxPool_12 [MaxPool]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 187
[08/20/2024-19:31:30] [V] [TRT] MaxPool_12 [MaxPool] inputs: [187 -> (1, 64, 112, 112)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: MaxPool_12 for ONNX node: MaxPool_12
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 188 for ONNX tensor: 188
[08/20/2024-19:31:30] [V] [TRT] MaxPool_12 [MaxPool] outputs: [188 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_13 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_13 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_13 [Constant] outputs: [189 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_14 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_14 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_14 [Constant] outputs: [190 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_15 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 188
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 189
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 190
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_15 [QuantizeLinear] inputs: [188 -> (1, 64, 56, 56)[FLOAT]], [189 -> ()[FLOAT]], [190 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 189 for ONNX node: 189
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 190 for ONNX node: 190
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 191 for ONNX tensor: 191
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_15 [QuantizeLinear] outputs: [191 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_16 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_16 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_16 [Constant] outputs: [192 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_17 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_17 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_17 [Constant] outputs: [193 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_18 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 191
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 192
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 193
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_18 [DequantizeLinear] inputs: [191 -> (1, 64, 56, 56)[FLOAT]], [192 -> ()[FLOAT]], [193 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 192 for ONNX node: 192
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 193 for ONNX node: 193
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 194 for ONNX tensor: 194
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_18 [DequantizeLinear] outputs: [194 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_19 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_19 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_19 [Constant] outputs: [195 -> (64)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_20 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer1.0.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 195
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 530
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_20 [QuantizeLinear] inputs: [layer1.0.conv1.weight -> (64, 64, 3, 3)[FLOAT]], [195 -> (64)[FLOAT]], [530 -> (64)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: layer1.0.conv1.weight for ONNX node: layer1.0.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 195 for ONNX node: 195
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 530 for ONNX node: 530
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 198 for ONNX tensor: 198
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_20 [QuantizeLinear] outputs: [198 -> (64, 64, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_21 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 198
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 195
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 530
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_21 [DequantizeLinear] inputs: [198 -> (64, 64, 3, 3)[FLOAT]], [195 -> (64)[FLOAT]], [530 -> (64)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 199 for ONNX tensor: 199
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_21 [DequantizeLinear] outputs: [199 -> (64, 64, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Conv_22 [Conv]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 194
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 199
[08/20/2024-19:31:30] [V] [TRT] Conv_22 [Conv] inputs: [194 -> (1, 64, 56, 56)[FLOAT]], [199 -> (64, 64, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Conv_22 for ONNX node: Conv_22
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 200 for ONNX tensor: 200
[08/20/2024-19:31:30] [V] [TRT] Conv_22 [Conv] outputs: [200 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: BatchNormalization_23 [BatchNormalization]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 200
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer1.0.bn1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer1.0.bn1.bias
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer1.0.bn1.running_mean
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer1.0.bn1.running_var
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_23 [BatchNormalization] inputs: [200 -> (1, 64, 56, 56)[FLOAT]], [layer1.0.bn1.weight -> (64)[FLOAT]], [layer1.0.bn1.bias -> (64)[FLOAT]], [layer1.0.bn1.running_mean -> (64)[FLOAT]], [layer1.0.bn1.running_var -> (64)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: BatchNormalization_23 for ONNX node: BatchNormalization_23
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 201 for ONNX tensor: 201
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_23 [BatchNormalization] outputs: [201 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Relu_24 [Relu]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 201
[08/20/2024-19:31:30] [V] [TRT] Relu_24 [Relu] inputs: [201 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Relu_24 for ONNX node: Relu_24
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 202 for ONNX tensor: 202
[08/20/2024-19:31:30] [V] [TRT] Relu_24 [Relu] outputs: [202 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_25 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_25 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_25 [Constant] outputs: [203 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_26 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_26 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_26 [Constant] outputs: [204 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_27 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 202
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 203
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 204
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_27 [QuantizeLinear] inputs: [202 -> (1, 64, 56, 56)[FLOAT]], [203 -> ()[FLOAT]], [204 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 203 for ONNX node: 203
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 204 for ONNX node: 204
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 205 for ONNX tensor: 205
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_27 [QuantizeLinear] outputs: [205 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_28 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_28 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_28 [Constant] outputs: [206 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_29 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_29 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_29 [Constant] outputs: [207 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_30 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 205
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 206
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 207
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_30 [DequantizeLinear] inputs: [205 -> (1, 64, 56, 56)[FLOAT]], [206 -> ()[FLOAT]], [207 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 206 for ONNX node: 206
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 207 for ONNX node: 207
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 208 for ONNX tensor: 208
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_30 [DequantizeLinear] outputs: [208 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_31 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_31 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_31 [Constant] outputs: [209 -> (64)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_32 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer1.0.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 209
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 531
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_32 [QuantizeLinear] inputs: [layer1.0.conv2.weight -> (64, 64, 3, 3)[FLOAT]], [209 -> (64)[FLOAT]], [531 -> (64)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: layer1.0.conv2.weight for ONNX node: layer1.0.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 209 for ONNX node: 209
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 531 for ONNX node: 531
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 212 for ONNX tensor: 212
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_32 [QuantizeLinear] outputs: [212 -> (64, 64, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_33 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 212
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 209
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 531
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_33 [DequantizeLinear] inputs: [212 -> (64, 64, 3, 3)[FLOAT]], [209 -> (64)[FLOAT]], [531 -> (64)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 213 for ONNX tensor: 213
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_33 [DequantizeLinear] outputs: [213 -> (64, 64, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Conv_34 [Conv]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 208
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 213
[08/20/2024-19:31:30] [V] [TRT] Conv_34 [Conv] inputs: [208 -> (1, 64, 56, 56)[FLOAT]], [213 -> (64, 64, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Conv_34 for ONNX node: Conv_34
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 214 for ONNX tensor: 214
[08/20/2024-19:31:30] [V] [TRT] Conv_34 [Conv] outputs: [214 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: BatchNormalization_35 [BatchNormalization]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 214
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer1.0.bn2.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer1.0.bn2.bias
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer1.0.bn2.running_mean
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer1.0.bn2.running_var
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_35 [BatchNormalization] inputs: [214 -> (1, 64, 56, 56)[FLOAT]], [layer1.0.bn2.weight -> (64)[FLOAT]], [layer1.0.bn2.bias -> (64)[FLOAT]], [layer1.0.bn2.running_mean -> (64)[FLOAT]], [layer1.0.bn2.running_var -> (64)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: BatchNormalization_35 for ONNX node: BatchNormalization_35
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 215 for ONNX tensor: 215
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_35 [BatchNormalization] outputs: [215 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_36 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_36 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_36 [Constant] outputs: [216 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_37 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_37 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_37 [Constant] outputs: [217 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_38 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 188
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 216
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 217
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_38 [QuantizeLinear] inputs: [188 -> (1, 64, 56, 56)[FLOAT]], [216 -> ()[FLOAT]], [217 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 216 for ONNX node: 216
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 217 for ONNX node: 217
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 218 for ONNX tensor: 218
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_38 [QuantizeLinear] outputs: [218 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_39 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_39 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_39 [Constant] outputs: [219 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_40 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_40 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_40 [Constant] outputs: [220 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_41 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 218
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 219
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 220
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_41 [DequantizeLinear] inputs: [218 -> (1, 64, 56, 56)[FLOAT]], [219 -> ()[FLOAT]], [220 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 219 for ONNX node: 219
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 220 for ONNX node: 220
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 221 for ONNX tensor: 221
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_41 [DequantizeLinear] outputs: [221 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Add_42 [Add]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 221
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 215
[08/20/2024-19:31:30] [V] [TRT] Add_42 [Add] inputs: [221 -> (1, 64, 56, 56)[FLOAT]], [215 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Add_42 for ONNX node: Add_42
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 222 for ONNX tensor: 222
[08/20/2024-19:31:30] [V] [TRT] Add_42 [Add] outputs: [222 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Relu_43 [Relu]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 222
[08/20/2024-19:31:30] [V] [TRT] Relu_43 [Relu] inputs: [222 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Relu_43 for ONNX node: Relu_43
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 223 for ONNX tensor: 223
[08/20/2024-19:31:30] [V] [TRT] Relu_43 [Relu] outputs: [223 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_44 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_44 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_44 [Constant] outputs: [224 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_45 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_45 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_45 [Constant] outputs: [225 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_46 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 223
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 224
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 225
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_46 [QuantizeLinear] inputs: [223 -> (1, 64, 56, 56)[FLOAT]], [224 -> ()[FLOAT]], [225 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 224 for ONNX node: 224
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 225 for ONNX node: 225
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 226 for ONNX tensor: 226
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_46 [QuantizeLinear] outputs: [226 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_47 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_47 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_47 [Constant] outputs: [227 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_48 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_48 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_48 [Constant] outputs: [228 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_49 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 226
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 227
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 228
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_49 [DequantizeLinear] inputs: [226 -> (1, 64, 56, 56)[FLOAT]], [227 -> ()[FLOAT]], [228 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 227 for ONNX node: 227
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 228 for ONNX node: 228
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 229 for ONNX tensor: 229
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_49 [DequantizeLinear] outputs: [229 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_50 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_50 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_50 [Constant] outputs: [230 -> (64)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_51 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer1.1.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 230
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 532
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_51 [QuantizeLinear] inputs: [layer1.1.conv1.weight -> (64, 64, 3, 3)[FLOAT]], [230 -> (64)[FLOAT]], [532 -> (64)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: layer1.1.conv1.weight for ONNX node: layer1.1.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 230 for ONNX node: 230
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 532 for ONNX node: 532
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 233 for ONNX tensor: 233
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_51 [QuantizeLinear] outputs: [233 -> (64, 64, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_52 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 233
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 230
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 532
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_52 [DequantizeLinear] inputs: [233 -> (64, 64, 3, 3)[FLOAT]], [230 -> (64)[FLOAT]], [532 -> (64)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 234 for ONNX tensor: 234
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_52 [DequantizeLinear] outputs: [234 -> (64, 64, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Conv_53 [Conv]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 229
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 234
[08/20/2024-19:31:30] [V] [TRT] Conv_53 [Conv] inputs: [229 -> (1, 64, 56, 56)[FLOAT]], [234 -> (64, 64, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Conv_53 for ONNX node: Conv_53
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 235 for ONNX tensor: 235
[08/20/2024-19:31:30] [V] [TRT] Conv_53 [Conv] outputs: [235 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: BatchNormalization_54 [BatchNormalization]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 235
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer1.1.bn1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer1.1.bn1.bias
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer1.1.bn1.running_mean
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer1.1.bn1.running_var
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_54 [BatchNormalization] inputs: [235 -> (1, 64, 56, 56)[FLOAT]], [layer1.1.bn1.weight -> (64)[FLOAT]], [layer1.1.bn1.bias -> (64)[FLOAT]], [layer1.1.bn1.running_mean -> (64)[FLOAT]], [layer1.1.bn1.running_var -> (64)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: BatchNormalization_54 for ONNX node: BatchNormalization_54
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 236 for ONNX tensor: 236
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_54 [BatchNormalization] outputs: [236 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Relu_55 [Relu]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 236
[08/20/2024-19:31:30] [V] [TRT] Relu_55 [Relu] inputs: [236 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Relu_55 for ONNX node: Relu_55
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 237 for ONNX tensor: 237
[08/20/2024-19:31:30] [V] [TRT] Relu_55 [Relu] outputs: [237 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_56 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_56 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_56 [Constant] outputs: [238 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_57 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_57 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_57 [Constant] outputs: [239 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_58 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 237
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 238
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 239
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_58 [QuantizeLinear] inputs: [237 -> (1, 64, 56, 56)[FLOAT]], [238 -> ()[FLOAT]], [239 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 238 for ONNX node: 238
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 239 for ONNX node: 239
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 240 for ONNX tensor: 240
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_58 [QuantizeLinear] outputs: [240 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_59 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_59 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_59 [Constant] outputs: [241 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_60 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_60 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_60 [Constant] outputs: [242 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_61 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 240
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 241
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 242
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_61 [DequantizeLinear] inputs: [240 -> (1, 64, 56, 56)[FLOAT]], [241 -> ()[FLOAT]], [242 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 241 for ONNX node: 241
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 242 for ONNX node: 242
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 243 for ONNX tensor: 243
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_61 [DequantizeLinear] outputs: [243 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_62 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_62 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_62 [Constant] outputs: [244 -> (64)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_63 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer1.1.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 244
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 533
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_63 [QuantizeLinear] inputs: [layer1.1.conv2.weight -> (64, 64, 3, 3)[FLOAT]], [244 -> (64)[FLOAT]], [533 -> (64)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: layer1.1.conv2.weight for ONNX node: layer1.1.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 244 for ONNX node: 244
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 533 for ONNX node: 533
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 247 for ONNX tensor: 247
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_63 [QuantizeLinear] outputs: [247 -> (64, 64, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_64 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 247
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 244
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 533
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_64 [DequantizeLinear] inputs: [247 -> (64, 64, 3, 3)[FLOAT]], [244 -> (64)[FLOAT]], [533 -> (64)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 248 for ONNX tensor: 248
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_64 [DequantizeLinear] outputs: [248 -> (64, 64, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Conv_65 [Conv]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 243
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 248
[08/20/2024-19:31:30] [V] [TRT] Conv_65 [Conv] inputs: [243 -> (1, 64, 56, 56)[FLOAT]], [248 -> (64, 64, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Conv_65 for ONNX node: Conv_65
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 249 for ONNX tensor: 249
[08/20/2024-19:31:30] [V] [TRT] Conv_65 [Conv] outputs: [249 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: BatchNormalization_66 [BatchNormalization]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 249
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer1.1.bn2.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer1.1.bn2.bias
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer1.1.bn2.running_mean
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer1.1.bn2.running_var
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_66 [BatchNormalization] inputs: [249 -> (1, 64, 56, 56)[FLOAT]], [layer1.1.bn2.weight -> (64)[FLOAT]], [layer1.1.bn2.bias -> (64)[FLOAT]], [layer1.1.bn2.running_mean -> (64)[FLOAT]], [layer1.1.bn2.running_var -> (64)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: BatchNormalization_66 for ONNX node: BatchNormalization_66
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 250 for ONNX tensor: 250
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_66 [BatchNormalization] outputs: [250 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_67 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_67 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_67 [Constant] outputs: [251 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_68 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_68 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_68 [Constant] outputs: [252 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_69 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 223
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 251
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 252
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_69 [QuantizeLinear] inputs: [223 -> (1, 64, 56, 56)[FLOAT]], [251 -> ()[FLOAT]], [252 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 251 for ONNX node: 251
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 252 for ONNX node: 252
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 253 for ONNX tensor: 253
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_69 [QuantizeLinear] outputs: [253 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_70 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_70 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_70 [Constant] outputs: [254 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_71 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_71 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_71 [Constant] outputs: [255 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_72 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 253
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 254
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 255
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_72 [DequantizeLinear] inputs: [253 -> (1, 64, 56, 56)[FLOAT]], [254 -> ()[FLOAT]], [255 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 254 for ONNX node: 254
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 255 for ONNX node: 255
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 256 for ONNX tensor: 256
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_72 [DequantizeLinear] outputs: [256 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Add_73 [Add]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 256
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 250
[08/20/2024-19:31:30] [V] [TRT] Add_73 [Add] inputs: [256 -> (1, 64, 56, 56)[FLOAT]], [250 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Add_73 for ONNX node: Add_73
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 257 for ONNX tensor: 257
[08/20/2024-19:31:30] [V] [TRT] Add_73 [Add] outputs: [257 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Relu_74 [Relu]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 257
[08/20/2024-19:31:30] [V] [TRT] Relu_74 [Relu] inputs: [257 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Relu_74 for ONNX node: Relu_74
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 258 for ONNX tensor: 258
[08/20/2024-19:31:30] [V] [TRT] Relu_74 [Relu] outputs: [258 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_75 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_75 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_75 [Constant] outputs: [259 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_76 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_76 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_76 [Constant] outputs: [260 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_77 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 258
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 259
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 260
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_77 [QuantizeLinear] inputs: [258 -> (1, 64, 56, 56)[FLOAT]], [259 -> ()[FLOAT]], [260 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 259 for ONNX node: 259
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 260 for ONNX node: 260
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 261 for ONNX tensor: 261
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_77 [QuantizeLinear] outputs: [261 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_78 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_78 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_78 [Constant] outputs: [262 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_79 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_79 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_79 [Constant] outputs: [263 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_80 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 261
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 262
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 263
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_80 [DequantizeLinear] inputs: [261 -> (1, 64, 56, 56)[FLOAT]], [262 -> ()[FLOAT]], [263 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 262 for ONNX node: 262
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 263 for ONNX node: 263
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 264 for ONNX tensor: 264
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_80 [DequantizeLinear] outputs: [264 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_81 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_81 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_81 [Constant] outputs: [265 -> (128)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_82 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.0.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 265
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 534
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_82 [QuantizeLinear] inputs: [layer2.0.conv1.weight -> (128, 64, 3, 3)[FLOAT]], [265 -> (128)[FLOAT]], [534 -> (128)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: layer2.0.conv1.weight for ONNX node: layer2.0.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 265 for ONNX node: 265
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 534 for ONNX node: 534
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 268 for ONNX tensor: 268
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_82 [QuantizeLinear] outputs: [268 -> (128, 64, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_83 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 268
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 265
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 534
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_83 [DequantizeLinear] inputs: [268 -> (128, 64, 3, 3)[FLOAT]], [265 -> (128)[FLOAT]], [534 -> (128)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 269 for ONNX tensor: 269
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_83 [DequantizeLinear] outputs: [269 -> (128, 64, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Conv_84 [Conv]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 264
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 269
[08/20/2024-19:31:30] [V] [TRT] Conv_84 [Conv] inputs: [264 -> (1, 64, 56, 56)[FLOAT]], [269 -> (128, 64, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Conv_84 for ONNX node: Conv_84
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 270 for ONNX tensor: 270
[08/20/2024-19:31:30] [V] [TRT] Conv_84 [Conv] outputs: [270 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: BatchNormalization_85 [BatchNormalization]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 270
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.0.bn1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.0.bn1.bias
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.0.bn1.running_mean
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.0.bn1.running_var
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_85 [BatchNormalization] inputs: [270 -> (1, 128, 28, 28)[FLOAT]], [layer2.0.bn1.weight -> (128)[FLOAT]], [layer2.0.bn1.bias -> (128)[FLOAT]], [layer2.0.bn1.running_mean -> (128)[FLOAT]], [layer2.0.bn1.running_var -> (128)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: BatchNormalization_85 for ONNX node: BatchNormalization_85
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 271 for ONNX tensor: 271
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_85 [BatchNormalization] outputs: [271 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Relu_86 [Relu]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 271
[08/20/2024-19:31:30] [V] [TRT] Relu_86 [Relu] inputs: [271 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Relu_86 for ONNX node: Relu_86
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 272 for ONNX tensor: 272
[08/20/2024-19:31:30] [V] [TRT] Relu_86 [Relu] outputs: [272 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_87 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_87 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_87 [Constant] outputs: [273 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_88 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_88 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_88 [Constant] outputs: [274 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_89 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 272
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 273
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 274
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_89 [QuantizeLinear] inputs: [272 -> (1, 128, 28, 28)[FLOAT]], [273 -> ()[FLOAT]], [274 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 273 for ONNX node: 273
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 274 for ONNX node: 274
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 275 for ONNX tensor: 275
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_89 [QuantizeLinear] outputs: [275 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_90 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_90 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_90 [Constant] outputs: [276 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_91 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_91 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_91 [Constant] outputs: [277 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_92 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 275
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 276
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 277
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_92 [DequantizeLinear] inputs: [275 -> (1, 128, 28, 28)[FLOAT]], [276 -> ()[FLOAT]], [277 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 276 for ONNX node: 276
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 277 for ONNX node: 277
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 278 for ONNX tensor: 278
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_92 [DequantizeLinear] outputs: [278 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_93 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_93 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_93 [Constant] outputs: [279 -> (128)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_94 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.0.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 279
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 535
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_94 [QuantizeLinear] inputs: [layer2.0.conv2.weight -> (128, 128, 3, 3)[FLOAT]], [279 -> (128)[FLOAT]], [535 -> (128)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: layer2.0.conv2.weight for ONNX node: layer2.0.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 279 for ONNX node: 279
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 535 for ONNX node: 535
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 282 for ONNX tensor: 282
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_94 [QuantizeLinear] outputs: [282 -> (128, 128, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_95 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 282
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 279
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 535
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_95 [DequantizeLinear] inputs: [282 -> (128, 128, 3, 3)[FLOAT]], [279 -> (128)[FLOAT]], [535 -> (128)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 283 for ONNX tensor: 283
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_95 [DequantizeLinear] outputs: [283 -> (128, 128, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Conv_96 [Conv]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 278
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 283
[08/20/2024-19:31:30] [V] [TRT] Conv_96 [Conv] inputs: [278 -> (1, 128, 28, 28)[FLOAT]], [283 -> (128, 128, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Conv_96 for ONNX node: Conv_96
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 284 for ONNX tensor: 284
[08/20/2024-19:31:30] [V] [TRT] Conv_96 [Conv] outputs: [284 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: BatchNormalization_97 [BatchNormalization]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 284
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.0.bn2.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.0.bn2.bias
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.0.bn2.running_mean
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.0.bn2.running_var
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_97 [BatchNormalization] inputs: [284 -> (1, 128, 28, 28)[FLOAT]], [layer2.0.bn2.weight -> (128)[FLOAT]], [layer2.0.bn2.bias -> (128)[FLOAT]], [layer2.0.bn2.running_mean -> (128)[FLOAT]], [layer2.0.bn2.running_var -> (128)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: BatchNormalization_97 for ONNX node: BatchNormalization_97
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 285 for ONNX tensor: 285
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_97 [BatchNormalization] outputs: [285 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_98 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_98 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_98 [Constant] outputs: [286 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_99 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_99 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_99 [Constant] outputs: [287 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_100 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 258
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 286
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 287
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_100 [QuantizeLinear] inputs: [258 -> (1, 64, 56, 56)[FLOAT]], [286 -> ()[FLOAT]], [287 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 286 for ONNX node: 286
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 287 for ONNX node: 287
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 288 for ONNX tensor: 288
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_100 [QuantizeLinear] outputs: [288 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_101 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_101 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_101 [Constant] outputs: [289 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_102 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_102 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_102 [Constant] outputs: [290 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_103 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 288
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 289
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 290
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_103 [DequantizeLinear] inputs: [288 -> (1, 64, 56, 56)[FLOAT]], [289 -> ()[FLOAT]], [290 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 289 for ONNX node: 289
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 290 for ONNX node: 290
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 291 for ONNX tensor: 291
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_103 [DequantizeLinear] outputs: [291 -> (1, 64, 56, 56)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_104 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_104 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_104 [Constant] outputs: [292 -> (128)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_105 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.0.downsample.0.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 292
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 536
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_105 [QuantizeLinear] inputs: [layer2.0.downsample.0.weight -> (128, 64, 1, 1)[FLOAT]], [292 -> (128)[FLOAT]], [536 -> (128)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: layer2.0.downsample.0.weight for ONNX node: layer2.0.downsample.0.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 292 for ONNX node: 292
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 536 for ONNX node: 536
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 295 for ONNX tensor: 295
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_105 [QuantizeLinear] outputs: [295 -> (128, 64, 1, 1)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_106 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 295
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 292
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 536
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_106 [DequantizeLinear] inputs: [295 -> (128, 64, 1, 1)[FLOAT]], [292 -> (128)[FLOAT]], [536 -> (128)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 296 for ONNX tensor: 296
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_106 [DequantizeLinear] outputs: [296 -> (128, 64, 1, 1)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Conv_107 [Conv]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 291
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 296
[08/20/2024-19:31:30] [V] [TRT] Conv_107 [Conv] inputs: [291 -> (1, 64, 56, 56)[FLOAT]], [296 -> (128, 64, 1, 1)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Conv_107 for ONNX node: Conv_107
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 297 for ONNX tensor: 297
[08/20/2024-19:31:30] [V] [TRT] Conv_107 [Conv] outputs: [297 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: BatchNormalization_108 [BatchNormalization]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 297
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.0.downsample.1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.0.downsample.1.bias
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.0.downsample.1.running_mean
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.0.downsample.1.running_var
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_108 [BatchNormalization] inputs: [297 -> (1, 128, 28, 28)[FLOAT]], [layer2.0.downsample.1.weight -> (128)[FLOAT]], [layer2.0.downsample.1.bias -> (128)[FLOAT]], [layer2.0.downsample.1.running_mean -> (128)[FLOAT]], [layer2.0.downsample.1.running_var -> (128)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: BatchNormalization_108 for ONNX node: BatchNormalization_108
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 298 for ONNX tensor: 298
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_108 [BatchNormalization] outputs: [298 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_109 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_109 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_109 [Constant] outputs: [299 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_110 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_110 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_110 [Constant] outputs: [300 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_111 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 298
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 299
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 300
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_111 [QuantizeLinear] inputs: [298 -> (1, 128, 28, 28)[FLOAT]], [299 -> ()[FLOAT]], [300 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 299 for ONNX node: 299
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 300 for ONNX node: 300
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 301 for ONNX tensor: 301
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_111 [QuantizeLinear] outputs: [301 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_112 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_112 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_112 [Constant] outputs: [302 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_113 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_113 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_113 [Constant] outputs: [303 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_114 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 301
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 302
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 303
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_114 [DequantizeLinear] inputs: [301 -> (1, 128, 28, 28)[FLOAT]], [302 -> ()[FLOAT]], [303 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 302 for ONNX node: 302
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 303 for ONNX node: 303
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 304 for ONNX tensor: 304
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_114 [DequantizeLinear] outputs: [304 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Add_115 [Add]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 304
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 285
[08/20/2024-19:31:30] [V] [TRT] Add_115 [Add] inputs: [304 -> (1, 128, 28, 28)[FLOAT]], [285 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Add_115 for ONNX node: Add_115
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 305 for ONNX tensor: 305
[08/20/2024-19:31:30] [V] [TRT] Add_115 [Add] outputs: [305 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Relu_116 [Relu]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 305
[08/20/2024-19:31:30] [V] [TRT] Relu_116 [Relu] inputs: [305 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Relu_116 for ONNX node: Relu_116
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 306 for ONNX tensor: 306
[08/20/2024-19:31:30] [V] [TRT] Relu_116 [Relu] outputs: [306 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_117 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_117 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_117 [Constant] outputs: [307 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_118 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_118 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_118 [Constant] outputs: [308 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_119 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 306
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 307
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 308
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_119 [QuantizeLinear] inputs: [306 -> (1, 128, 28, 28)[FLOAT]], [307 -> ()[FLOAT]], [308 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 307 for ONNX node: 307
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 308 for ONNX node: 308
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 309 for ONNX tensor: 309
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_119 [QuantizeLinear] outputs: [309 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_120 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_120 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_120 [Constant] outputs: [310 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_121 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_121 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_121 [Constant] outputs: [311 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_122 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 309
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 310
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 311
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_122 [DequantizeLinear] inputs: [309 -> (1, 128, 28, 28)[FLOAT]], [310 -> ()[FLOAT]], [311 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 310 for ONNX node: 310
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 311 for ONNX node: 311
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 312 for ONNX tensor: 312
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_122 [DequantizeLinear] outputs: [312 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_123 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_123 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_123 [Constant] outputs: [313 -> (128)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_124 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.1.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 313
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 537
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_124 [QuantizeLinear] inputs: [layer2.1.conv1.weight -> (128, 128, 3, 3)[FLOAT]], [313 -> (128)[FLOAT]], [537 -> (128)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: layer2.1.conv1.weight for ONNX node: layer2.1.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 313 for ONNX node: 313
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 537 for ONNX node: 537
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 316 for ONNX tensor: 316
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_124 [QuantizeLinear] outputs: [316 -> (128, 128, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_125 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 316
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 313
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 537
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_125 [DequantizeLinear] inputs: [316 -> (128, 128, 3, 3)[FLOAT]], [313 -> (128)[FLOAT]], [537 -> (128)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 317 for ONNX tensor: 317
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_125 [DequantizeLinear] outputs: [317 -> (128, 128, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Conv_126 [Conv]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 312
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 317
[08/20/2024-19:31:30] [V] [TRT] Conv_126 [Conv] inputs: [312 -> (1, 128, 28, 28)[FLOAT]], [317 -> (128, 128, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Conv_126 for ONNX node: Conv_126
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 318 for ONNX tensor: 318
[08/20/2024-19:31:30] [V] [TRT] Conv_126 [Conv] outputs: [318 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: BatchNormalization_127 [BatchNormalization]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 318
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.1.bn1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.1.bn1.bias
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.1.bn1.running_mean
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.1.bn1.running_var
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_127 [BatchNormalization] inputs: [318 -> (1, 128, 28, 28)[FLOAT]], [layer2.1.bn1.weight -> (128)[FLOAT]], [layer2.1.bn1.bias -> (128)[FLOAT]], [layer2.1.bn1.running_mean -> (128)[FLOAT]], [layer2.1.bn1.running_var -> (128)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: BatchNormalization_127 for ONNX node: BatchNormalization_127
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 319 for ONNX tensor: 319
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_127 [BatchNormalization] outputs: [319 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Relu_128 [Relu]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 319
[08/20/2024-19:31:30] [V] [TRT] Relu_128 [Relu] inputs: [319 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Relu_128 for ONNX node: Relu_128
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 320 for ONNX tensor: 320
[08/20/2024-19:31:30] [V] [TRT] Relu_128 [Relu] outputs: [320 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_129 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_129 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_129 [Constant] outputs: [321 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_130 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_130 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_130 [Constant] outputs: [322 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_131 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 320
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 321
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 322
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_131 [QuantizeLinear] inputs: [320 -> (1, 128, 28, 28)[FLOAT]], [321 -> ()[FLOAT]], [322 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 321 for ONNX node: 321
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 322 for ONNX node: 322
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 323 for ONNX tensor: 323
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_131 [QuantizeLinear] outputs: [323 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_132 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_132 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_132 [Constant] outputs: [324 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_133 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_133 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_133 [Constant] outputs: [325 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_134 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 323
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 324
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 325
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_134 [DequantizeLinear] inputs: [323 -> (1, 128, 28, 28)[FLOAT]], [324 -> ()[FLOAT]], [325 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 324 for ONNX node: 324
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 325 for ONNX node: 325
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 326 for ONNX tensor: 326
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_134 [DequantizeLinear] outputs: [326 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_135 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_135 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_135 [Constant] outputs: [327 -> (128)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_136 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.1.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 327
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 538
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_136 [QuantizeLinear] inputs: [layer2.1.conv2.weight -> (128, 128, 3, 3)[FLOAT]], [327 -> (128)[FLOAT]], [538 -> (128)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: layer2.1.conv2.weight for ONNX node: layer2.1.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 327 for ONNX node: 327
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 538 for ONNX node: 538
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 330 for ONNX tensor: 330
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_136 [QuantizeLinear] outputs: [330 -> (128, 128, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_137 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 330
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 327
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 538
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_137 [DequantizeLinear] inputs: [330 -> (128, 128, 3, 3)[FLOAT]], [327 -> (128)[FLOAT]], [538 -> (128)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 331 for ONNX tensor: 331
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_137 [DequantizeLinear] outputs: [331 -> (128, 128, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Conv_138 [Conv]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 326
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 331
[08/20/2024-19:31:30] [V] [TRT] Conv_138 [Conv] inputs: [326 -> (1, 128, 28, 28)[FLOAT]], [331 -> (128, 128, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Conv_138 for ONNX node: Conv_138
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 332 for ONNX tensor: 332
[08/20/2024-19:31:30] [V] [TRT] Conv_138 [Conv] outputs: [332 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: BatchNormalization_139 [BatchNormalization]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 332
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.1.bn2.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.1.bn2.bias
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.1.bn2.running_mean
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer2.1.bn2.running_var
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_139 [BatchNormalization] inputs: [332 -> (1, 128, 28, 28)[FLOAT]], [layer2.1.bn2.weight -> (128)[FLOAT]], [layer2.1.bn2.bias -> (128)[FLOAT]], [layer2.1.bn2.running_mean -> (128)[FLOAT]], [layer2.1.bn2.running_var -> (128)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: BatchNormalization_139 for ONNX node: BatchNormalization_139
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 333 for ONNX tensor: 333
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_139 [BatchNormalization] outputs: [333 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_140 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_140 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_140 [Constant] outputs: [334 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_141 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_141 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_141 [Constant] outputs: [335 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_142 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 306
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 334
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 335
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_142 [QuantizeLinear] inputs: [306 -> (1, 128, 28, 28)[FLOAT]], [334 -> ()[FLOAT]], [335 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 334 for ONNX node: 334
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 335 for ONNX node: 335
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 336 for ONNX tensor: 336
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_142 [QuantizeLinear] outputs: [336 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_143 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_143 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_143 [Constant] outputs: [337 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_144 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_144 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_144 [Constant] outputs: [338 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_145 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 336
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 337
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 338
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_145 [DequantizeLinear] inputs: [336 -> (1, 128, 28, 28)[FLOAT]], [337 -> ()[FLOAT]], [338 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 337 for ONNX node: 337
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 338 for ONNX node: 338
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 339 for ONNX tensor: 339
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_145 [DequantizeLinear] outputs: [339 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Add_146 [Add]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 339
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 333
[08/20/2024-19:31:30] [V] [TRT] Add_146 [Add] inputs: [339 -> (1, 128, 28, 28)[FLOAT]], [333 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Add_146 for ONNX node: Add_146
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 340 for ONNX tensor: 340
[08/20/2024-19:31:30] [V] [TRT] Add_146 [Add] outputs: [340 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Relu_147 [Relu]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 340
[08/20/2024-19:31:30] [V] [TRT] Relu_147 [Relu] inputs: [340 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Relu_147 for ONNX node: Relu_147
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 341 for ONNX tensor: 341
[08/20/2024-19:31:30] [V] [TRT] Relu_147 [Relu] outputs: [341 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_148 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_148 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_148 [Constant] outputs: [342 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_149 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_149 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_149 [Constant] outputs: [343 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_150 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 341
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 342
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 343
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_150 [QuantizeLinear] inputs: [341 -> (1, 128, 28, 28)[FLOAT]], [342 -> ()[FLOAT]], [343 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 342 for ONNX node: 342
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 343 for ONNX node: 343
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 344 for ONNX tensor: 344
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_150 [QuantizeLinear] outputs: [344 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_151 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_151 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_151 [Constant] outputs: [345 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_152 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_152 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_152 [Constant] outputs: [346 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_153 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 344
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 345
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 346
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_153 [DequantizeLinear] inputs: [344 -> (1, 128, 28, 28)[FLOAT]], [345 -> ()[FLOAT]], [346 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 345 for ONNX node: 345
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 346 for ONNX node: 346
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 347 for ONNX tensor: 347
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_153 [DequantizeLinear] outputs: [347 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_154 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_154 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_154 [Constant] outputs: [348 -> (256)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_155 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.0.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 348
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 539
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_155 [QuantizeLinear] inputs: [layer3.0.conv1.weight -> (256, 128, 3, 3)[FLOAT]], [348 -> (256)[FLOAT]], [539 -> (256)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: layer3.0.conv1.weight for ONNX node: layer3.0.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 348 for ONNX node: 348
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 539 for ONNX node: 539
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 351 for ONNX tensor: 351
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_155 [QuantizeLinear] outputs: [351 -> (256, 128, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_156 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 351
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 348
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 539
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_156 [DequantizeLinear] inputs: [351 -> (256, 128, 3, 3)[FLOAT]], [348 -> (256)[FLOAT]], [539 -> (256)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 352 for ONNX tensor: 352
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_156 [DequantizeLinear] outputs: [352 -> (256, 128, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Conv_157 [Conv]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 347
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 352
[08/20/2024-19:31:30] [V] [TRT] Conv_157 [Conv] inputs: [347 -> (1, 128, 28, 28)[FLOAT]], [352 -> (256, 128, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Conv_157 for ONNX node: Conv_157
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 353 for ONNX tensor: 353
[08/20/2024-19:31:30] [V] [TRT] Conv_157 [Conv] outputs: [353 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: BatchNormalization_158 [BatchNormalization]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 353
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.0.bn1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.0.bn1.bias
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.0.bn1.running_mean
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.0.bn1.running_var
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_158 [BatchNormalization] inputs: [353 -> (1, 256, 14, 14)[FLOAT]], [layer3.0.bn1.weight -> (256)[FLOAT]], [layer3.0.bn1.bias -> (256)[FLOAT]], [layer3.0.bn1.running_mean -> (256)[FLOAT]], [layer3.0.bn1.running_var -> (256)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: BatchNormalization_158 for ONNX node: BatchNormalization_158
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 354 for ONNX tensor: 354
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_158 [BatchNormalization] outputs: [354 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Relu_159 [Relu]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 354
[08/20/2024-19:31:30] [V] [TRT] Relu_159 [Relu] inputs: [354 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Relu_159 for ONNX node: Relu_159
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 355 for ONNX tensor: 355
[08/20/2024-19:31:30] [V] [TRT] Relu_159 [Relu] outputs: [355 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_160 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_160 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_160 [Constant] outputs: [356 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_161 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_161 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_161 [Constant] outputs: [357 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_162 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 355
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 356
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 357
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_162 [QuantizeLinear] inputs: [355 -> (1, 256, 14, 14)[FLOAT]], [356 -> ()[FLOAT]], [357 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 356 for ONNX node: 356
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 357 for ONNX node: 357
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 358 for ONNX tensor: 358
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_162 [QuantizeLinear] outputs: [358 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_163 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_163 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_163 [Constant] outputs: [359 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_164 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_164 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_164 [Constant] outputs: [360 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_165 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 358
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 359
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 360
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_165 [DequantizeLinear] inputs: [358 -> (1, 256, 14, 14)[FLOAT]], [359 -> ()[FLOAT]], [360 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 359 for ONNX node: 359
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 360 for ONNX node: 360
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 361 for ONNX tensor: 361
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_165 [DequantizeLinear] outputs: [361 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_166 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_166 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_166 [Constant] outputs: [362 -> (256)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_167 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.0.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 362
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 540
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_167 [QuantizeLinear] inputs: [layer3.0.conv2.weight -> (256, 256, 3, 3)[FLOAT]], [362 -> (256)[FLOAT]], [540 -> (256)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: layer3.0.conv2.weight for ONNX node: layer3.0.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 362 for ONNX node: 362
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 540 for ONNX node: 540
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 365 for ONNX tensor: 365
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_167 [QuantizeLinear] outputs: [365 -> (256, 256, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_168 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 365
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 362
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 540
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_168 [DequantizeLinear] inputs: [365 -> (256, 256, 3, 3)[FLOAT]], [362 -> (256)[FLOAT]], [540 -> (256)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 366 for ONNX tensor: 366
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_168 [DequantizeLinear] outputs: [366 -> (256, 256, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Conv_169 [Conv]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 361
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 366
[08/20/2024-19:31:30] [V] [TRT] Conv_169 [Conv] inputs: [361 -> (1, 256, 14, 14)[FLOAT]], [366 -> (256, 256, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Conv_169 for ONNX node: Conv_169
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 367 for ONNX tensor: 367
[08/20/2024-19:31:30] [V] [TRT] Conv_169 [Conv] outputs: [367 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: BatchNormalization_170 [BatchNormalization]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 367
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.0.bn2.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.0.bn2.bias
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.0.bn2.running_mean
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.0.bn2.running_var
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_170 [BatchNormalization] inputs: [367 -> (1, 256, 14, 14)[FLOAT]], [layer3.0.bn2.weight -> (256)[FLOAT]], [layer3.0.bn2.bias -> (256)[FLOAT]], [layer3.0.bn2.running_mean -> (256)[FLOAT]], [layer3.0.bn2.running_var -> (256)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: BatchNormalization_170 for ONNX node: BatchNormalization_170
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 368 for ONNX tensor: 368
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_170 [BatchNormalization] outputs: [368 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_171 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_171 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_171 [Constant] outputs: [369 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_172 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_172 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_172 [Constant] outputs: [370 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_173 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 341
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 369
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 370
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_173 [QuantizeLinear] inputs: [341 -> (1, 128, 28, 28)[FLOAT]], [369 -> ()[FLOAT]], [370 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 369 for ONNX node: 369
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 370 for ONNX node: 370
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 371 for ONNX tensor: 371
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_173 [QuantizeLinear] outputs: [371 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_174 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_174 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_174 [Constant] outputs: [372 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_175 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_175 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_175 [Constant] outputs: [373 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_176 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 371
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 372
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 373
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_176 [DequantizeLinear] inputs: [371 -> (1, 128, 28, 28)[FLOAT]], [372 -> ()[FLOAT]], [373 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 372 for ONNX node: 372
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 373 for ONNX node: 373
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 374 for ONNX tensor: 374
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_176 [DequantizeLinear] outputs: [374 -> (1, 128, 28, 28)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_177 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_177 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_177 [Constant] outputs: [375 -> (256)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_178 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.0.downsample.0.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 375
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 541
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_178 [QuantizeLinear] inputs: [layer3.0.downsample.0.weight -> (256, 128, 1, 1)[FLOAT]], [375 -> (256)[FLOAT]], [541 -> (256)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: layer3.0.downsample.0.weight for ONNX node: layer3.0.downsample.0.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 375 for ONNX node: 375
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 541 for ONNX node: 541
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 378 for ONNX tensor: 378
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_178 [QuantizeLinear] outputs: [378 -> (256, 128, 1, 1)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_179 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 378
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 375
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 541
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_179 [DequantizeLinear] inputs: [378 -> (256, 128, 1, 1)[FLOAT]], [375 -> (256)[FLOAT]], [541 -> (256)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 379 for ONNX tensor: 379
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_179 [DequantizeLinear] outputs: [379 -> (256, 128, 1, 1)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Conv_180 [Conv]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 374
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 379
[08/20/2024-19:31:30] [V] [TRT] Conv_180 [Conv] inputs: [374 -> (1, 128, 28, 28)[FLOAT]], [379 -> (256, 128, 1, 1)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Conv_180 for ONNX node: Conv_180
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 380 for ONNX tensor: 380
[08/20/2024-19:31:30] [V] [TRT] Conv_180 [Conv] outputs: [380 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: BatchNormalization_181 [BatchNormalization]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 380
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.0.downsample.1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.0.downsample.1.bias
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.0.downsample.1.running_mean
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.0.downsample.1.running_var
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_181 [BatchNormalization] inputs: [380 -> (1, 256, 14, 14)[FLOAT]], [layer3.0.downsample.1.weight -> (256)[FLOAT]], [layer3.0.downsample.1.bias -> (256)[FLOAT]], [layer3.0.downsample.1.running_mean -> (256)[FLOAT]], [layer3.0.downsample.1.running_var -> (256)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: BatchNormalization_181 for ONNX node: BatchNormalization_181
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 381 for ONNX tensor: 381
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_181 [BatchNormalization] outputs: [381 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_182 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_182 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_182 [Constant] outputs: [382 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_183 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_183 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_183 [Constant] outputs: [383 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_184 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 381
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 382
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 383
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_184 [QuantizeLinear] inputs: [381 -> (1, 256, 14, 14)[FLOAT]], [382 -> ()[FLOAT]], [383 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 382 for ONNX node: 382
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 383 for ONNX node: 383
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 384 for ONNX tensor: 384
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_184 [QuantizeLinear] outputs: [384 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_185 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_185 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_185 [Constant] outputs: [385 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_186 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_186 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_186 [Constant] outputs: [386 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_187 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 384
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 385
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 386
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_187 [DequantizeLinear] inputs: [384 -> (1, 256, 14, 14)[FLOAT]], [385 -> ()[FLOAT]], [386 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 385 for ONNX node: 385
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 386 for ONNX node: 386
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 387 for ONNX tensor: 387
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_187 [DequantizeLinear] outputs: [387 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Add_188 [Add]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 387
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 368
[08/20/2024-19:31:30] [V] [TRT] Add_188 [Add] inputs: [387 -> (1, 256, 14, 14)[FLOAT]], [368 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Add_188 for ONNX node: Add_188
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 388 for ONNX tensor: 388
[08/20/2024-19:31:30] [V] [TRT] Add_188 [Add] outputs: [388 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Relu_189 [Relu]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 388
[08/20/2024-19:31:30] [V] [TRT] Relu_189 [Relu] inputs: [388 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Relu_189 for ONNX node: Relu_189
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 389 for ONNX tensor: 389
[08/20/2024-19:31:30] [V] [TRT] Relu_189 [Relu] outputs: [389 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_190 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_190 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_190 [Constant] outputs: [390 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_191 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_191 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_191 [Constant] outputs: [391 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_192 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 389
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 390
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 391
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_192 [QuantizeLinear] inputs: [389 -> (1, 256, 14, 14)[FLOAT]], [390 -> ()[FLOAT]], [391 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 390 for ONNX node: 390
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 391 for ONNX node: 391
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 392 for ONNX tensor: 392
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_192 [QuantizeLinear] outputs: [392 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_193 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_193 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_193 [Constant] outputs: [393 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_194 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_194 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_194 [Constant] outputs: [394 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_195 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 392
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 393
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 394
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_195 [DequantizeLinear] inputs: [392 -> (1, 256, 14, 14)[FLOAT]], [393 -> ()[FLOAT]], [394 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 393 for ONNX node: 393
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 394 for ONNX node: 394
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 395 for ONNX tensor: 395
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_195 [DequantizeLinear] outputs: [395 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_196 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_196 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_196 [Constant] outputs: [396 -> (256)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_197 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.1.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 396
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 542
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_197 [QuantizeLinear] inputs: [layer3.1.conv1.weight -> (256, 256, 3, 3)[FLOAT]], [396 -> (256)[FLOAT]], [542 -> (256)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: layer3.1.conv1.weight for ONNX node: layer3.1.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 396 for ONNX node: 396
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 542 for ONNX node: 542
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 399 for ONNX tensor: 399
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_197 [QuantizeLinear] outputs: [399 -> (256, 256, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_198 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 399
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 396
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 542
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_198 [DequantizeLinear] inputs: [399 -> (256, 256, 3, 3)[FLOAT]], [396 -> (256)[FLOAT]], [542 -> (256)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 400 for ONNX tensor: 400
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_198 [DequantizeLinear] outputs: [400 -> (256, 256, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Conv_199 [Conv]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 395
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 400
[08/20/2024-19:31:30] [V] [TRT] Conv_199 [Conv] inputs: [395 -> (1, 256, 14, 14)[FLOAT]], [400 -> (256, 256, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Conv_199 for ONNX node: Conv_199
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 401 for ONNX tensor: 401
[08/20/2024-19:31:30] [V] [TRT] Conv_199 [Conv] outputs: [401 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: BatchNormalization_200 [BatchNormalization]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 401
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.1.bn1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.1.bn1.bias
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.1.bn1.running_mean
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.1.bn1.running_var
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_200 [BatchNormalization] inputs: [401 -> (1, 256, 14, 14)[FLOAT]], [layer3.1.bn1.weight -> (256)[FLOAT]], [layer3.1.bn1.bias -> (256)[FLOAT]], [layer3.1.bn1.running_mean -> (256)[FLOAT]], [layer3.1.bn1.running_var -> (256)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: BatchNormalization_200 for ONNX node: BatchNormalization_200
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 402 for ONNX tensor: 402
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_200 [BatchNormalization] outputs: [402 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Relu_201 [Relu]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 402
[08/20/2024-19:31:30] [V] [TRT] Relu_201 [Relu] inputs: [402 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Relu_201 for ONNX node: Relu_201
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 403 for ONNX tensor: 403
[08/20/2024-19:31:30] [V] [TRT] Relu_201 [Relu] outputs: [403 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_202 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_202 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_202 [Constant] outputs: [404 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_203 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_203 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_203 [Constant] outputs: [405 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_204 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 403
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 404
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 405
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_204 [QuantizeLinear] inputs: [403 -> (1, 256, 14, 14)[FLOAT]], [404 -> ()[FLOAT]], [405 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 404 for ONNX node: 404
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 405 for ONNX node: 405
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 406 for ONNX tensor: 406
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_204 [QuantizeLinear] outputs: [406 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_205 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_205 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_205 [Constant] outputs: [407 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_206 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_206 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_206 [Constant] outputs: [408 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_207 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 406
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 407
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 408
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_207 [DequantizeLinear] inputs: [406 -> (1, 256, 14, 14)[FLOAT]], [407 -> ()[FLOAT]], [408 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 407 for ONNX node: 407
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 408 for ONNX node: 408
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 409 for ONNX tensor: 409
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_207 [DequantizeLinear] outputs: [409 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_208 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_208 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_208 [Constant] outputs: [410 -> (256)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_209 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.1.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 410
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 543
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_209 [QuantizeLinear] inputs: [layer3.1.conv2.weight -> (256, 256, 3, 3)[FLOAT]], [410 -> (256)[FLOAT]], [543 -> (256)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: layer3.1.conv2.weight for ONNX node: layer3.1.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 410 for ONNX node: 410
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 543 for ONNX node: 543
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 413 for ONNX tensor: 413
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_209 [QuantizeLinear] outputs: [413 -> (256, 256, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_210 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 413
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 410
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 543
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_210 [DequantizeLinear] inputs: [413 -> (256, 256, 3, 3)[FLOAT]], [410 -> (256)[FLOAT]], [543 -> (256)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 414 for ONNX tensor: 414
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_210 [DequantizeLinear] outputs: [414 -> (256, 256, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Conv_211 [Conv]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 409
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 414
[08/20/2024-19:31:30] [V] [TRT] Conv_211 [Conv] inputs: [409 -> (1, 256, 14, 14)[FLOAT]], [414 -> (256, 256, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Conv_211 for ONNX node: Conv_211
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 415 for ONNX tensor: 415
[08/20/2024-19:31:30] [V] [TRT] Conv_211 [Conv] outputs: [415 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: BatchNormalization_212 [BatchNormalization]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 415
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.1.bn2.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.1.bn2.bias
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.1.bn2.running_mean
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer3.1.bn2.running_var
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_212 [BatchNormalization] inputs: [415 -> (1, 256, 14, 14)[FLOAT]], [layer3.1.bn2.weight -> (256)[FLOAT]], [layer3.1.bn2.bias -> (256)[FLOAT]], [layer3.1.bn2.running_mean -> (256)[FLOAT]], [layer3.1.bn2.running_var -> (256)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: BatchNormalization_212 for ONNX node: BatchNormalization_212
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 416 for ONNX tensor: 416
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_212 [BatchNormalization] outputs: [416 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_213 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_213 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_213 [Constant] outputs: [417 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_214 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_214 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_214 [Constant] outputs: [418 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_215 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 389
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 417
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 418
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_215 [QuantizeLinear] inputs: [389 -> (1, 256, 14, 14)[FLOAT]], [417 -> ()[FLOAT]], [418 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 417 for ONNX node: 417
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 418 for ONNX node: 418
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 419 for ONNX tensor: 419
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_215 [QuantizeLinear] outputs: [419 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_216 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_216 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_216 [Constant] outputs: [420 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_217 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_217 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_217 [Constant] outputs: [421 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_218 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 419
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 420
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 421
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_218 [DequantizeLinear] inputs: [419 -> (1, 256, 14, 14)[FLOAT]], [420 -> ()[FLOAT]], [421 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 420 for ONNX node: 420
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 421 for ONNX node: 421
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 422 for ONNX tensor: 422
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_218 [DequantizeLinear] outputs: [422 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Add_219 [Add]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 422
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 416
[08/20/2024-19:31:30] [V] [TRT] Add_219 [Add] inputs: [422 -> (1, 256, 14, 14)[FLOAT]], [416 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Add_219 for ONNX node: Add_219
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 423 for ONNX tensor: 423
[08/20/2024-19:31:30] [V] [TRT] Add_219 [Add] outputs: [423 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Relu_220 [Relu]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 423
[08/20/2024-19:31:30] [V] [TRT] Relu_220 [Relu] inputs: [423 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Relu_220 for ONNX node: Relu_220
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 424 for ONNX tensor: 424
[08/20/2024-19:31:30] [V] [TRT] Relu_220 [Relu] outputs: [424 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_221 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_221 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_221 [Constant] outputs: [425 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_222 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_222 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_222 [Constant] outputs: [426 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_223 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 424
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 425
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 426
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_223 [QuantizeLinear] inputs: [424 -> (1, 256, 14, 14)[FLOAT]], [425 -> ()[FLOAT]], [426 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 425 for ONNX node: 425
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 426 for ONNX node: 426
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 427 for ONNX tensor: 427
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_223 [QuantizeLinear] outputs: [427 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_224 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_224 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_224 [Constant] outputs: [428 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_225 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_225 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_225 [Constant] outputs: [429 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_226 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 427
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 428
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 429
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_226 [DequantizeLinear] inputs: [427 -> (1, 256, 14, 14)[FLOAT]], [428 -> ()[FLOAT]], [429 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 428 for ONNX node: 428
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 429 for ONNX node: 429
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 430 for ONNX tensor: 430
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_226 [DequantizeLinear] outputs: [430 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_227 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_227 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_227 [Constant] outputs: [431 -> (512)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_228 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.0.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 431
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 544
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_228 [QuantizeLinear] inputs: [layer4.0.conv1.weight -> (512, 256, 3, 3)[FLOAT]], [431 -> (512)[FLOAT]], [544 -> (512)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: layer4.0.conv1.weight for ONNX node: layer4.0.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 431 for ONNX node: 431
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 544 for ONNX node: 544
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 434 for ONNX tensor: 434
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_228 [QuantizeLinear] outputs: [434 -> (512, 256, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_229 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 434
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 431
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 544
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_229 [DequantizeLinear] inputs: [434 -> (512, 256, 3, 3)[FLOAT]], [431 -> (512)[FLOAT]], [544 -> (512)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 435 for ONNX tensor: 435
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_229 [DequantizeLinear] outputs: [435 -> (512, 256, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Conv_230 [Conv]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 430
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 435
[08/20/2024-19:31:30] [V] [TRT] Conv_230 [Conv] inputs: [430 -> (1, 256, 14, 14)[FLOAT]], [435 -> (512, 256, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Conv_230 for ONNX node: Conv_230
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 436 for ONNX tensor: 436
[08/20/2024-19:31:30] [V] [TRT] Conv_230 [Conv] outputs: [436 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: BatchNormalization_231 [BatchNormalization]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 436
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.0.bn1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.0.bn1.bias
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.0.bn1.running_mean
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.0.bn1.running_var
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_231 [BatchNormalization] inputs: [436 -> (1, 512, 7, 7)[FLOAT]], [layer4.0.bn1.weight -> (512)[FLOAT]], [layer4.0.bn1.bias -> (512)[FLOAT]], [layer4.0.bn1.running_mean -> (512)[FLOAT]], [layer4.0.bn1.running_var -> (512)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: BatchNormalization_231 for ONNX node: BatchNormalization_231
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 437 for ONNX tensor: 437
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_231 [BatchNormalization] outputs: [437 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Relu_232 [Relu]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 437
[08/20/2024-19:31:30] [V] [TRT] Relu_232 [Relu] inputs: [437 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Relu_232 for ONNX node: Relu_232
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 438 for ONNX tensor: 438
[08/20/2024-19:31:30] [V] [TRT] Relu_232 [Relu] outputs: [438 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_233 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_233 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_233 [Constant] outputs: [439 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_234 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_234 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_234 [Constant] outputs: [440 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_235 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 438
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 439
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 440
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_235 [QuantizeLinear] inputs: [438 -> (1, 512, 7, 7)[FLOAT]], [439 -> ()[FLOAT]], [440 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 439 for ONNX node: 439
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 440 for ONNX node: 440
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 441 for ONNX tensor: 441
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_235 [QuantizeLinear] outputs: [441 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_236 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_236 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_236 [Constant] outputs: [442 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_237 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_237 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_237 [Constant] outputs: [443 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_238 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 441
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 442
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 443
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_238 [DequantizeLinear] inputs: [441 -> (1, 512, 7, 7)[FLOAT]], [442 -> ()[FLOAT]], [443 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 442 for ONNX node: 442
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 443 for ONNX node: 443
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 444 for ONNX tensor: 444
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_238 [DequantizeLinear] outputs: [444 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_239 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_239 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_239 [Constant] outputs: [445 -> (512)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_240 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.0.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 445
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 545
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_240 [QuantizeLinear] inputs: [layer4.0.conv2.weight -> (512, 512, 3, 3)[FLOAT]], [445 -> (512)[FLOAT]], [545 -> (512)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: layer4.0.conv2.weight for ONNX node: layer4.0.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 445 for ONNX node: 445
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 545 for ONNX node: 545
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 448 for ONNX tensor: 448
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_240 [QuantizeLinear] outputs: [448 -> (512, 512, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_241 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 448
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 445
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 545
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_241 [DequantizeLinear] inputs: [448 -> (512, 512, 3, 3)[FLOAT]], [445 -> (512)[FLOAT]], [545 -> (512)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 449 for ONNX tensor: 449
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_241 [DequantizeLinear] outputs: [449 -> (512, 512, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Conv_242 [Conv]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 444
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 449
[08/20/2024-19:31:30] [V] [TRT] Conv_242 [Conv] inputs: [444 -> (1, 512, 7, 7)[FLOAT]], [449 -> (512, 512, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Conv_242 for ONNX node: Conv_242
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 450 for ONNX tensor: 450
[08/20/2024-19:31:30] [V] [TRT] Conv_242 [Conv] outputs: [450 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: BatchNormalization_243 [BatchNormalization]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 450
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.0.bn2.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.0.bn2.bias
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.0.bn2.running_mean
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.0.bn2.running_var
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_243 [BatchNormalization] inputs: [450 -> (1, 512, 7, 7)[FLOAT]], [layer4.0.bn2.weight -> (512)[FLOAT]], [layer4.0.bn2.bias -> (512)[FLOAT]], [layer4.0.bn2.running_mean -> (512)[FLOAT]], [layer4.0.bn2.running_var -> (512)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: BatchNormalization_243 for ONNX node: BatchNormalization_243
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 451 for ONNX tensor: 451
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_243 [BatchNormalization] outputs: [451 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_244 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_244 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_244 [Constant] outputs: [452 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_245 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_245 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_245 [Constant] outputs: [453 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_246 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 424
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 452
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 453
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_246 [QuantizeLinear] inputs: [424 -> (1, 256, 14, 14)[FLOAT]], [452 -> ()[FLOAT]], [453 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 452 for ONNX node: 452
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 453 for ONNX node: 453
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 454 for ONNX tensor: 454
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_246 [QuantizeLinear] outputs: [454 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_247 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_247 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_247 [Constant] outputs: [455 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_248 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_248 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_248 [Constant] outputs: [456 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_249 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 454
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 455
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 456
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_249 [DequantizeLinear] inputs: [454 -> (1, 256, 14, 14)[FLOAT]], [455 -> ()[FLOAT]], [456 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 455 for ONNX node: 455
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 456 for ONNX node: 456
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 457 for ONNX tensor: 457
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_249 [DequantizeLinear] outputs: [457 -> (1, 256, 14, 14)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_250 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_250 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_250 [Constant] outputs: [458 -> (512)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_251 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.0.downsample.0.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 458
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 546
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_251 [QuantizeLinear] inputs: [layer4.0.downsample.0.weight -> (512, 256, 1, 1)[FLOAT]], [458 -> (512)[FLOAT]], [546 -> (512)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: layer4.0.downsample.0.weight for ONNX node: layer4.0.downsample.0.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 458 for ONNX node: 458
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 546 for ONNX node: 546
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 461 for ONNX tensor: 461
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_251 [QuantizeLinear] outputs: [461 -> (512, 256, 1, 1)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_252 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 461
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 458
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 546
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_252 [DequantizeLinear] inputs: [461 -> (512, 256, 1, 1)[FLOAT]], [458 -> (512)[FLOAT]], [546 -> (512)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 462 for ONNX tensor: 462
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_252 [DequantizeLinear] outputs: [462 -> (512, 256, 1, 1)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Conv_253 [Conv]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 457
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 462
[08/20/2024-19:31:30] [V] [TRT] Conv_253 [Conv] inputs: [457 -> (1, 256, 14, 14)[FLOAT]], [462 -> (512, 256, 1, 1)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Conv_253 for ONNX node: Conv_253
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 463 for ONNX tensor: 463
[08/20/2024-19:31:30] [V] [TRT] Conv_253 [Conv] outputs: [463 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: BatchNormalization_254 [BatchNormalization]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 463
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.0.downsample.1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.0.downsample.1.bias
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.0.downsample.1.running_mean
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.0.downsample.1.running_var
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_254 [BatchNormalization] inputs: [463 -> (1, 512, 7, 7)[FLOAT]], [layer4.0.downsample.1.weight -> (512)[FLOAT]], [layer4.0.downsample.1.bias -> (512)[FLOAT]], [layer4.0.downsample.1.running_mean -> (512)[FLOAT]], [layer4.0.downsample.1.running_var -> (512)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: BatchNormalization_254 for ONNX node: BatchNormalization_254
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 464 for ONNX tensor: 464
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_254 [BatchNormalization] outputs: [464 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_255 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_255 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_255 [Constant] outputs: [465 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_256 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_256 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_256 [Constant] outputs: [466 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_257 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 464
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 465
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 466
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_257 [QuantizeLinear] inputs: [464 -> (1, 512, 7, 7)[FLOAT]], [465 -> ()[FLOAT]], [466 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 465 for ONNX node: 465
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 466 for ONNX node: 466
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 467 for ONNX tensor: 467
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_257 [QuantizeLinear] outputs: [467 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_258 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_258 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_258 [Constant] outputs: [468 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_259 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_259 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_259 [Constant] outputs: [469 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_260 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 467
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 468
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 469
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_260 [DequantizeLinear] inputs: [467 -> (1, 512, 7, 7)[FLOAT]], [468 -> ()[FLOAT]], [469 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 468 for ONNX node: 468
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 469 for ONNX node: 469
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 470 for ONNX tensor: 470
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_260 [DequantizeLinear] outputs: [470 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Add_261 [Add]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 470
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 451
[08/20/2024-19:31:30] [V] [TRT] Add_261 [Add] inputs: [470 -> (1, 512, 7, 7)[FLOAT]], [451 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Add_261 for ONNX node: Add_261
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 471 for ONNX tensor: 471
[08/20/2024-19:31:30] [V] [TRT] Add_261 [Add] outputs: [471 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Relu_262 [Relu]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 471
[08/20/2024-19:31:30] [V] [TRT] Relu_262 [Relu] inputs: [471 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Relu_262 for ONNX node: Relu_262
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 472 for ONNX tensor: 472
[08/20/2024-19:31:30] [V] [TRT] Relu_262 [Relu] outputs: [472 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_263 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_263 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_263 [Constant] outputs: [473 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_264 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_264 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_264 [Constant] outputs: [474 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_265 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 472
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 473
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 474
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_265 [QuantizeLinear] inputs: [472 -> (1, 512, 7, 7)[FLOAT]], [473 -> ()[FLOAT]], [474 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 473 for ONNX node: 473
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 474 for ONNX node: 474
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 475 for ONNX tensor: 475
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_265 [QuantizeLinear] outputs: [475 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_266 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_266 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_266 [Constant] outputs: [476 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_267 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_267 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_267 [Constant] outputs: [477 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_268 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 475
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 476
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 477
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_268 [DequantizeLinear] inputs: [475 -> (1, 512, 7, 7)[FLOAT]], [476 -> ()[FLOAT]], [477 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 476 for ONNX node: 476
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 477 for ONNX node: 477
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 478 for ONNX tensor: 478
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_268 [DequantizeLinear] outputs: [478 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_269 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_269 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_269 [Constant] outputs: [479 -> (512)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_270 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.1.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 479
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 547
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_270 [QuantizeLinear] inputs: [layer4.1.conv1.weight -> (512, 512, 3, 3)[FLOAT]], [479 -> (512)[FLOAT]], [547 -> (512)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: layer4.1.conv1.weight for ONNX node: layer4.1.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 479 for ONNX node: 479
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 547 for ONNX node: 547
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 482 for ONNX tensor: 482
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_270 [QuantizeLinear] outputs: [482 -> (512, 512, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_271 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 482
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 479
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 547
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_271 [DequantizeLinear] inputs: [482 -> (512, 512, 3, 3)[FLOAT]], [479 -> (512)[FLOAT]], [547 -> (512)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 483 for ONNX tensor: 483
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_271 [DequantizeLinear] outputs: [483 -> (512, 512, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Conv_272 [Conv]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 478
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 483
[08/20/2024-19:31:30] [V] [TRT] Conv_272 [Conv] inputs: [478 -> (1, 512, 7, 7)[FLOAT]], [483 -> (512, 512, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Conv_272 for ONNX node: Conv_272
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 484 for ONNX tensor: 484
[08/20/2024-19:31:30] [V] [TRT] Conv_272 [Conv] outputs: [484 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: BatchNormalization_273 [BatchNormalization]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 484
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.1.bn1.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.1.bn1.bias
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.1.bn1.running_mean
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.1.bn1.running_var
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_273 [BatchNormalization] inputs: [484 -> (1, 512, 7, 7)[FLOAT]], [layer4.1.bn1.weight -> (512)[FLOAT]], [layer4.1.bn1.bias -> (512)[FLOAT]], [layer4.1.bn1.running_mean -> (512)[FLOAT]], [layer4.1.bn1.running_var -> (512)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: BatchNormalization_273 for ONNX node: BatchNormalization_273
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 485 for ONNX tensor: 485
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_273 [BatchNormalization] outputs: [485 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Relu_274 [Relu]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 485
[08/20/2024-19:31:30] [V] [TRT] Relu_274 [Relu] inputs: [485 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Relu_274 for ONNX node: Relu_274
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 486 for ONNX tensor: 486
[08/20/2024-19:31:30] [V] [TRT] Relu_274 [Relu] outputs: [486 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_275 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_275 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_275 [Constant] outputs: [487 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_276 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_276 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_276 [Constant] outputs: [488 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_277 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 486
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 487
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 488
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_277 [QuantizeLinear] inputs: [486 -> (1, 512, 7, 7)[FLOAT]], [487 -> ()[FLOAT]], [488 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 487 for ONNX node: 487
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 488 for ONNX node: 488
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 489 for ONNX tensor: 489
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_277 [QuantizeLinear] outputs: [489 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_278 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_278 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_278 [Constant] outputs: [490 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_279 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_279 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_279 [Constant] outputs: [491 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_280 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 489
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 490
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 491
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_280 [DequantizeLinear] inputs: [489 -> (1, 512, 7, 7)[FLOAT]], [490 -> ()[FLOAT]], [491 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 490 for ONNX node: 490
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 491 for ONNX node: 491
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 492 for ONNX tensor: 492
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_280 [DequantizeLinear] outputs: [492 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_281 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_281 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_281 [Constant] outputs: [493 -> (512)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_282 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.1.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 493
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 548
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_282 [QuantizeLinear] inputs: [layer4.1.conv2.weight -> (512, 512, 3, 3)[FLOAT]], [493 -> (512)[FLOAT]], [548 -> (512)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: layer4.1.conv2.weight for ONNX node: layer4.1.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 493 for ONNX node: 493
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 548 for ONNX node: 548
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 496 for ONNX tensor: 496
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_282 [QuantizeLinear] outputs: [496 -> (512, 512, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_283 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 496
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 493
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 548
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_283 [DequantizeLinear] inputs: [496 -> (512, 512, 3, 3)[FLOAT]], [493 -> (512)[FLOAT]], [548 -> (512)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 497 for ONNX tensor: 497
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_283 [DequantizeLinear] outputs: [497 -> (512, 512, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Conv_284 [Conv]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 492
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 497
[08/20/2024-19:31:30] [V] [TRT] Conv_284 [Conv] inputs: [492 -> (1, 512, 7, 7)[FLOAT]], [497 -> (512, 512, 3, 3)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Kernel weights are not set yet. Kernel weights must be set using setInput(1, kernel_tensor) API call.
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Conv_284 for ONNX node: Conv_284
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 498 for ONNX tensor: 498
[08/20/2024-19:31:30] [V] [TRT] Conv_284 [Conv] outputs: [498 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: BatchNormalization_285 [BatchNormalization]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 498
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.1.bn2.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.1.bn2.bias
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.1.bn2.running_mean
[08/20/2024-19:31:30] [V] [TRT] Searching for input: layer4.1.bn2.running_var
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_285 [BatchNormalization] inputs: [498 -> (1, 512, 7, 7)[FLOAT]], [layer4.1.bn2.weight -> (512)[FLOAT]], [layer4.1.bn2.bias -> (512)[FLOAT]], [layer4.1.bn2.running_mean -> (512)[FLOAT]], [layer4.1.bn2.running_var -> (512)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: BatchNormalization_285 for ONNX node: BatchNormalization_285
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 499 for ONNX tensor: 499
[08/20/2024-19:31:30] [V] [TRT] BatchNormalization_285 [BatchNormalization] outputs: [499 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_286 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_286 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_286 [Constant] outputs: [500 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_287 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_287 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_287 [Constant] outputs: [501 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_288 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 472
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 500
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 501
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_288 [QuantizeLinear] inputs: [472 -> (1, 512, 7, 7)[FLOAT]], [500 -> ()[FLOAT]], [501 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 500 for ONNX node: 500
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 501 for ONNX node: 501
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 502 for ONNX tensor: 502
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_288 [QuantizeLinear] outputs: [502 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_289 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_289 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_289 [Constant] outputs: [503 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_290 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_290 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_290 [Constant] outputs: [504 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_291 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 502
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 503
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 504
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_291 [DequantizeLinear] inputs: [502 -> (1, 512, 7, 7)[FLOAT]], [503 -> ()[FLOAT]], [504 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 503 for ONNX node: 503
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 504 for ONNX node: 504
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 505 for ONNX tensor: 505
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_291 [DequantizeLinear] outputs: [505 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Add_292 [Add]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 505
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 499
[08/20/2024-19:31:30] [V] [TRT] Add_292 [Add] inputs: [505 -> (1, 512, 7, 7)[FLOAT]], [499 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Add_292 for ONNX node: Add_292
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 506 for ONNX tensor: 506
[08/20/2024-19:31:30] [V] [TRT] Add_292 [Add] outputs: [506 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Relu_293 [Relu]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 506
[08/20/2024-19:31:30] [V] [TRT] Relu_293 [Relu] inputs: [506 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Relu_293 for ONNX node: Relu_293
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 507 for ONNX tensor: 507
[08/20/2024-19:31:30] [V] [TRT] Relu_293 [Relu] outputs: [507 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_294 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_294 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_294 [Constant] outputs: [508 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_295 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_295 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_295 [Constant] outputs: [509 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_296 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 507
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 508
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 509
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_296 [QuantizeLinear] inputs: [507 -> (1, 512, 7, 7)[FLOAT]], [508 -> ()[FLOAT]], [509 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 508 for ONNX node: 508
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 509 for ONNX node: 509
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 510 for ONNX tensor: 510
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_296 [QuantizeLinear] outputs: [510 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_297 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_297 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_297 [Constant] outputs: [511 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_298 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_298 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_298 [Constant] outputs: [512 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_299 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 510
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 511
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 512
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_299 [DequantizeLinear] inputs: [510 -> (1, 512, 7, 7)[FLOAT]], [511 -> ()[FLOAT]], [512 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 511 for ONNX node: 511
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 512 for ONNX node: 512
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 513 for ONNX tensor: 513
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_299 [DequantizeLinear] outputs: [513 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: GlobalAveragePool_300 [GlobalAveragePool]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 513
[08/20/2024-19:31:30] [V] [TRT] GlobalAveragePool_300 [GlobalAveragePool] inputs: [513 -> (1, 512, 7, 7)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] GlobalAveragePool operators are implemented via Reduce layers rather than Pooling layers
[08/20/2024-19:31:30] [V] [TRT] Registering layer: GlobalAveragePool_300 for ONNX node: GlobalAveragePool_300
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 514 for ONNX tensor: 514
[08/20/2024-19:31:30] [V] [TRT] GlobalAveragePool_300 [GlobalAveragePool] outputs: [514 -> (1, 512, 1, 1)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Flatten_301 [Flatten]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 514
[08/20/2024-19:31:30] [V] [TRT] Flatten_301 [Flatten] inputs: [514 -> (1, 512, 1, 1)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Flatten_301 for ONNX node: Flatten_301
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 515 for ONNX tensor: 515
[08/20/2024-19:31:30] [V] [TRT] Flatten_301 [Flatten] outputs: [515 -> (1, 512)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_302 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_302 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_302 [Constant] outputs: [516 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_303 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_303 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_303 [Constant] outputs: [517 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_304 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 515
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 516
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 517
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_304 [QuantizeLinear] inputs: [515 -> (1, 512)[FLOAT]], [516 -> ()[FLOAT]], [517 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 516 for ONNX node: 516
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 517 for ONNX node: 517
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 518 for ONNX tensor: 518
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_304 [QuantizeLinear] outputs: [518 -> (1, 512)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_305 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_305 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_305 [Constant] outputs: [519 -> ()[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_306 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_306 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_306 [Constant] outputs: [520 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_307 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 518
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 519
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 520
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_307 [DequantizeLinear] inputs: [518 -> (1, 512)[FLOAT]], [519 -> ()[FLOAT]], [520 -> ()[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 519 for ONNX node: 519
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 520 for ONNX node: 520
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 521 for ONNX tensor: 521
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_307 [DequantizeLinear] outputs: [521 -> (1, 512)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Constant_308 [Constant]
[08/20/2024-19:31:30] [V] [TRT] Constant_308 [Constant] inputs: 
[08/20/2024-19:31:30] [V] [TRT] Constant_308 [Constant] outputs: [522 -> (1000)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: QuantizeLinear_309 [QuantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: fc.weight
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 522
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 549
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_309 [QuantizeLinear] inputs: [fc.weight -> (1000, 512)[FLOAT]], [522 -> (1000)[FLOAT]], [549 -> (1000)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: fc.weight for ONNX node: fc.weight
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 522 for ONNX node: 522
[08/20/2024-19:31:30] [V] [TRT] Registering layer: 549 for ONNX node: 549
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 525 for ONNX tensor: 525
[08/20/2024-19:31:30] [V] [TRT] QuantizeLinear_309 [QuantizeLinear] outputs: [525 -> (1000, 512)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: DequantizeLinear_310 [DequantizeLinear]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 525
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 522
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 549
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_310 [DequantizeLinear] inputs: [525 -> (1000, 512)[FLOAT]], [522 -> (1000)[FLOAT]], [549 -> (1000)[INT8]], 
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 526 for ONNX tensor: 526
[08/20/2024-19:31:30] [V] [TRT] DequantizeLinear_310 [DequantizeLinear] outputs: [526 -> (1000, 512)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Gemm_311 [Gemm]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 521
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 526
[08/20/2024-19:31:30] [V] [TRT] Searching for input: fc.bias
[08/20/2024-19:31:30] [V] [TRT] Gemm_311 [Gemm] inputs: [521 -> (1, 512)[FLOAT]], [526 -> (1000, 512)[FLOAT]], [fc.bias -> (1000)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Using opA: 0 opB: 1
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Gemm_311 for ONNX node: Gemm_311
[08/20/2024-19:31:30] [V] [TRT] Registering layer: fc.bias for ONNX node: fc.bias
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 527 for ONNX tensor: 527
[08/20/2024-19:31:30] [V] [TRT] Gemm_311 [Gemm] outputs: [527 -> (1, 1000)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Parsing node: Softmax_312 [Softmax]
[08/20/2024-19:31:30] [V] [TRT] Searching for input: 527
[08/20/2024-19:31:30] [V] [TRT] Softmax_312 [Softmax] inputs: [527 -> (1, 1000)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Registering layer: Softmax_312 for ONNX node: Softmax_312
[08/20/2024-19:31:30] [V] [TRT] Registering tensor: 528_120 for ONNX tensor: 528
[08/20/2024-19:31:30] [V] [TRT] Softmax_312 [Softmax] outputs: [528 -> (1, 1000)[FLOAT]], 
[08/20/2024-19:31:30] [V] [TRT] Marking 528_120 as output: 528
[08/20/2024-19:31:30] [I] Finish parsing network model
[08/20/2024-19:31:30] [W] [TRT] Calibrator won't be used in explicit precision mode. Use quantization aware training to generate network with Quantize/Dequantize nodes.
[08/20/2024-19:31:30] [V] [TRT] Original: 359 layers
[08/20/2024-19:31:30] [V] [TRT] After dead-layer removal: 359 layers
[08/20/2024-19:31:30] [V] [TRT] Applying generic optimizations to the graph for inference.
[08/20/2024-19:31:30] [V] [TRT] Running: ConstShuffleFusion on fc.bias
[08/20/2024-19:31:30] [V] [TRT] ConstShuffleFusion: Fusing fc.bias with (Unnamed Layer* 355) [Shuffle]
[08/20/2024-19:31:30] [V] [TRT] Running: ShuffleErasure on (Unnamed Layer* 358) [Shuffle]
[08/20/2024-19:31:30] [V] [TRT] Removing (Unnamed Layer* 358) [Shuffle]
[08/20/2024-19:31:30] [V] [TRT] QDQ graph optimizer - constant folding of Q/DQ initializers
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_2
[08/20/2024-19:31:30] [V] [TRT] Removing 175
[08/20/2024-19:31:30] [V] [TRT] Removing 174
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_20
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_32
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_51
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_63
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_82
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_94
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_105
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_124
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_136
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_155
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_167
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_178
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_197
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_209
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_228
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_240
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_251
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_270
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_282
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_309
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_5
[08/20/2024-19:31:30] [V] [TRT] Removing 178
[08/20/2024-19:31:30] [V] [TRT] Removing 177
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_21
[08/20/2024-19:31:30] [V] [TRT] Removing 530
[08/20/2024-19:31:30] [V] [TRT] Removing 195
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_52
[08/20/2024-19:31:30] [V] [TRT] Removing 532
[08/20/2024-19:31:30] [V] [TRT] Removing 230
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_83
[08/20/2024-19:31:30] [V] [TRT] Removing 534
[08/20/2024-19:31:30] [V] [TRT] Removing 265
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_106
[08/20/2024-19:31:30] [V] [TRT] Removing 536
[08/20/2024-19:31:30] [V] [TRT] Removing 292
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_137
[08/20/2024-19:31:30] [V] [TRT] Removing 538
[08/20/2024-19:31:30] [V] [TRT] Removing 327
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_168
[08/20/2024-19:31:30] [V] [TRT] Removing 540
[08/20/2024-19:31:30] [V] [TRT] Removing 362
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_198
[08/20/2024-19:31:30] [V] [TRT] Removing 542
[08/20/2024-19:31:30] [V] [TRT] Removing 396
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_229
[08/20/2024-19:31:30] [V] [TRT] Removing 544
[08/20/2024-19:31:30] [V] [TRT] Removing 431
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_252
[08/20/2024-19:31:30] [V] [TRT] Removing 546
[08/20/2024-19:31:30] [V] [TRT] Removing 458
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_283
[08/20/2024-19:31:30] [V] [TRT] Removing 548
[08/20/2024-19:31:30] [V] [TRT] Removing 493
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_15
[08/20/2024-19:31:30] [V] [TRT] Removing 190
[08/20/2024-19:31:30] [V] [TRT] Removing 189
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_18
[08/20/2024-19:31:30] [V] [TRT] Removing 193
[08/20/2024-19:31:30] [V] [TRT] Removing 192
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_27
[08/20/2024-19:31:30] [V] [TRT] Removing 204
[08/20/2024-19:31:30] [V] [TRT] Removing 203
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_46
[08/20/2024-19:31:30] [V] [TRT] Removing 225
[08/20/2024-19:31:30] [V] [TRT] Removing 224
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_49
[08/20/2024-19:31:30] [V] [TRT] Removing 228
[08/20/2024-19:31:30] [V] [TRT] Removing 227
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_58
[08/20/2024-19:31:30] [V] [TRT] Removing 239
[08/20/2024-19:31:30] [V] [TRT] Removing 238
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_77
[08/20/2024-19:31:30] [V] [TRT] Removing 260
[08/20/2024-19:31:30] [V] [TRT] Removing 259
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_80
[08/20/2024-19:31:30] [V] [TRT] Removing 263
[08/20/2024-19:31:30] [V] [TRT] Removing 262
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_111
[08/20/2024-19:31:30] [V] [TRT] Removing 300
[08/20/2024-19:31:30] [V] [TRT] Removing 299
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_114
[08/20/2024-19:31:30] [V] [TRT] Removing 303
[08/20/2024-19:31:30] [V] [TRT] Removing 302
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_119
[08/20/2024-19:31:30] [V] [TRT] Removing 308
[08/20/2024-19:31:30] [V] [TRT] Removing 307
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_122
[08/20/2024-19:31:30] [V] [TRT] Removing 311
[08/20/2024-19:31:30] [V] [TRT] Removing 310
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_131
[08/20/2024-19:31:30] [V] [TRT] Removing 322
[08/20/2024-19:31:30] [V] [TRT] Removing 321
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_150
[08/20/2024-19:31:30] [V] [TRT] Removing 343
[08/20/2024-19:31:30] [V] [TRT] Removing 342
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_153
[08/20/2024-19:31:30] [V] [TRT] Removing 346
[08/20/2024-19:31:30] [V] [TRT] Removing 345
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_184
[08/20/2024-19:31:30] [V] [TRT] Removing 383
[08/20/2024-19:31:30] [V] [TRT] Removing 382
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_187
[08/20/2024-19:31:30] [V] [TRT] Removing 386
[08/20/2024-19:31:30] [V] [TRT] Removing 385
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_192
[08/20/2024-19:31:30] [V] [TRT] Removing 391
[08/20/2024-19:31:30] [V] [TRT] Removing 390
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_195
[08/20/2024-19:31:30] [V] [TRT] Removing 394
[08/20/2024-19:31:30] [V] [TRT] Removing 393
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_204
[08/20/2024-19:31:30] [V] [TRT] Removing 405
[08/20/2024-19:31:30] [V] [TRT] Removing 404
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_223
[08/20/2024-19:31:30] [V] [TRT] Removing 426
[08/20/2024-19:31:30] [V] [TRT] Removing 425
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_226
[08/20/2024-19:31:30] [V] [TRT] Removing 429
[08/20/2024-19:31:30] [V] [TRT] Removing 428
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_257
[08/20/2024-19:31:30] [V] [TRT] Removing 466
[08/20/2024-19:31:30] [V] [TRT] Removing 465
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_260
[08/20/2024-19:31:30] [V] [TRT] Removing 469
[08/20/2024-19:31:30] [V] [TRT] Removing 468
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_265
[08/20/2024-19:31:30] [V] [TRT] Removing 474
[08/20/2024-19:31:30] [V] [TRT] Removing 473
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_268
[08/20/2024-19:31:30] [V] [TRT] Removing 477
[08/20/2024-19:31:30] [V] [TRT] Removing 476
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_277
[08/20/2024-19:31:30] [V] [TRT] Removing 488
[08/20/2024-19:31:30] [V] [TRT] Removing 487
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_296
[08/20/2024-19:31:30] [V] [TRT] Removing 509
[08/20/2024-19:31:30] [V] [TRT] Removing 508
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_304
[08/20/2024-19:31:30] [V] [TRT] Removing 517
[08/20/2024-19:31:30] [V] [TRT] Removing 516
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_7
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_8
[08/20/2024-19:31:30] [V] [TRT] Removing 529
[08/20/2024-19:31:30] [V] [TRT] Removing 180
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_33
[08/20/2024-19:31:30] [V] [TRT] Removing 531
[08/20/2024-19:31:30] [V] [TRT] Removing 209
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_64
[08/20/2024-19:31:30] [V] [TRT] Removing 533
[08/20/2024-19:31:30] [V] [TRT] Removing 244
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_95
[08/20/2024-19:31:30] [V] [TRT] Removing 535
[08/20/2024-19:31:30] [V] [TRT] Removing 279
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_125
[08/20/2024-19:31:30] [V] [TRT] Removing 537
[08/20/2024-19:31:30] [V] [TRT] Removing 313
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_156
[08/20/2024-19:31:30] [V] [TRT] Removing 539
[08/20/2024-19:31:30] [V] [TRT] Removing 348
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_179
[08/20/2024-19:31:30] [V] [TRT] Removing 541
[08/20/2024-19:31:30] [V] [TRT] Removing 375
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_210
[08/20/2024-19:31:30] [V] [TRT] Removing 543
[08/20/2024-19:31:30] [V] [TRT] Removing 410
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_241
[08/20/2024-19:31:30] [V] [TRT] Removing 545
[08/20/2024-19:31:30] [V] [TRT] Removing 445
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_271
[08/20/2024-19:31:30] [V] [TRT] Removing 547
[08/20/2024-19:31:30] [V] [TRT] Removing 479
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_310
[08/20/2024-19:31:30] [V] [TRT] Removing 549
[08/20/2024-19:31:30] [V] [TRT] Removing 522
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_38
[08/20/2024-19:31:30] [V] [TRT] Removing 217
[08/20/2024-19:31:30] [V] [TRT] Removing 216
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_41
[08/20/2024-19:31:30] [V] [TRT] Removing 220
[08/20/2024-19:31:30] [V] [TRT] Removing 219
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_30
[08/20/2024-19:31:30] [V] [TRT] Removing 207
[08/20/2024-19:31:30] [V] [TRT] Removing 206
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_69
[08/20/2024-19:31:30] [V] [TRT] Removing 252
[08/20/2024-19:31:30] [V] [TRT] Removing 251
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_72
[08/20/2024-19:31:30] [V] [TRT] Removing 255
[08/20/2024-19:31:30] [V] [TRT] Removing 254
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_61
[08/20/2024-19:31:30] [V] [TRT] Removing 242
[08/20/2024-19:31:30] [V] [TRT] Removing 241
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_100
[08/20/2024-19:31:30] [V] [TRT] Removing 287
[08/20/2024-19:31:30] [V] [TRT] Removing 286
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_103
[08/20/2024-19:31:30] [V] [TRT] Removing 290
[08/20/2024-19:31:30] [V] [TRT] Removing 289
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_89
[08/20/2024-19:31:30] [V] [TRT] Removing 274
[08/20/2024-19:31:30] [V] [TRT] Removing 273
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_92
[08/20/2024-19:31:30] [V] [TRT] Removing 277
[08/20/2024-19:31:30] [V] [TRT] Removing 276
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_142
[08/20/2024-19:31:30] [V] [TRT] Removing 335
[08/20/2024-19:31:30] [V] [TRT] Removing 334
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_145
[08/20/2024-19:31:30] [V] [TRT] Removing 338
[08/20/2024-19:31:30] [V] [TRT] Removing 337
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_134
[08/20/2024-19:31:30] [V] [TRT] Removing 325
[08/20/2024-19:31:30] [V] [TRT] Removing 324
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_173
[08/20/2024-19:31:30] [V] [TRT] Removing 370
[08/20/2024-19:31:30] [V] [TRT] Removing 369
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_176
[08/20/2024-19:31:30] [V] [TRT] Removing 373
[08/20/2024-19:31:30] [V] [TRT] Removing 372
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_162
[08/20/2024-19:31:30] [V] [TRT] Removing 357
[08/20/2024-19:31:30] [V] [TRT] Removing 356
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_165
[08/20/2024-19:31:30] [V] [TRT] Removing 360
[08/20/2024-19:31:30] [V] [TRT] Removing 359
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_215
[08/20/2024-19:31:30] [V] [TRT] Removing 418
[08/20/2024-19:31:30] [V] [TRT] Removing 417
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_218
[08/20/2024-19:31:30] [V] [TRT] Removing 421
[08/20/2024-19:31:30] [V] [TRT] Removing 420
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_207
[08/20/2024-19:31:30] [V] [TRT] Removing 408
[08/20/2024-19:31:30] [V] [TRT] Removing 407
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_246
[08/20/2024-19:31:30] [V] [TRT] Removing 453
[08/20/2024-19:31:30] [V] [TRT] Removing 452
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_249
[08/20/2024-19:31:30] [V] [TRT] Removing 456
[08/20/2024-19:31:30] [V] [TRT] Removing 455
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_235
[08/20/2024-19:31:30] [V] [TRT] Removing 440
[08/20/2024-19:31:30] [V] [TRT] Removing 439
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_238
[08/20/2024-19:31:30] [V] [TRT] Removing 443
[08/20/2024-19:31:30] [V] [TRT] Removing 442
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on QuantizeLinear_288
[08/20/2024-19:31:30] [V] [TRT] Removing 501
[08/20/2024-19:31:30] [V] [TRT] Removing 500
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_291
[08/20/2024-19:31:30] [V] [TRT] Removing 504
[08/20/2024-19:31:30] [V] [TRT] Removing 503
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_280
[08/20/2024-19:31:30] [V] [TRT] Removing 491
[08/20/2024-19:31:30] [V] [TRT] Removing 490
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_299
[08/20/2024-19:31:30] [V] [TRT] Removing 512
[08/20/2024-19:31:30] [V] [TRT] Removing 511
[08/20/2024-19:31:30] [V] [TRT] Running: ConstQDQInitializersFusion on DequantizeLinear_307
[08/20/2024-19:31:30] [V] [TRT] Removing 520
[08/20/2024-19:31:30] [V] [TRT] Removing 519
[08/20/2024-19:31:30] [V] [TRT] After Myelin optimization: 195 layers
[08/20/2024-19:31:30] [V] [TRT] QDQ graph optimizer - constant folding of Q/DQ initializers
[08/20/2024-19:31:30] [V] [TRT] QDQ graph optimizer forward pass - DQ motions and fusions
[08/20/2024-19:31:30] [V] [TRT] QDQ graph optimizer backward pass
[08/20/2024-19:31:30] [V] [TRT] QDQ graph optimizer quantization pass - Generate quantized ops
[08/20/2024-19:31:30] [V] [TRT] Running: EltReluFusion on Add_42
[08/20/2024-19:31:30] [V] [TRT] EltReluFusion: Fusing Add_42 with Relu_43
[08/20/2024-19:31:30] [V] [TRT] Running: EltReluFusion on Add_73
[08/20/2024-19:31:30] [V] [TRT] EltReluFusion: Fusing Add_73 with Relu_74
[08/20/2024-19:31:30] [V] [TRT] Running: EltReluFusion on Add_115
[08/20/2024-19:31:30] [V] [TRT] EltReluFusion: Fusing Add_115 with Relu_116
[08/20/2024-19:31:30] [V] [TRT] Running: EltReluFusion on Add_146
[08/20/2024-19:31:30] [V] [TRT] EltReluFusion: Fusing Add_146 with Relu_147
[08/20/2024-19:31:30] [V] [TRT] Running: EltReluFusion on Add_188
[08/20/2024-19:31:30] [V] [TRT] EltReluFusion: Fusing Add_188 with Relu_189
[08/20/2024-19:31:30] [V] [TRT] Running: EltReluFusion on Add_219
[08/20/2024-19:31:30] [V] [TRT] EltReluFusion: Fusing Add_219 with Relu_220
[08/20/2024-19:31:30] [V] [TRT] Running: EltReluFusion on Add_261
[08/20/2024-19:31:30] [V] [TRT] EltReluFusion: Fusing Add_261 with Relu_262
[08/20/2024-19:31:30] [V] [TRT] Running: EltReluFusion on Add_292
[08/20/2024-19:31:30] [V] [TRT] EltReluFusion: Fusing Add_292 with Relu_293
[08/20/2024-19:31:30] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_10
[08/20/2024-19:31:30] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_10 with Relu_11
[08/20/2024-19:31:30] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_23
[08/20/2024-19:31:30] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_23 with Relu_24
[08/20/2024-19:31:30] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_54
[08/20/2024-19:31:30] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_54 with Relu_55
[08/20/2024-19:31:30] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_85
[08/20/2024-19:31:30] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_85 with Relu_86
[08/20/2024-19:31:30] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_127
[08/20/2024-19:31:30] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_127 with Relu_128
[08/20/2024-19:31:30] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_158
[08/20/2024-19:31:30] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_158 with Relu_159
[08/20/2024-19:31:30] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_200
[08/20/2024-19:31:30] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_200 with Relu_201
[08/20/2024-19:31:30] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_231
[08/20/2024-19:31:30] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_231 with Relu_232
[08/20/2024-19:31:30] [V] [TRT] Running: ScaleActivationFusion on BatchNormalization_273
[08/20/2024-19:31:30] [V] [TRT] ScaleActivationFusion: Fusing BatchNormalization_273 with Relu_274
[08/20/2024-19:31:30] [V] [TRT] Running: ReduceToPoolingFusion on GlobalAveragePool_300
[08/20/2024-19:31:30] [V] [TRT] Swap the layer type of GlobalAveragePool_300 from REDUCE to POOLING
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on conv1.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing conv1.weight with QuantizeLinear_7
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on layer1.0.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing layer1.0.conv1.weight with QuantizeLinear_20
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on layer1.0.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing layer1.0.conv2.weight with QuantizeLinear_32
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on layer1.1.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing layer1.1.conv1.weight with QuantizeLinear_51
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on layer1.1.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing layer1.1.conv2.weight with QuantizeLinear_63
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on layer2.0.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing layer2.0.conv1.weight with QuantizeLinear_82
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on layer2.0.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing layer2.0.conv2.weight with QuantizeLinear_94
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on layer2.0.downsample.0.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing layer2.0.downsample.0.weight with QuantizeLinear_105
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on layer2.1.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing layer2.1.conv1.weight with QuantizeLinear_124
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on layer2.1.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing layer2.1.conv2.weight with QuantizeLinear_136
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on layer3.0.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing layer3.0.conv1.weight with QuantizeLinear_155
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on layer3.0.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing layer3.0.conv2.weight with QuantizeLinear_167
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on layer3.0.downsample.0.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing layer3.0.downsample.0.weight with QuantizeLinear_178
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on layer3.1.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing layer3.1.conv1.weight with QuantizeLinear_197
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on layer3.1.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing layer3.1.conv2.weight with QuantizeLinear_209
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on layer4.0.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing layer4.0.conv1.weight with QuantizeLinear_228
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on layer4.0.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing layer4.0.conv2.weight with QuantizeLinear_240
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on layer4.0.downsample.0.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing layer4.0.downsample.0.weight with QuantizeLinear_251
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on layer4.1.conv1.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing layer4.1.conv1.weight with QuantizeLinear_270
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on layer4.1.conv2.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing layer4.1.conv2.weight with QuantizeLinear_282
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsQuantizeFusion on fc.weight
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsQuantizeFusion: Fusing fc.weight with QuantizeLinear_309
[08/20/2024-19:31:30] [V] [TRT] Running: MatMulToConvTransform on Gemm_311
[08/20/2024-19:31:30] [V] [TRT] Convert layer type of Gemm_311 from MATRIX_MULTIPLY to CONVOLUTION
[08/20/2024-19:31:30] [V] [TRT] Running: VanillaSwapWithPreceedingDQ on DequantizeLinear_310
[08/20/2024-19:31:30] [V] [TRT] Swapping DequantizeLinear_310 with transpose_before_Gemm_311
[08/20/2024-19:31:30] [V] [TRT] Running: VanillaSwapWithPreceedingDQ on DequantizeLinear_307
[08/20/2024-19:31:30] [V] [TRT] Swapping DequantizeLinear_307 with reshape_before_Gemm_311
[08/20/2024-19:31:30] [V] [TRT] Running: ConstShuffleFusion on fc.weight + QuantizeLinear_309
[08/20/2024-19:31:30] [V] [TRT] ConstShuffleFusion: Fusing fc.weight + QuantizeLinear_309 with transpose_before_Gemm_311
[08/20/2024-19:31:30] [V] [TRT] Running: VanillaSwapWithFollowingQ on Flatten_301
[08/20/2024-19:31:30] [V] [TRT] Swapping Flatten_301 with QuantizeLinear_304
[08/20/2024-19:31:30] [V] [TRT] Running: HorizontalMergeQNodes on QuantizeLinear_15
[08/20/2024-19:31:30] [V] [TRT] Eliminating QuantizeLinear_38 which duplicates (Q) QuantizeLinear_15
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_38
[08/20/2024-19:31:30] [V] [TRT] Running: HorizontalMergeQNodes on QuantizeLinear_46
[08/20/2024-19:31:30] [V] [TRT] Eliminating QuantizeLinear_69 which duplicates (Q) QuantizeLinear_46
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_69
[08/20/2024-19:31:30] [V] [TRT] Running: HorizontalMergeQNodes on QuantizeLinear_77
[08/20/2024-19:31:30] [V] [TRT] Eliminating QuantizeLinear_100 which duplicates (Q) QuantizeLinear_77
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_100
[08/20/2024-19:31:30] [V] [TRT] Running: HorizontalMergeQNodes on QuantizeLinear_119
[08/20/2024-19:31:30] [V] [TRT] Eliminating QuantizeLinear_142 which duplicates (Q) QuantizeLinear_119
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_142
[08/20/2024-19:31:30] [V] [TRT] Running: HorizontalMergeQNodes on QuantizeLinear_150
[08/20/2024-19:31:30] [V] [TRT] Eliminating QuantizeLinear_173 which duplicates (Q) QuantizeLinear_150
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_173
[08/20/2024-19:31:30] [V] [TRT] Running: HorizontalMergeQNodes on QuantizeLinear_192
[08/20/2024-19:31:30] [V] [TRT] Eliminating QuantizeLinear_215 which duplicates (Q) QuantizeLinear_192
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_215
[08/20/2024-19:31:30] [V] [TRT] Running: HorizontalMergeQNodes on QuantizeLinear_223
[08/20/2024-19:31:30] [V] [TRT] Eliminating QuantizeLinear_246 which duplicates (Q) QuantizeLinear_223
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_246
[08/20/2024-19:31:30] [V] [TRT] Running: HorizontalMergeQNodes on QuantizeLinear_265
[08/20/2024-19:31:30] [V] [TRT] Eliminating QuantizeLinear_288 which duplicates (Q) QuantizeLinear_265
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_288
[08/20/2024-19:31:30] [V] [TRT] Running: VanillaSwapWithFollowingQ on MaxPool_12
[08/20/2024-19:31:30] [V] [TRT] Swapping MaxPool_12 with QuantizeLinear_15
[08/20/2024-19:31:30] [V] [TRT] Running: ShuffleShuffleFusion on Flatten_301
[08/20/2024-19:31:30] [V] [TRT] ShuffleShuffleFusion: Fusing Flatten_301 with reshape_before_Gemm_311
[08/20/2024-19:31:30] [V] [TRT] Running: ShuffleErasure on Flatten_301 + reshape_before_Gemm_311
[08/20/2024-19:31:30] [V] [TRT] Removing Flatten_301 + reshape_before_Gemm_311
[08/20/2024-19:31:30] [V] [TRT] Running: SqueezePushDownJoin on reshape_after_Gemm_311
[08/20/2024-19:31:30] [V] [TRT] -----------SqueezePushDown kSQUEEZE_JOIN case: Gemm_311 --> reshape_after_Gemm_311 --> (Unnamed Layer* 356) [ElementWise]
[08/20/2024-19:31:30] [V] [TRT] Running: ConstShuffleFusion on fc.bias + (Unnamed Layer* 355) [Shuffle]
[08/20/2024-19:31:30] [V] [TRT] ConstShuffleFusion: Fusing fc.bias + (Unnamed Layer* 355) [Shuffle] with unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output
[08/20/2024-19:31:30] [V] [TRT] Running: ConstEltFusion on fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output
[08/20/2024-19:31:30] [V] [TRT] ConstEltFusion: Fusing fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output with (Unnamed Layer* 356) [ElementWise]
[08/20/2024-19:31:30] [V] [TRT] Running: ConvScaleFusion on Gemm_311
[08/20/2024-19:31:30] [V] [TRT] ConvScaleFusion: Fusing Gemm_311 with fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise]
[08/20/2024-19:31:30] [V] [TRT] Running: QConvScaleFusion on Conv_9
[08/20/2024-19:31:30] [V] [TRT] Removing BatchNormalization_10 + Relu_11
[08/20/2024-19:31:30] [V] [TRT] Running: QConvScaleFusion on Conv_22
[08/20/2024-19:31:30] [V] [TRT] Removing BatchNormalization_23 + Relu_24
[08/20/2024-19:31:30] [V] [TRT] Running: QConvScaleFusion on Conv_34
[08/20/2024-19:31:30] [V] [TRT] Removing BatchNormalization_35
[08/20/2024-19:31:30] [V] [TRT] Running: QConvScaleFusion on Conv_53
[08/20/2024-19:31:30] [V] [TRT] Removing BatchNormalization_54 + Relu_55
[08/20/2024-19:31:30] [V] [TRT] Running: QConvScaleFusion on Conv_65
[08/20/2024-19:31:30] [V] [TRT] Removing BatchNormalization_66
[08/20/2024-19:31:30] [V] [TRT] Running: QConvScaleFusion on Conv_84
[08/20/2024-19:31:30] [V] [TRT] Removing BatchNormalization_85 + Relu_86
[08/20/2024-19:31:30] [V] [TRT] Running: QConvScaleFusion on Conv_107
[08/20/2024-19:31:30] [V] [TRT] Removing BatchNormalization_108
[08/20/2024-19:31:30] [V] [TRT] Running: QConvScaleFusion on Conv_96
[08/20/2024-19:31:30] [V] [TRT] Removing BatchNormalization_97
[08/20/2024-19:31:30] [V] [TRT] Running: QConvScaleFusion on Conv_126
[08/20/2024-19:31:30] [V] [TRT] Removing BatchNormalization_127 + Relu_128
[08/20/2024-19:31:30] [V] [TRT] Running: QConvScaleFusion on Conv_138
[08/20/2024-19:31:30] [V] [TRT] Removing BatchNormalization_139
[08/20/2024-19:31:30] [V] [TRT] Running: QConvScaleFusion on Conv_157
[08/20/2024-19:31:30] [V] [TRT] Removing BatchNormalization_158 + Relu_159
[08/20/2024-19:31:30] [V] [TRT] Running: QConvScaleFusion on Conv_180
[08/20/2024-19:31:30] [V] [TRT] Removing BatchNormalization_181
[08/20/2024-19:31:30] [V] [TRT] Running: QConvScaleFusion on Conv_169
[08/20/2024-19:31:30] [V] [TRT] Removing BatchNormalization_170
[08/20/2024-19:31:30] [V] [TRT] Running: QConvScaleFusion on Conv_199
[08/20/2024-19:31:30] [V] [TRT] Removing BatchNormalization_200 + Relu_201
[08/20/2024-19:31:30] [V] [TRT] Running: QConvScaleFusion on Conv_211
[08/20/2024-19:31:30] [V] [TRT] Removing BatchNormalization_212
[08/20/2024-19:31:30] [V] [TRT] Running: QConvScaleFusion on Conv_230
[08/20/2024-19:31:30] [V] [TRT] Removing BatchNormalization_231 + Relu_232
[08/20/2024-19:31:30] [V] [TRT] Running: QConvScaleFusion on Conv_253
[08/20/2024-19:31:30] [V] [TRT] Removing BatchNormalization_254
[08/20/2024-19:31:30] [V] [TRT] Running: QConvScaleFusion on Conv_242
[08/20/2024-19:31:30] [V] [TRT] Removing BatchNormalization_243
[08/20/2024-19:31:30] [V] [TRT] Running: QConvScaleFusion on Conv_272
[08/20/2024-19:31:30] [V] [TRT] Removing BatchNormalization_273 + Relu_274
[08/20/2024-19:31:30] [V] [TRT] Running: QConvScaleFusion on Conv_284
[08/20/2024-19:31:30] [V] [TRT] Removing BatchNormalization_285
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeConvWithResidualAdd on Conv_34
[08/20/2024-19:31:30] [V] [TRT] Swapping Add_42 + Relu_43 with QuantizeLinear_46
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_46 into Conv_34
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_30 and DequantizeLinear_33) into Conv_34
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_46
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_30
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_33
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing layer1.0.conv2.weight + QuantizeLinear_32 with Conv_34
[08/20/2024-19:31:30] [V] [TRT] ConvEltwiseSumFusion: Fusing layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 with Add_42 + Relu_43
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_41
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeConvWithResidualAdd on Conv_65
[08/20/2024-19:31:30] [V] [TRT] Swapping Add_73 + Relu_74 with QuantizeLinear_77
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_77 into Conv_65
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_61 and DequantizeLinear_64) into Conv_65
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_77
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_61
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_64
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing layer1.1.conv2.weight + QuantizeLinear_63 with Conv_65
[08/20/2024-19:31:30] [V] [TRT] ConvEltwiseSumFusion: Fusing layer1.1.conv2.weight + QuantizeLinear_63 + Conv_65 with Add_73 + Relu_74
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_72
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeConvWithResidualAdd on Conv_96
[08/20/2024-19:31:30] [V] [TRT] Swapping Add_115 + Relu_116 with QuantizeLinear_119
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_119 into Conv_96
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_92 and DequantizeLinear_95) into Conv_96
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_119
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_92
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_95
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing layer2.0.conv2.weight + QuantizeLinear_94 with Conv_96
[08/20/2024-19:31:30] [V] [TRT] ConvEltwiseSumFusion: Fusing layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 with Add_115 + Relu_116
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_114
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeConvWithResidualAdd on Conv_138
[08/20/2024-19:31:30] [V] [TRT] Swapping Add_146 + Relu_147 with QuantizeLinear_150
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_150 into Conv_138
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_134 and DequantizeLinear_137) into Conv_138
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_150
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_134
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_137
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing layer2.1.conv2.weight + QuantizeLinear_136 with Conv_138
[08/20/2024-19:31:30] [V] [TRT] ConvEltwiseSumFusion: Fusing layer2.1.conv2.weight + QuantizeLinear_136 + Conv_138 with Add_146 + Relu_147
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_145
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeConvWithResidualAdd on Conv_169
[08/20/2024-19:31:30] [V] [TRT] Swapping Add_188 + Relu_189 with QuantizeLinear_192
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_192 into Conv_169
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_165 and DequantizeLinear_168) into Conv_169
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_192
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_165
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_168
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing layer3.0.conv2.weight + QuantizeLinear_167 with Conv_169
[08/20/2024-19:31:30] [V] [TRT] ConvEltwiseSumFusion: Fusing layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 with Add_188 + Relu_189
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_187
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeConvWithResidualAdd on Conv_211
[08/20/2024-19:31:30] [V] [TRT] Swapping Add_219 + Relu_220 with QuantizeLinear_223
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_223 into Conv_211
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_207 and DequantizeLinear_210) into Conv_211
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_223
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_207
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_210
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing layer3.1.conv2.weight + QuantizeLinear_209 with Conv_211
[08/20/2024-19:31:30] [V] [TRT] ConvEltwiseSumFusion: Fusing layer3.1.conv2.weight + QuantizeLinear_209 + Conv_211 with Add_219 + Relu_220
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_218
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeConvWithResidualAdd on Conv_242
[08/20/2024-19:31:30] [V] [TRT] Swapping Add_261 + Relu_262 with QuantizeLinear_265
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_265 into Conv_242
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_238 and DequantizeLinear_241) into Conv_242
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_265
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_238
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_241
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing layer4.0.conv2.weight + QuantizeLinear_240 with Conv_242
[08/20/2024-19:31:30] [V] [TRT] ConvEltwiseSumFusion: Fusing layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 with Add_261 + Relu_262
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_260
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeConvWithResidualAdd on Conv_284
[08/20/2024-19:31:30] [V] [TRT] Swapping Add_292 + Relu_293 with QuantizeLinear_296
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_296 into Conv_284
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_280 and DequantizeLinear_283) into Conv_284
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_296
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_280
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_283
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing layer4.1.conv2.weight + QuantizeLinear_282 with Conv_284
[08/20/2024-19:31:30] [V] [TRT] ConvEltwiseSumFusion: Fusing layer4.1.conv2.weight + QuantizeLinear_282 + Conv_284 with Add_292 + Relu_293
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_291
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_9
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_15 into Conv_9
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_5 and DequantizeLinear_8) into Conv_9
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_15
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_5
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_8
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_22
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_27 into Conv_22
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_18 and DequantizeLinear_21) into Conv_22
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_27
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_18
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_21
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_53
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_58 into Conv_53
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_49 and DequantizeLinear_52) into Conv_53
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_58
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_49
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_52
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_84
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_89 into Conv_84
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_80 and DequantizeLinear_83) into Conv_84
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_89
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_80
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_83
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_126
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_131 into Conv_126
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_122 and DequantizeLinear_125) into Conv_126
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_131
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_122
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_125
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_157
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_162 into Conv_157
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_153 and DequantizeLinear_156) into Conv_157
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_162
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_153
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_156
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_199
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_204 into Conv_199
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_195 and DequantizeLinear_198) into Conv_199
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_204
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_195
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_198
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_230
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_235 into Conv_230
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_226 and DequantizeLinear_229) into Conv_230
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_235
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_226
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_229
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_272
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_277 into Conv_272
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_268 and DequantizeLinear_271) into Conv_272
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_277
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_268
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_271
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeDoubleInputNodes on Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise]
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_307 and DequantizeLinear_310) into Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise]
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_307
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_310
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_107
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_111 into Conv_107
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_103 and DequantizeLinear_106) into Conv_107
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_111
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_103
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_106
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_180
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_184 into Conv_180
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_176 and DequantizeLinear_179) into Conv_180
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_184
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_176
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_179
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeDoubleInputNodes on Conv_253
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing QuantizeLinear_257 into Conv_253
[08/20/2024-19:31:30] [V] [TRT] QuantizeDoubleInputNodes: fusing (DequantizeLinear_249 and DequantizeLinear_252) into Conv_253
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_257
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_249
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_252
[08/20/2024-19:31:30] [V] [TRT] Running: QuantizeSingleInputNodes on GlobalAveragePool_300
[08/20/2024-19:31:30] [V] [TRT] Removing QuantizeLinear_304
[08/20/2024-19:31:30] [V] [TRT] Removing DequantizeLinear_299
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsFusion on conv1.weight + QuantizeLinear_7
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing conv1.weight + QuantizeLinear_7 with Conv_9
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsFusion on layer1.0.conv1.weight + QuantizeLinear_20
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing layer1.0.conv1.weight + QuantizeLinear_20 with Conv_22
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsFusion on layer1.1.conv1.weight + QuantizeLinear_51
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing layer1.1.conv1.weight + QuantizeLinear_51 with Conv_53
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsFusion on layer2.0.conv1.weight + QuantizeLinear_82
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing layer2.0.conv1.weight + QuantizeLinear_82 with Conv_84
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsFusion on layer2.0.downsample.0.weight + QuantizeLinear_105
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing layer2.0.downsample.0.weight + QuantizeLinear_105 with Conv_107
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsFusion on layer2.1.conv1.weight + QuantizeLinear_124
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing layer2.1.conv1.weight + QuantizeLinear_124 with Conv_126
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsFusion on layer3.0.conv1.weight + QuantizeLinear_155
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing layer3.0.conv1.weight + QuantizeLinear_155 with Conv_157
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsFusion on layer3.0.downsample.0.weight + QuantizeLinear_178
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing layer3.0.downsample.0.weight + QuantizeLinear_178 with Conv_180
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsFusion on layer3.1.conv1.weight + QuantizeLinear_197
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing layer3.1.conv1.weight + QuantizeLinear_197 with Conv_199
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsFusion on layer4.0.conv1.weight + QuantizeLinear_228
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing layer4.0.conv1.weight + QuantizeLinear_228 with Conv_230
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsFusion on layer4.0.downsample.0.weight + QuantizeLinear_251
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing layer4.0.downsample.0.weight + QuantizeLinear_251 with Conv_253
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsFusion on layer4.1.conv1.weight + QuantizeLinear_270
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing layer4.1.conv1.weight + QuantizeLinear_270 with Conv_272
[08/20/2024-19:31:30] [V] [TRT] Running: ConstWeightsFusion on fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311
[08/20/2024-19:31:30] [V] [TRT] ConstWeightsFusion: Fusing fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 with Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise]
[08/20/2024-19:31:30] [V] [TRT] Running: ConvActPoolFusion on conv1.weight + QuantizeLinear_7 + Conv_9
[08/20/2024-19:31:30] [V] [TRT] ConvActPoolFusion: Fusing conv1.weight + QuantizeLinear_7 + Conv_9 with MaxPool_12
[08/20/2024-19:31:30] [V] [TRT] After dupe layer removal: 25 layers
[08/20/2024-19:31:30] [V] [TRT] After final dead-layer removal: 25 layers
[08/20/2024-19:31:30] [V] [TRT] After tensor merging: 25 layers
[08/20/2024-19:31:30] [V] [TRT] QDQ graph optimizer quantization epilogue pass
[08/20/2024-19:31:30] [V] [TRT] QDQ optimization pass
[08/20/2024-19:31:30] [V] [TRT] QDQ graph optimizer constant fold dangling QDQ pass
[08/20/2024-19:31:30] [V] [TRT] Running: QDQToCopy on QuantizeLinear_2
[08/20/2024-19:31:30] [V] [TRT] Swap the layer type of QuantizeLinear_2 from QUANTIZE to kQDQ
[08/20/2024-19:31:30] [V] [TRT] After dupe layer removal: 25 layers
[08/20/2024-19:31:30] [V] [TRT] After final dead-layer removal: 25 layers
[08/20/2024-19:31:30] [V] [TRT] After tensor merging: 25 layers
[08/20/2024-19:31:30] [V] [TRT] After vertical fusions: 25 layers
[08/20/2024-19:31:30] [V] [TRT] After dupe layer removal: 25 layers
[08/20/2024-19:31:30] [V] [TRT] After final dead-layer removal: 25 layers
[08/20/2024-19:31:30] [V] [TRT] After tensor merging: 25 layers
[08/20/2024-19:31:30] [V] [TRT] After slice removal: 25 layers
[08/20/2024-19:31:30] [V] [TRT] After concat removal: 25 layers
[08/20/2024-19:31:30] [V] [TRT] Trying to split Reshape and strided tensor
[08/20/2024-19:31:30] [V] [TRT] Graph construction and optimization completed in 0.28184 seconds.
[08/20/2024-19:31:30] [V] [TRT] Trying to load shared library libcublas.so.11
[08/20/2024-19:31:30] [V] [TRT] Loaded shared library libcublas.so.11
[08/20/2024-19:31:46] [V] [TRT] Using cublas as plugin tactic source
[08/20/2024-19:31:46] [V] [TRT] Trying to load shared library libcublasLt.so.11
[08/20/2024-19:31:46] [V] [TRT] Loaded shared library libcublasLt.so.11
[08/20/2024-19:31:46] [V] [TRT] Using cublasLt as core library tactic source
[08/20/2024-19:31:46] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +1225, GPU +338, now: CPU 2486, GPU 1672 (MiB)
[08/20/2024-19:31:46] [V] [TRT] Trying to load shared library libcudnn.so.8
[08/20/2024-19:31:46] [V] [TRT] Loaded shared library libcudnn.so.8
[08/20/2024-19:31:46] [V] [TRT] Using cuDNN as plugin tactic source
[08/20/2024-19:31:48] [V] [TRT] Using cuDNN as core library tactic source
[08/20/2024-19:31:48] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +234, GPU +50, now: CPU 2720, GPU 1722 (MiB)
[08/20/2024-19:31:48] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[08/20/2024-19:31:48] [V] [TRT] Constructing optimization profile number 0 [1/1].
[08/20/2024-19:31:48] [V] [TRT] Reserving memory for host IO tensors. Host: 0 bytes
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Float(150528,50176,224,1) -> Int8(150528,50176,224,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: QuantizeLinear_2 (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.143506
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.129829
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.285989
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.129829
[08/20/2024-19:31:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0x00000000000003ea
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 191) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.122075
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.200119
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.12427
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.122075
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 191) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.13429
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.12288
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.12939
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.12288
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(191 -> <out>) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.130194
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.137582
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.122002
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.122002
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(191 -> <out>) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.164279
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.126171
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.150821
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.126171
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(191 -> <out>) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.50059
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.145262
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.153454
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.145262
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(191 -> <out>) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.397312
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.129975
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.125147
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.125147
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(191 -> <out>) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.130706
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.134363
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.128951
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.128951
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(191 -> <out>) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.13451
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.12661
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.233179
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.12661
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 226) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.227913
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.121344
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.107227
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.107227
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 226) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.192512
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.120393
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.17291
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.120393
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 226) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.142848
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.125806
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.397897
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.125806
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 226) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.136704
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.132901
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.132901
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.132901
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(200704,3136,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(6272,3136:32,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(275 -> <out>) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0740693
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.144091
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.094208
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0740693
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(275 -> <out>) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.21899
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.134071
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.13056
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.13056
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(275 -> <out>) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.130926
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.132608
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.140434
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.130926
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(275 -> <out>) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.145262
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.135022
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.106569
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.106569
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(275 -> <out>) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.262729
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.368494
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.123246
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.123246
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(275 -> <out>) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.279259
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.131438
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.111543
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.111543
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 309) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.387072
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.214601
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.115931
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.115931
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 309) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.148773
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.127195
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.157403
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.127195
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 309) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.3072
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.130999
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.420279
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.130999
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 309) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.176201
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.130779
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.233033
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.130779
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 309) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.134583
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.114395
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.126098
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.114395
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 309) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0830171
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.12171
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.102473
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0830171
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(100352,784,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(3136,784:32,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:48] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(358 -> <out>) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.130048
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.12939
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0959634
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0959634
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(358 -> <out>) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.235227
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.12661
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.134363
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.12661
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(358 -> <out>) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.273408
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.137435
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.103351
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.103351
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(358 -> <out>) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.128878
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.123465
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.168375
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.123465
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(358 -> <out>) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.106642
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.127854
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.127927
[08/20/2024-19:31:48] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.106642
[08/20/2024-19:31:48] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(358 -> <out>) (Reformat)
[08/20/2024-19:31:48] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.655214
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.124489
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.106789
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.106789
[08/20/2024-19:31:49] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 392) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.120686
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.130633
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0928183
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0928183
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 392) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.13195
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.124123
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.122661
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.122661
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 392) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.124416
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.378587
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.362496
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.124416
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 392) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.131365
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.122002
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.116443
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.116443
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 392) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.124489
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.192073
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.123465
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.123465
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 392) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.103717
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.13056
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0820663
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0820663
[08/20/2024-19:31:49] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(50176,196,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(1568,196:32,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:49] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49,7,1) -> Int8(6272,49:4,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(441 -> <out>) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.217234
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.153746
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.104741
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.104741
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49,7,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(441 -> <out>) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.113152
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0930377
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.119003
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0930377
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(6272,49:4,7,1) -> Int8(25088,49,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(441 -> <out>) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0919406
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.127269
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0788968
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0788968
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(6272,49:4,7,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(441 -> <out>) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.128731
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0849189
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0608061
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0608061
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(784,49:32,7,1) -> Int8(25088,49,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(441 -> <out>) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.168594
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.133559
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.119223
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.119223
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(784,49:32,7,1) -> Int8(6272,49:4,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(441 -> <out>) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0939154
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.115639
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.090624
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.090624
[08/20/2024-19:31:49] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49,7,1) -> Int8(6272,49:4,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49,7,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(6272,49:4,7,1) -> Int8(25088,49,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(6272,49:4,7,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(784,49:32,7,1) -> Int8(25088,49,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(784,49:32,7,1) -> Int8(6272,49:4,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49,7,1) -> Int8(6272,49:4,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 475) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.121125
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.109934
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.133705
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.109934
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49,7,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 475) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.121563
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.542281
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.245394
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.121563
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(6272,49:4,7,1) -> Int8(25088,49,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 475) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.221769
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.123611
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.101742
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.101742
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(6272,49:4,7,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 475) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.105472
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.122222
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.174665
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.105472
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(784,49:32,7,1) -> Int8(25088,49,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 475) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.103643
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.130341
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.203045
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.103643
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(784,49:32,7,1) -> Int8(6272,49:4,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 475) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.297838
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.120905
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.04864
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.04864
[08/20/2024-19:31:49] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49,7,1) -> Int8(6272,49:4,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49,7,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(6272,49:4,7,1) -> Int8(25088,49,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(6272,49:4,7,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(784,49:32,7,1) -> Int8(25088,49,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(784,49:32,7,1) -> Int8(6272,49:4,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49,7,1) -> Int8(6272,49:4,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49,7,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(6272,49:4,7,1) -> Int8(25088,49,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(6272,49:4,7,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(784,49:32,7,1) -> Int8(25088,49,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(784,49:32,7,1) -> Int8(6272,49:4,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49,7,1) -> Int8(6272,49:4,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49,7,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(6272,49:4,7,1) -> Int8(25088,49,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(6272,49:4,7,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(784,49:32,7,1) -> Int8(25088,49,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(784,49:32,7,1) -> Int8(6272,49:4,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49,7,1) -> Int8(6272,49:4,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(25088,49,7,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(6272,49:4,7,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(784,49:32,7,1) -> Int8(6272,49:4,7,1) ***************
[08/20/2024-19:31:49] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(128,1:4,1,1) -> Int8(16,1:32,1,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.176859
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.264192
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0879177
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0879177
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Int8(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(515 -> <out>) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.258633
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.132754
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0744594
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0744594
[08/20/2024-19:31:49] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Float(1000,1,1,1) -> Half(1000,1,1,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 356) [ElementWise]_out_tensor -> <out>) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0777265
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.188782
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.117467
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0777265
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Float(32,1:32,1,1) -> Float(1000,1,1,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 356) [ElementWise]_out_tensor -> <out>) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0805303
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0854309
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.114322
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0805303
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Float(32,1:32,1,1) -> Half(1000,1,1,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 356) [ElementWise]_out_tensor -> <out>) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0581242
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0755566
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.154039
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x00000000000003e8 Time: 0.0581242
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Half(1000,1,1,1) -> Float(1000,1,1,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 356) [ElementWise]_out_tensor -> <out>) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0550034
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0396069
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.161792
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0396069
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Half(32,1:32,1,1) -> Float(1000,1,1,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 356) [ElementWise]_out_tensor -> <out>) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0925257
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0309833
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.108763
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0309833
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Half(32,1:32,1,1) -> Half(1000,1,1,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat((Unnamed Layer* 356) [ElementWise]_out_tensor -> <out>) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0918674
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.108837
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0724846
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0724846
[08/20/2024-19:31:49] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Float(1000,1) -> Half(1000,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(527 -> <out>) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0657798
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0639269
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0969874
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0639269
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Half(1000,1) -> Float(1000,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(527 -> <out>) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.064512
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0888686
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0607086
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.0607086
[08/20/2024-19:31:49] [V] [TRT] =============== Computing reformatting costs: 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning Reformat: Half(1000,1) -> Float(1000,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 528) (Reformat)
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0939886
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0541745
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0606598
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x00000000000003ea Time: 0.0541745
[08/20/2024-19:31:49] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning format combination: Int8(150528,50176,224,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 (ConvActPool)
[08/20/2024-19:31:49] [V] [TRT] Tactic Name: kIMMA_V1_TILE_32x64 
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.125513
[08/20/2024-19:31:49] [V] [TRT] Tactic Name: kIMMA_V2_TILE_16x224 
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x000000000000044c Time: 0.226523
[08/20/2024-19:31:49] [V] [TRT] Tactic Name: kIMMA_V2_TILE_12x240 
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000456 Time: 0.146286
[08/20/2024-19:31:49] [V] [TRT] Tactic Name: kIMMA_V2_TILE_16x240 
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000457 Time: 0.154331
[08/20/2024-19:31:49] [V] [TRT] Tactic Name: kIMMA_V2_TILE_20x240 
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000458 Time: 0.144969
[08/20/2024-19:31:49] [V] [TRT] Tactic Name: kIMMA_V2_TILE_12x120 
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000460 Time: 0.134071
[08/20/2024-19:31:49] [V] [TRT] Tactic Name: kIMMA_V2_TILE_16x120 
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000461 Time: 0.117029
[08/20/2024-19:31:49] [V] [TRT] Tactic Name: kIMMA_V2_TILE_20x120 
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000462 Time: 0.145993
[08/20/2024-19:31:49] [V] [TRT] Tactic Name: kIMMA_V2_TILE_12x200 
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x000000000000046a Time: 0.332507
[08/20/2024-19:31:49] [V] [TRT] Tactic Name: kIMMA_V2_TILE_16x200 
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x000000000000046b Time: 0.179931
[08/20/2024-19:31:49] [V] [TRT] Tactic Name: kIMMA_V2_TILE_20x200 
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x000000000000046c Time: 0.132754
[08/20/2024-19:31:49] [V] [TRT] Tactic Name: kIMMA_V2_TILE_12x100 
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000474 Time: 0.306469
[08/20/2024-19:31:49] [V] [TRT] Tactic Name: kIMMA_V2_TILE_16x100 
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000475 Time: 0.12427
[08/20/2024-19:31:49] [V] [TRT] Tactic Name: kIMMA_V2_TILE_20x100 
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0000000000000476 Time: 0.160037
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x0000000000000461 Time: 0.117029
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 (CaskConvActPool)
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm72_trt_conv_act_pool_v2_tile_rows_12_tile_cols_120 Tactic: 0x3cf3672bfafcee02
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x3cf3672bfafcee02 Time: 0.155209
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm72_trt_conv_act_pool_v2_tile_rows_16_tile_cols_100 Tactic: 0x714758e16557c6ee
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x714758e16557c6ee Time: 0.127488
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm72_trt_conv_act_pool_v2_tile_rows_20_tile_cols_240 Tactic: 0xd54d4a56ceee5426
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xd54d4a56ceee5426 Time: 0.160475
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm72_trt_conv_act_pool_v2_tile_rows_16_tile_cols_120 Tactic: 0xd895abc5dcf624f4
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xd895abc5dcf624f4 Time: 0.152722
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm72_trt_conv_act_pool_v2_tile_rows_20_tile_cols_100 Tactic: 0x552c20eba11d38ca
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x552c20eba11d38ca Time: 0.164425
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm72_trt_conv_act_pool_v2_tile_rows_20_tile_cols_120 Tactic: 0xfcfed3cf18bcdad0
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xfcfed3cf18bcdad0 Time: 0.145774
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm80_trt_conv_act_pool_v3_tile_rows_8_tile_cols_112 Tactic: 0xbea3c9e81542d720
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xbea3c9e81542d720 Time: 0.134437
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm80_trt_conv_act_pool_v3_tile_rows_8_tile_cols_124 Tactic: 0xccccb68da7fc3a5f
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xccccb68da7fc3a5f Time: 0.145847
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm72_trt_conv_act_pool_v2_tile_rows_20_tile_cols_200 Tactic: 0x1430033412a38e97
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x1430033412a38e97 Time: 0.161646
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm72_trt_conv_act_pool_v2_tile_rows_12_tile_cols_100 Tactic: 0x9521940f435d0c18
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x9521940f435d0c18 Time: 0.159013
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm72_trt_conv_act_pool_v2_tile_rows_12_tile_cols_200 Tactic: 0xd43db7d0f0e3ba45
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xd43db7d0f0e3ba45 Time: 0.161646
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm72_trt_conv_act_pool_v2_tile_rows_16_tile_cols_224 Tactic: 0xe2594b9e90c7cc9a
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xe2594b9e90c7cc9a Time: 0.167424
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm80_trt_conv_act_pool_v3_tile_rows_4_tile_cols_112 Tactic: 0x00d033f1d05396bf
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x00d033f1d05396bf Time: 0.151406
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm72_trt_conv_act_pool_v2_tile_rows_12_tile_cols_240 Tactic: 0x1540feb22cae60f4
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x1540feb22cae60f4 Time: 0.140069
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm80_trt_conv_act_pool_v3_tile_rows_4_tile_cols_120 Tactic: 0x096f8f109d6225f3
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x096f8f109d6225f3 Time: 0.164718
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm72_trt_conv_act_pool Tactic: 0x97d50e90c139753e
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x97d50e90c139753e Time: 0.16779
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm80_trt_conv_act_pool_v3_tile_rows_4_tile_cols_116 Tactic: 0x7b00f0752fdcc88c
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x7b00f0752fdcc88c Time: 0.156965
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm80_trt_conv_act_pool_v3_tile_rows_8_tile_cols_120 Tactic: 0xb71c75095873646c
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xb71c75095873646c Time: 0.156087
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm80_trt_conv_act_pool_v3_tile_rows_8_tile_cols_116 Tactic: 0xc5730a6ceacd8913
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xc5730a6ceacd8913 Time: 0.144823
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm72_trt_conv_act_pool_v2_tile_rows_16_tile_cols_200 Tactic: 0x305b7b3ed6e970b3
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x305b7b3ed6e970b3 Time: 0.183735
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm80_trt_conv_act_pool_v3_tile_rows_4_tile_cols_124 Tactic: 0x72bf4c9462ed7bc0
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x72bf4c9462ed7bc0 Time: 0.148919
[08/20/2024-19:31:49] [V] [TRT] conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12 Set Tactic Name: sm72_trt_conv_act_pool_v2_tile_rows_16_tile_cols_240 Tactic: 0xf126325c0aa4aa02
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xf126325c0aa4aa02 Time: 0.154478
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x714758e16557c6ee Time: 0.127488
[08/20/2024-19:31:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ConvActPool Tactic: 0x0000000000000461
[08/20/2024-19:31:49] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 (CaskFlattenConvolution)
[08/20/2024-19:31:49] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 (CaskConvolution)
[08/20/2024-19:31:49] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 (CudaDepthwiseConvolution)
[08/20/2024-19:31:49] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 (FusedConvActConvolution)
[08/20/2024-19:31:49] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 (CaskFlattenConvolution)
[08/20/2024-19:31:49] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 (CaskConvolution)
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.193975
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.278674
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.178322
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.177445
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.295205
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0xcc3c5501ab7b5867
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xcc3c5501ab7b5867 Time: 0.185929
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0xe0658ca00f36ea3e
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xe0658ca00f36ea3e Time: 0.303397
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.192073
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.184174
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.176567
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0x1f0263042c683192 Time: 0.176567
[08/20/2024-19:31:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x1f0263042c683192
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 (CaskFlattenConvolution)
[08/20/2024-19:31:49] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 (CaskConvolution)
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 0x2cf0cc5b8a069ae7
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x2cf0cc5b8a069ae7 Time: 0.306469
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 0x0da8f7df8cfd2e37
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0da8f7df8cfd2e37 Time: 0.185344
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.191781
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.191634
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.176713
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.162816
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.294473
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.294912
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.188562
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.183735
[08/20/2024-19:31:49] [V] [TRT] Fastest Tactic: 0xeb494e2e67f079d4 Time: 0.162816
[08/20/2024-19:31:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xeb494e2e67f079d4
[08/20/2024-19:31:49] [V] [TRT] *************** Autotuning format combination: Int8(6272,3136:32,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 (CudaGroupConvolution)
[08/20/2024-19:31:49] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 (CudaDepthwiseConvolution)
[08/20/2024-19:31:49] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 (FusedConvActConvolution)
[08/20/2024-19:31:49] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 (CaskFlattenConvolution)
[08/20/2024-19:31:49] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:49] [V] [TRT] --------------- Timing Runner: layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 (CaskConvolution)
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xd3f592fae61c7986 Time: 0.138386
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x4cf18ad3e295ea18 Time: 0.169545
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.134656
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.136997
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x4805f65acfc5cf25 Time: 0.161792
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xef01fb6e433afa50 Time: 0.132901
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.194414
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x705baf38e41eee0b Time: 0.138094
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x70ccdad7e8ced9ab Time: 0.192439
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.138459
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.13707
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.135826
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.149358
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.140873
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.164571
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x60edc1e1753cd5b8 Time: 0.140946
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x53554c607d072468 Time: 0.135461
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.131657
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x2f34f689bfca5071 Time: 0.137143
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xf8d4389f60adfa3c Time: 0.147017
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xd30e9f770878c3fd Time: 0.144677
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x028e842ce51fbd9d Time: 0.139483
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x9d0f90e0cec890bb Time: 0.13429
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.140946
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xea88b51105501f96 Time: 0.148334
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.147602
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.138825
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.13824
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.14336
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.138971
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xf33711e7c9ed4673 Time: 0.136777
[08/20/2024-19:31:49] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[08/20/2024-19:31:49] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.139337
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.148773
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.154478
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x4749124f62d8bd23 Time: 0.135973
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xd9f3bbc3e16b16ac Time: 0.140654
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.124635
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.146286
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x9f6920f4a40549f4 Time: 0.148041
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.139995
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.136411
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xd3d41ef6de22d9b6 Time: 0.134949
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x19b79d0c4ff629da Time: 0.131291
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x9262f8f95beb428d Time: 0.132608
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.117248
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xbb88763c3b0e94d4 Time: 0.134071
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x4f6730716f78f4a3 Time: 0.134802
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.132462
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xd277f13d771603ee Time: 0.140361
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.132901
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x554e2e252e28b3fd Time: 0.183735
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xeb9516439d87ac23 Time: 0.151845
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.153161
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x671c943720ba8655 Time: 0.124635
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.127195
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.138825
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x8b2f6e180c235792 Time: 0.148187
[08/20/2024-19:31:50] [V] [TRT] Fastest Tactic: 0xf56c0ac895d82363 Time: 0.117248
[08/20/2024-19:31:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xf56c0ac895d82363
[08/20/2024-19:31:50] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:50] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136,56,1), Int8(200704,3136,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 (CaskFlattenConvolution)
[08/20/2024-19:31:50] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 (CaskConvolution)
[08/20/2024-19:31:50] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1), Int8(50176,3136:4,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 (CaskFlattenConvolution)
[08/20/2024-19:31:50] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 (CaskConvolution)
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.162377
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.202021
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.153893
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.161353
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.240786
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0xcc3c5501ab7b5867
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xcc3c5501ab7b5867 Time: 0.147895
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0xe0658ca00f36ea3e
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xe0658ca00f36ea3e Time: 0.223671
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.149504
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.156965
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.159305
[08/20/2024-19:31:50] [V] [TRT] Fastest Tactic: 0xcc3c5501ab7b5867 Time: 0.147895
[08/20/2024-19:31:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xcc3c5501ab7b5867
[08/20/2024-19:31:50] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1), Int8(6272,3136:32,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 (CaskFlattenConvolution)
[08/20/2024-19:31:50] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 (CaskConvolution)
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 0x2cf0cc5b8a069ae7
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x2cf0cc5b8a069ae7 Time: 0.223086
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 0x0da8f7df8cfd2e37
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x0da8f7df8cfd2e37 Time: 0.137289
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.160622
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.160183
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.121856
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.150967
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.227621
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.24064
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.190757
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.177591
[08/20/2024-19:31:50] [V] [TRT] Fastest Tactic: 0xf3f27c40da3380fe Time: 0.121856
[08/20/2024-19:31:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xf3f27c40da3380fe
[08/20/2024-19:31:50] [V] [TRT] *************** Autotuning format combination: Int8(6272,3136:32,56,1), Int8(6272,3136:32,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 (CaskFlattenConvolution)
[08/20/2024-19:31:50] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 (CaskConvolution)
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xd3f592fae61c7986 Time: 0.120613
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x4cf18ad3e295ea18 Time: 0.245175
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.120174
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.146578
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x4805f65acfc5cf25 Time: 0.138679
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xef01fb6e433afa50 Time: 0.133193
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.194267
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x705baf38e41eee0b Time: 0.181394
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x70ccdad7e8ced9ab Time: 0.116517
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.146286
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.116736
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.137801
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.14336
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.341138
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.170569
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x60edc1e1753cd5b8 Time: 0.150674
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x53554c607d072468 Time: 0.129902
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.117467
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x2f34f689bfca5071 Time: 0.142555
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xf8d4389f60adfa3c Time: 0.146432
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xd30e9f770878c3fd Time: 0.156379
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x028e842ce51fbd9d Time: 0.127927
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x9d0f90e0cec890bb Time: 0.102693
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.143506
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xea88b51105501f96 Time: 0.152576
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.145189
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.124709
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.13056
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.121125
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.131657
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xf33711e7c9ed4673 Time: 0.147749
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.122514
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.145627
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.165449
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x4749124f62d8bd23 Time: 0.118784
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xd9f3bbc3e16b16ac Time: 0.143653
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.13707
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.151406
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x9f6920f4a40549f4 Time: 0.145115
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.135753
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.112933
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xd3d41ef6de22d9b6 Time: 0.132754
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x19b79d0c4ff629da Time: 0.241445
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x9262f8f95beb428d Time: 0.225865
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.131218
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xbb88763c3b0e94d4 Time: 0.139776
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x4f6730716f78f4a3 Time: 0.125294
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.12917
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xd277f13d771603ee Time: 0.119662
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.109349
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x554e2e252e28b3fd Time: 0.167205
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xeb9516439d87ac23 Time: 0.116955
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.152869
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x671c943720ba8655 Time: 0.123538
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.121783
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.161061
[08/20/2024-19:31:50] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x8b2f6e180c235792 Time: 0.121051
[08/20/2024-19:31:50] [V] [TRT] Fastest Tactic: 0x9d0f90e0cec890bb Time: 0.102693
[08/20/2024-19:31:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9d0f90e0cec890bb
[08/20/2024-19:31:50] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:50] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer1.1.conv1.weight + QuantizeLinear_51 + Conv_53 (CaskFlattenConvolution)
[08/20/2024-19:31:50] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer1.1.conv1.weight + QuantizeLinear_51 + Conv_53 (CaskConvolution)
[08/20/2024-19:31:50] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:50] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:50] [V] [TRT] *************** Autotuning format combination: Int8(6272,3136:32,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:50] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:50] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136,56,1), Int8(200704,3136,56,1) -> Int8(200704,3136,56,1) ***************
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer1.1.conv2.weight + QuantizeLinear_63 + Conv_65 + Add_73 + Relu_74 (CaskFlattenConvolution)
[08/20/2024-19:31:50] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer1.1.conv2.weight + QuantizeLinear_63 + Conv_65 + Add_73 + Relu_74 (CaskConvolution)
[08/20/2024-19:31:50] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1), Int8(50176,3136:4,56,1) -> Int8(50176,3136:4,56,1) ***************
[08/20/2024-19:31:50] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1), Int8(6272,3136:32,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:50] [V] [TRT] *************** Autotuning format combination: Int8(6272,3136:32,56,1), Int8(6272,3136:32,56,1) -> Int8(6272,3136:32,56,1) ***************
[08/20/2024-19:31:50] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:50] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136,56,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 (CaskFlattenConvolution)
[08/20/2024-19:31:50] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 (CaskConvolution)
[08/20/2024-19:31:50] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 (CudaDepthwiseConvolution)
[08/20/2024-19:31:50] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 (FusedConvActConvolution)
[08/20/2024-19:31:50] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 (CaskFlattenConvolution)
[08/20/2024-19:31:50] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 (CaskConvolution)
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.154624
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.152137
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.199973
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.150967
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.144677
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0xcc3c5501ab7b5867
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xcc3c5501ab7b5867 Time: 0.158427
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0xe0658ca00f36ea3e
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xe0658ca00f36ea3e Time: 0.178761
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.160622
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.156672
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.151113
[08/20/2024-19:31:50] [V] [TRT] Fastest Tactic: 0xf6833cac33ebf690 Time: 0.144677
[08/20/2024-19:31:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xf6833cac33ebf690
[08/20/2024-19:31:50] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 (CaskFlattenConvolution)
[08/20/2024-19:31:50] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 (CaskConvolution)
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 0x2cf0cc5b8a069ae7
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x2cf0cc5b8a069ae7 Time: 0.143799
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 0x0da8f7df8cfd2e37
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x0da8f7df8cfd2e37 Time: 0.152137
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.164718
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.189586
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.132901
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.157696
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.177591
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.177152
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.188416
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.144896
[08/20/2024-19:31:50] [V] [TRT] Fastest Tactic: 0xf3f27c40da3380fe Time: 0.132901
[08/20/2024-19:31:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xf3f27c40da3380fe
[08/20/2024-19:31:50] [V] [TRT] *************** Autotuning format combination: Int8(6272,3136:32,56,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 (CudaGroupConvolution)
[08/20/2024-19:31:50] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 (CudaDepthwiseConvolution)
[08/20/2024-19:31:50] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 (FusedConvActConvolution)
[08/20/2024-19:31:50] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 (CaskFlattenConvolution)
[08/20/2024-19:31:50] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 (CaskConvolution)
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xd3f592fae61c7986 Time: 0.0899657
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x4cf18ad3e295ea18 Time: 0.146432
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.0556861
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.0554423
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x4805f65acfc5cf25 Time: 0.179639
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xef01fb6e433afa50 Time: 0.102034
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.153746
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x705baf38e41eee0b Time: 0.0359497
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x70ccdad7e8ced9ab Time: 0.0246735
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.147749
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.0372443
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.139849
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.129829
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.0531992
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.133266
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x60edc1e1753cd5b8 Time: 0.133339
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x53554c607d072468 Time: 0.116297
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.140288
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x2f34f689bfca5071 Time: 0.081408
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xf8d4389f60adfa3c Time: 0.147456
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xd30e9f770878c3fd Time: 0.02397
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x028e842ce51fbd9d Time: 0.13941
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x9d0f90e0cec890bb Time: 0.0803109
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.0887954
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xea88b51105501f96 Time: 0.117979
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.153161
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.137655
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.201728
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.0542232
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.0477379
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xf33711e7c9ed4673 Time: 0.0384731
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.125879
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.0529554
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.12917
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x4749124f62d8bd23 Time: 0.169253
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xd9f3bbc3e16b16ac Time: 0.0382903
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.0536137
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.150674
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x9f6920f4a40549f4 Time: 0.226597
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.206848
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.130048
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xd3d41ef6de22d9b6 Time: 0.223086
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x19b79d0c4ff629da Time: 0.139337
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x9262f8f95beb428d Time: 0.0427154
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.0543086
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xbb88763c3b0e94d4 Time: 0.210651
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x4f6730716f78f4a3 Time: 0.20875
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.0268678
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xd277f13d771603ee Time: 0.0549059
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.0598796
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x554e2e252e28b3fd Time: 0.146139
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xeb9516439d87ac23 Time: 0.139995
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.13685
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x671c943720ba8655 Time: 0.017213
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.137947
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.247515
[08/20/2024-19:31:50] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x8b2f6e180c235792 Time: 0.143799
[08/20/2024-19:31:50] [V] [TRT] Fastest Tactic: 0x671c943720ba8655 Time: 0.017213
[08/20/2024-19:31:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x671c943720ba8655
[08/20/2024-19:31:50] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:50] [V] [TRT] *************** Autotuning format combination: Int8(200704,3136,56,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 (CaskFlattenConvolution)
[08/20/2024-19:31:50] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 (CaskConvolution)
[08/20/2024-19:31:50] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 (CudaDepthwiseConvolution)
[08/20/2024-19:31:50] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 (FusedConvActConvolution)
[08/20/2024-19:31:50] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 (CaskFlattenConvolution)
[08/20/2024-19:31:50] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 (CaskConvolution)
[08/20/2024-19:31:50] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0x5801cac4d6968e8f
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x5801cac4d6968e8f Time: 0.115785
[08/20/2024-19:31:50] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.150674
[08/20/2024-19:31:50] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.0466651
[08/20/2024-19:31:50] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.0708511
[08/20/2024-19:31:50] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.0204251
[08/20/2024-19:31:50] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.0287451
[08/20/2024-19:31:50] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.0255025
[08/20/2024-19:31:50] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.116005
[08/20/2024-19:31:50] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x576df6f0e1a2ad08
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x576df6f0e1a2ad08 Time: 0.0322706
[08/20/2024-19:31:50] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xd1d72dad018b082d Time: 0.0718751
[08/20/2024-19:31:50] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x8a10449e6d8c189c Time: 0.0263071
[08/20/2024-19:31:50] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.165303
[08/20/2024-19:31:50] [V] [TRT] Fastest Tactic: 0x8846c5916f34f7e9 Time: 0.0204251
[08/20/2024-19:31:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8846c5916f34f7e9
[08/20/2024-19:31:50] [V] [TRT] *************** Autotuning format combination: Int8(50176,3136:4,56,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 (CaskFlattenConvolution)
[08/20/2024-19:31:50] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:50] [V] [TRT] --------------- Timing Runner: layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 (CaskConvolution)
[08/20/2024-19:31:50] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.0514438
[08/20/2024-19:31:50] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.021922
[08/20/2024-19:31:50] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_c32_nn_v1 Tactic: 0x27a2321ffe88b0d6
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0x27a2321ffe88b0d6 Time: 0.161792
[08/20/2024-19:31:50] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.0572952
[08/20/2024-19:31:50] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[08/20/2024-19:31:50] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.0365714
[08/20/2024-19:31:50] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x9fc2bcaa51428a78 Time: 0.0439954
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.0437394
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.161938
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x7a2c2a831965ff85 Time: 0.0400091
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.0314222
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.115712
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xc27fa49e07d992c2 Time: 0.0267378
[08/20/2024-19:31:51] [V] [TRT] Fastest Tactic: 0x320c30eda409da30 Time: 0.021922
[08/20/2024-19:31:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x320c30eda409da30
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(6272,3136:32,56,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 (CudaGroupConvolution)
[08/20/2024-19:31:51] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 (CudaDepthwiseConvolution)
[08/20/2024-19:31:51] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 (FusedConvActConvolution)
[08/20/2024-19:31:51] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 (CaskFlattenConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 (CaskConvolution)
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xdfdddae7a4bcc830 Time: 0.10123
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.0525653
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.0325339
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x932469cec5625217 Time: 0.0420571
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.0254537
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xa5a7024b355e2bbc Time: 0.0212846
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd9c6b8a2f7935fa5 Time: 0.0484937
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.0218175
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.0385829
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xfa5f2e15625aa266 Time: 0.0233221
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.0251611
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.0401554
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x5947ea3454b6a27b Time: 0.0494933
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.0401701
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.0330606
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x601b41d38fc4645b Time: 0.045056
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.0242416
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x79a4e52543793dbe Time: 0.037888
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x311b82feb19aef19 Time: 0.0287598
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.215625
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.0251368
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.0306907
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x881d70ee6f8bc650 Time: 0.0390949
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x6106e2811713d7ee Time: 0.0403017
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.0487497
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x18f10c3bd17f3940 Time: 0.0320366
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.05504
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.0284526
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x65920facc9ae819d Time: 0.0161402
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x7247cc5dea3981f1 Time: 0.0593432
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.03968
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xfac85bfa6e8a95c6 Time: 0.040704
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x596666386c88024b Time: 0.05632
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xcddae68de84cc6ee Time: 0.0531017
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.0430446
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xc6627e11680191d5 Time: 0.0627566
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.0480183
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x15fad4362e913239 Time: 0.0468114
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.0161727
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.0298715
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xea7e3523ffa8ae75 Time: 0.0722164
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.0243322
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.0404114
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x599d6bb582ecb830 Time: 0.0257672
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x53604f016bff6d61 Time: 0.0630491
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.028355
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.0642682
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.0194011
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x58e405fffd827823 Time: 0.0225698
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.0425326
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xc29602984551b4e8 Time: 0.0186368
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xed8f60f5aa2efd98 Time: 0.0547596
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.045312
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x179c6422445ceb76 Time: 0.0738743
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x01bc9ada86b72c5f Time: 0.0663162
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.050176
[08/20/2024-19:31:51] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.0222354
[08/20/2024-19:31:51] [V] [TRT] Fastest Tactic: 0x65920facc9ae819d Time: 0.0161402
[08/20/2024-19:31:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x65920facc9ae819d
[08/20/2024-19:31:51] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(100352,784,28,1), Int8(100352,784,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 (CaskFlattenConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 (CaskConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1), Int8(25088,784:4,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 (CaskFlattenConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 (CaskConvolution)
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.0776777
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.0878446
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.0661699
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.068803
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.0862354
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0xcc3c5501ab7b5867
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xcc3c5501ab7b5867 Time: 0.0584168
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0xe0658ca00f36ea3e
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xe0658ca00f36ea3e Time: 0.0891611
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.0628541
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0550034
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.0559299
[08/20/2024-19:31:51] [V] [TRT] Fastest Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0550034
[08/20/2024-19:31:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1), Int8(3136,784:32,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 (CaskFlattenConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 (CaskConvolution)
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 0x2cf0cc5b8a069ae7
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x2cf0cc5b8a069ae7 Time: 0.0897463
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 0x0da8f7df8cfd2e37
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x0da8f7df8cfd2e37 Time: 0.058563
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.0689493
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.0630979
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.056125
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.077824
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.0884297
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.0868937
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.0659749
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.0549059
[08/20/2024-19:31:51] [V] [TRT] Fastest Tactic: 0xc911b61f7a5c0315 Time: 0.0549059
[08/20/2024-19:31:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(3136,784:32,28,1), Int8(3136,784:32,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 (CaskFlattenConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 (CaskConvolution)
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd3f592fae61c7986 Time: 0.0196023
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4cf18ad3e295ea18 Time: 0.0373029
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.0167416
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.0209607
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4805f65acfc5cf25 Time: 0.0681204
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xef01fb6e433afa50 Time: 0.0228833
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.047933
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x705baf38e41eee0b Time: 0.01856
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x70ccdad7e8ced9ab Time: 0.0152283
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.0383634
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.016514
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.0291694
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.0285842
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.0229042
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.037888
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x60edc1e1753cd5b8 Time: 0.0377783
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x53554c607d072468 Time: 0.0189989
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.0384366
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x2f34f689bfca5071 Time: 0.0208353
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xf8d4389f60adfa3c Time: 0.0480792
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd30e9f770878c3fd Time: 0.0175218
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x028e842ce51fbd9d Time: 0.0290816
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x9d0f90e0cec890bb Time: 0.0262583
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.0231549
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xea88b51105501f96 Time: 0.0284038
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.0489569
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.027331
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.0229669
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.0229042
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.0190354
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xf33711e7c9ed4673 Time: 0.0226325
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.0210651
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.0226116
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.0314807
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4749124f62d8bd23 Time: 0.0196937
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd9f3bbc3e16b16ac Time: 0.0378149
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.0234684
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.0757029
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x9f6920f4a40549f4 Time: 0.0223399
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.019584
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.0223399
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd3d41ef6de22d9b6 Time: 0.0287013
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x19b79d0c4ff629da Time: 0.0265752
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x9262f8f95beb428d Time: 0.0164978
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.0191634
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xbb88763c3b0e94d4 Time: 0.0179749
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4f6730716f78f4a3 Time: 0.0224862
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.0158964
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd277f13d771603ee Time: 0.0225489
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.0199314
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x554e2e252e28b3fd Time: 0.0474331
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xeb9516439d87ac23 Time: 0.0302811
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.0379246
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x671c943720ba8655 Time: 0.0156087
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.0275749
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.0296082
[08/20/2024-19:31:51] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x8b2f6e180c235792 Time: 0.0372663
[08/20/2024-19:31:51] [V] [TRT] Fastest Tactic: 0x70ccdad7e8ced9ab Time: 0.0152283
[08/20/2024-19:31:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x70ccdad7e8ced9ab
[08/20/2024-19:31:51] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(100352,784,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 (CaskFlattenConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 (CaskConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 (CudaDepthwiseConvolution)
[08/20/2024-19:31:51] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 (FusedConvActConvolution)
[08/20/2024-19:31:51] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 (CaskFlattenConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 (CaskConvolution)
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.075264
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.0852846
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.0636343
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.0664137
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.0584168
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0xcc3c5501ab7b5867
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xcc3c5501ab7b5867 Time: 0.0389851
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0xe0658ca00f36ea3e
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xe0658ca00f36ea3e Time: 0.0603185
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.04224
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0368274
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.0373394
[08/20/2024-19:31:51] [V] [TRT] Fastest Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0368274
[08/20/2024-19:31:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 (CaskFlattenConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 (CaskConvolution)
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 0x2cf0cc5b8a069ae7
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x2cf0cc5b8a069ae7 Time: 0.0603672
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 0x0da8f7df8cfd2e37
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x0da8f7df8cfd2e37 Time: 0.0389486
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.0461166
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.0419863
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.0373029
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.0522728
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.0594408
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.0585143
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.0444709
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.036608
[08/20/2024-19:31:51] [V] [TRT] Fastest Tactic: 0xc911b61f7a5c0315 Time: 0.036608
[08/20/2024-19:31:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(3136,784:32,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 (CudaGroupConvolution)
[08/20/2024-19:31:51] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 (CudaDepthwiseConvolution)
[08/20/2024-19:31:51] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 (FusedConvActConvolution)
[08/20/2024-19:31:51] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 (CaskFlattenConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 (CaskConvolution)
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd3f592fae61c7986 Time: 0.0136711
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4cf18ad3e295ea18 Time: 0.025405
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.016514
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.012544
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4805f65acfc5cf25 Time: 0.0445074
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xef01fb6e433afa50 Time: 0.0153605
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.0325632
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x705baf38e41eee0b Time: 0.0126781
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x70ccdad7e8ced9ab Time: 0.0114553
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.0260145
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.0119227
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.0194194
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.0189257
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.0154331
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.0257707
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x60edc1e1753cd5b8 Time: 0.0255756
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x53554c607d072468 Time: 0.0124933
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.0258682
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x2f34f689bfca5071 Time: 0.0142562
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xf8d4389f60adfa3c Time: 0.0323584
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd30e9f770878c3fd Time: 0.0124587
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x028e842ce51fbd9d Time: 0.0184869
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x9d0f90e0cec890bb Time: 0.0154478
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.0155941
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xea88b51105501f96 Time: 0.0186697
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.0328558
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.0188891
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.0154478
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.0154185
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.0132189
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xf33711e7c9ed4673 Time: 0.0157989
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.0145262
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.0153893
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.0209607
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4749124f62d8bd23 Time: 0.0142961
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd9f3bbc3e16b16ac Time: 0.0254293
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.0157111
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.0494446
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x9f6920f4a40549f4 Time: 0.0150976
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.013489
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.0152567
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd3d41ef6de22d9b6 Time: 0.0188709
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x19b79d0c4ff629da Time: 0.0183771
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x9262f8f95beb428d Time: 0.0118041
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.0134986
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xbb88763c3b0e94d4 Time: 0.0130593
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4f6730716f78f4a3 Time: 0.0152137
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.0119383
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd277f13d771603ee Time: 0.0151698
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.0139104
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x554e2e252e28b3fd Time: 0.0321536
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xeb9516439d87ac23 Time: 0.0202606
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.025795
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x671c943720ba8655 Time: 0.0123594
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.0191451
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.0196206
[08/20/2024-19:31:51] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x8b2f6e180c235792 Time: 0.0253318
[08/20/2024-19:31:51] [V] [TRT] Fastest Tactic: 0x70ccdad7e8ced9ab Time: 0.0114553
[08/20/2024-19:31:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x70ccdad7e8ced9ab
[08/20/2024-19:31:51] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(100352,784,28,1), Int8(100352,784,28,1) -> Int8(100352,784,28,1) ***************
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.1.conv2.weight + QuantizeLinear_136 + Conv_138 + Add_146 + Relu_147 (CaskFlattenConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer2.1.conv2.weight + QuantizeLinear_136 + Conv_138 + Add_146 + Relu_147 (CaskConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1), Int8(25088,784:4,28,1) -> Int8(25088,784:4,28,1) ***************
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1), Int8(3136,784:32,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(3136,784:32,28,1), Int8(3136,784:32,28,1) -> Int8(3136,784:32,28,1) ***************
[08/20/2024-19:31:51] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(100352,784,28,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 (CaskFlattenConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 (CaskConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 (CudaDepthwiseConvolution)
[08/20/2024-19:31:51] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 (FusedConvActConvolution)
[08/20/2024-19:31:51] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 (CaskFlattenConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 (CaskConvolution)
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.0493958
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.058563
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.0423863
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.0455314
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.058563
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0xcc3c5501ab7b5867
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xcc3c5501ab7b5867 Time: 0.0385829
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0xe0658ca00f36ea3e
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xe0658ca00f36ea3e Time: 0.0598796
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.04096
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0356645
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.0372663
[08/20/2024-19:31:51] [V] [TRT] Fastest Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0356645
[08/20/2024-19:31:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 (CaskFlattenConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 (CaskConvolution)
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 0x2cf0cc5b8a069ae7
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x2cf0cc5b8a069ae7 Time: 0.0508099
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 0x0da8f7df8cfd2e37
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x0da8f7df8cfd2e37 Time: 0.0310418
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.036864
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.0330331
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.0300178
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.0399726
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.0472857
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.0471806
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.0342309
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.0286729
[08/20/2024-19:31:51] [V] [TRT] Fastest Tactic: 0xc911b61f7a5c0315 Time: 0.0286729
[08/20/2024-19:31:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(3136,784:32,28,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 (CudaGroupConvolution)
[08/20/2024-19:31:51] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 (CudaDepthwiseConvolution)
[08/20/2024-19:31:51] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 (FusedConvActConvolution)
[08/20/2024-19:31:51] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 (CaskFlattenConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 (CaskConvolution)
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd3f592fae61c7986 Time: 0.00977036
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4cf18ad3e295ea18 Time: 0.0207954
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.0103886
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.0104594
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4805f65acfc5cf25 Time: 0.0512975
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xef01fb6e433afa50 Time: 0.0129116
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.0264038
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x705baf38e41eee0b Time: 0.0107938
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x70ccdad7e8ced9ab Time: 0.00934457
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.0211487
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.00895086
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.0181766
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.0155077
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.0125432
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.0209398
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x60edc1e1753cd5b8 Time: 0.0208562
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x53554c607d072468 Time: 0.0114103
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.0210913
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x2f34f689bfca5071 Time: 0.00843482
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xf8d4389f60adfa3c Time: 0.026429
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd30e9f770878c3fd Time: 0.0102514
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x028e842ce51fbd9d Time: 0.0100742
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x9d0f90e0cec890bb Time: 0.0126659
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.0131649
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xea88b51105501f96 Time: 0.0152699
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.0267703
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.0102397
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.0132189
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.0130061
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.0115003
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xf33711e7c9ed4673 Time: 0.0126415
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.0154048
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.0132987
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.0178834
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4749124f62d8bd23 Time: 0.00802997
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd9f3bbc3e16b16ac Time: 0.0208562
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.012861
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.0510537
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x9f6920f4a40549f4 Time: 0.0123855
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.0110934
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.00875267
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd3d41ef6de22d9b6 Time: 0.018268
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x19b79d0c4ff629da Time: 0.0100849
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x9262f8f95beb428d Time: 0.00914286
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.0105806
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xbb88763c3b0e94d4 Time: 0.00802057
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4f6730716f78f4a3 Time: 0.0125227
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.00890622
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd277f13d771603ee Time: 0.0130072
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.00866286
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x554e2e252e28b3fd Time: 0.0261851
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xeb9516439d87ac23 Time: 0.0174908
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.0209398
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x671c943720ba8655 Time: 0.00910628
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.00986606
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.0160914
[08/20/2024-19:31:51] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x8b2f6e180c235792 Time: 0.0207314
[08/20/2024-19:31:51] [V] [TRT] Fastest Tactic: 0xbb88763c3b0e94d4 Time: 0.00802057
[08/20/2024-19:31:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xbb88763c3b0e94d4
[08/20/2024-19:31:51] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(100352,784,28,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 (CaskFlattenConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 (CaskConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 (CudaDepthwiseConvolution)
[08/20/2024-19:31:51] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 (FusedConvActConvolution)
[08/20/2024-19:31:51] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 (CaskFlattenConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 (CaskConvolution)
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0x5801cac4d6968e8f
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x5801cac4d6968e8f Time: 0.00859644
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.00977189
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.0119722
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.00924314
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.00932571
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.0119714
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.00870212
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.00783687
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x576df6f0e1a2ad08
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x576df6f0e1a2ad08 Time: 0.00957318
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd1d72dad018b082d Time: 0.00813511
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x8a10449e6d8c189c Time: 0.00828927
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.00902486
[08/20/2024-19:31:51] [V] [TRT] Fastest Tactic: 0x9aa46c15c2a1d8a7 Time: 0.00783687
[08/20/2024-19:31:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(25088,784:4,28,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 (CaskFlattenConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 (CaskConvolution)
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.00775771
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.0140443
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_c32_nn_v1 Tactic: 0x27a2321ffe88b0d6
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x27a2321ffe88b0d6 Time: 0.019352
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.0177051
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.0155209
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x9fc2bcaa51428a78 Time: 0.015557
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.0156119
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.0149248
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x7a2c2a831965ff85 Time: 0.0080094
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.00825727
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.00714789
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xc27fa49e07d992c2 Time: 0.00906114
[08/20/2024-19:31:51] [V] [TRT] Fastest Tactic: 0xc911b61f7a5c0315 Time: 0.00714789
[08/20/2024-19:31:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:51] [V] [TRT] *************** Autotuning format combination: Int8(3136,784:32,28,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 (CudaGroupConvolution)
[08/20/2024-19:31:51] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 (CudaDepthwiseConvolution)
[08/20/2024-19:31:51] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 (FusedConvActConvolution)
[08/20/2024-19:31:51] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 (CaskFlattenConvolution)
[08/20/2024-19:31:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:51] [V] [TRT] --------------- Timing Runner: layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 (CaskConvolution)
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xdfdddae7a4bcc830 Time: 0.00798051
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.00629029
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.00581723
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x932469cec5625217 Time: 0.00518465
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.00727977
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xa5a7024b355e2bbc Time: 0.00557521
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xd9c6b8a2f7935fa5 Time: 0.0062408
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.00842676
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.0100904
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0xfa5f2e15625aa266 Time: 0.00807238
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.00680729
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.00535484
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x5947ea3454b6a27b Time: 0.00723135
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.00582506
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.00758256
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x601b41d38fc4645b Time: 0.00651948
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.00713556
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x79a4e52543793dbe Time: 0.0122954
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x311b82feb19aef19 Time: 0.00567719
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.00886158
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.00968343
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.00580389
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x881d70ee6f8bc650 Time: 0.00514869
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x6106e2811713d7ee Time: 0.00593664
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[08/20/2024-19:31:51] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.00582235
[08/20/2024-19:31:51] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x18f10c3bd17f3940 Time: 0.00617791
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.00772526
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.00575525
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x65920facc9ae819d Time: 0.00607181
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x7247cc5dea3981f1 Time: 0.00814095
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.00544762
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xfac85bfa6e8a95c6 Time: 0.00680642
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x596666386c88024b Time: 0.00620838
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xcddae68de84cc6ee Time: 0.00880618
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.00654504
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xc6627e11680191d5 Time: 0.00781426
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.00700539
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x15fad4362e913239 Time: 0.0063998
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.00574752
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.00870938
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xea7e3523ffa8ae75 Time: 0.00856981
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.00563165
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.0102691
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x599d6bb582ecb830 Time: 0.00612838
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x53604f016bff6d61 Time: 0.00978429
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.00602133
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.00579365
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.00639384
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x58e405fffd827823 Time: 0.00552563
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.00581797
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xc29602984551b4e8 Time: 0.00721714
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xed8f60f5aa2efd98 Time: 0.00558681
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.00833473
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x179c6422445ceb76 Time: 0.00554497
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x01bc9ada86b72c5f Time: 0.0136072
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.00572672
[08/20/2024-19:31:52] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.0071632
[08/20/2024-19:31:52] [V] [TRT] Fastest Tactic: 0x881d70ee6f8bc650 Time: 0.00514869
[08/20/2024-19:31:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x881d70ee6f8bc650
[08/20/2024-19:31:52] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:52] [V] [TRT] *************** Autotuning format combination: Int8(50176,196,14,1), Int8(50176,196,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 (CaskFlattenConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 (CaskConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1), Int8(12544,196:4,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 (CaskFlattenConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 (CaskConvolution)
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.0642194
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.072704
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.0544213
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.05632
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.0715429
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0xcc3c5501ab7b5867
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xcc3c5501ab7b5867 Time: 0.0476404
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0xe0658ca00f36ea3e
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xe0658ca00f36ea3e Time: 0.0738743
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.0517379
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0429691
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.0449097
[08/20/2024-19:31:52] [V] [TRT] Fastest Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0429691
[08/20/2024-19:31:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:52] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1), Int8(1568,196:32,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 (CaskFlattenConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 (CaskConvolution)
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 0x2cf0cc5b8a069ae7
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x2cf0cc5b8a069ae7 Time: 0.0743131
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 0x0da8f7df8cfd2e37
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x0da8f7df8cfd2e37 Time: 0.0477867
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.05632
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.0519314
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.045056
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.0640731
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.0731429
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.0719726
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.0544259
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.0426057
[08/20/2024-19:31:52] [V] [TRT] Fastest Tactic: 0xc911b61f7a5c0315 Time: 0.0426057
[08/20/2024-19:31:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:52] [V] [TRT] *************** Autotuning format combination: Int8(1568,196:32,14,1), Int8(1568,196:32,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 (CaskFlattenConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 (CaskConvolution)
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd3f592fae61c7986 Time: 0.0107406
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x4cf18ad3e295ea18 Time: 0.0293449
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.0111434
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.0140717
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x4805f65acfc5cf25 Time: 0.0482758
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xef01fb6e433afa50 Time: 0.0167416
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.0381074
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x705baf38e41eee0b Time: 0.0139636
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x70ccdad7e8ced9ab Time: 0.0109192
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.0313929
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.0120133
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.021442
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.0238773
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.0166603
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.029579
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x60edc1e1753cd5b8 Time: 0.0292334
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x53554c607d072468 Time: 0.0139902
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.0295817
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x2f34f689bfca5071 Time: 0.0103967
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xf8d4389f60adfa3c Time: 0.0378571
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd30e9f770878c3fd Time: 0.0124952
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x028e842ce51fbd9d Time: 0.0125074
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x9d0f90e0cec890bb Time: 0.016384
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.0169539
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xea88b51105501f96 Time: 0.0209816
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.0381806
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.0128975
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.0167274
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.0166466
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.0130061
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xf33711e7c9ed4673 Time: 0.0165943
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.00968594
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.0166766
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.0251421
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x4749124f62d8bd23 Time: 0.0099072
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd9f3bbc3e16b16ac Time: 0.0292599
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.0169016
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.0545158
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x9f6920f4a40549f4 Time: 0.0165298
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.0134317
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.00953783
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd3d41ef6de22d9b6 Time: 0.0210651
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x19b79d0c4ff629da Time: 0.012067
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x9262f8f95beb428d Time: 0.0119714
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.0101925
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xbb88763c3b0e94d4 Time: 0.0103677
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x4f6730716f78f4a3 Time: 0.0164328
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.0112088
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd277f13d771603ee Time: 0.016546
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.0106348
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x554e2e252e28b3fd Time: 0.037816
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xeb9516439d87ac23 Time: 0.0233639
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.0295497
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x671c943720ba8655 Time: 0.011084
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.0121051
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.0221309
[08/20/2024-19:31:52] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x8b2f6e180c235792 Time: 0.0292864
[08/20/2024-19:31:52] [V] [TRT] Fastest Tactic: 0x955d593b1135a423 Time: 0.00953783
[08/20/2024-19:31:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x955d593b1135a423
[08/20/2024-19:31:52] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:52] [V] [TRT] *************** Autotuning format combination: Int8(50176,196,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 (CaskFlattenConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 (CaskConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 (CudaDepthwiseConvolution)
[08/20/2024-19:31:52] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 (FusedConvActConvolution)
[08/20/2024-19:31:52] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 (CaskFlattenConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 (CaskConvolution)
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.0578804
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.0863086
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.0490088
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.0507611
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.0645653
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0xcc3c5501ab7b5867
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xcc3c5501ab7b5867 Time: 0.0427154
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0xe0658ca00f36ea3e
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xe0658ca00f36ea3e Time: 0.0667642
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.0465257
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0382903
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.040632
[08/20/2024-19:31:52] [V] [TRT] Fastest Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0382903
[08/20/2024-19:31:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:52] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 (CaskFlattenConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 (CaskConvolution)
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 0x2cf0cc5b8a069ae7
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x2cf0cc5b8a069ae7 Time: 0.0668526
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 0x0da8f7df8cfd2e37
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x0da8f7df8cfd2e37 Time: 0.0426789
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.0507611
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.0464126
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.0401189
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.0579291
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.065731
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.0646613
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.0489097
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.0381074
[08/20/2024-19:31:52] [V] [TRT] Fastest Tactic: 0xc911b61f7a5c0315 Time: 0.0381074
[08/20/2024-19:31:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:52] [V] [TRT] *************** Autotuning format combination: Int8(1568,196:32,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 (CudaGroupConvolution)
[08/20/2024-19:31:52] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 (CudaDepthwiseConvolution)
[08/20/2024-19:31:52] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 (FusedConvActConvolution)
[08/20/2024-19:31:52] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 (CaskFlattenConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 (CaskConvolution)
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd3f592fae61c7986 Time: 0.00923486
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x4cf18ad3e295ea18 Time: 0.0264046
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.0101848
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.0119044
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x4805f65acfc5cf25 Time: 0.0429714
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xef01fb6e433afa50 Time: 0.014965
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.0340553
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x705baf38e41eee0b Time: 0.013125
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x70ccdad7e8ced9ab Time: 0.0101544
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.026624
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.0107876
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.0191817
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.0188343
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.0153769
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.0265097
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x60edc1e1753cd5b8 Time: 0.0263558
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x53554c607d072468 Time: 0.0122735
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.0265752
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x2f34f689bfca5071 Time: 0.00811048
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xf8d4389f60adfa3c Time: 0.0339721
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd30e9f770878c3fd Time: 0.0131086
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x028e842ce51fbd9d Time: 0.0125208
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x9d0f90e0cec890bb Time: 0.0147163
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.0150555
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xea88b51105501f96 Time: 0.0186514
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.0342894
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.0120855
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.0149211
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.0149248
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.0118604
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xf33711e7c9ed4673 Time: 0.0148059
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.00906971
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.0149504
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.0223817
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x4749124f62d8bd23 Time: 0.00887288
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd9f3bbc3e16b16ac Time: 0.0262865
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.0151136
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.0483261
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x9f6920f4a40549f4 Time: 0.014848
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.0126309
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.00880457
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd3d41ef6de22d9b6 Time: 0.0198251
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x19b79d0c4ff629da Time: 0.0105048
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x9262f8f95beb428d Time: 0.0098813
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.00997516
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xbb88763c3b0e94d4 Time: 0.00843294
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x4f6730716f78f4a3 Time: 0.0162052
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.00995627
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd277f13d771603ee Time: 0.014848
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.00869217
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x554e2e252e28b3fd Time: 0.0339154
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xeb9516439d87ac23 Time: 0.0205656
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.0265265
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x671c943720ba8655 Time: 0.00950314
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.0116916
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.0197514
[08/20/2024-19:31:52] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x8b2f6e180c235792 Time: 0.0263802
[08/20/2024-19:31:52] [V] [TRT] Fastest Tactic: 0x2f34f689bfca5071 Time: 0.00811048
[08/20/2024-19:31:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x2f34f689bfca5071
[08/20/2024-19:31:52] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:52] [V] [TRT] *************** Autotuning format combination: Int8(50176,196,14,1), Int8(50176,196,14,1) -> Int8(50176,196,14,1) ***************
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.1.conv2.weight + QuantizeLinear_209 + Conv_211 + Add_219 + Relu_220 (CaskFlattenConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer3.1.conv2.weight + QuantizeLinear_209 + Conv_211 + Add_219 + Relu_220 (CaskConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1), Int8(12544,196:4,14,1) -> Int8(12544,196:4,14,1) ***************
[08/20/2024-19:31:52] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1), Int8(1568,196:32,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:52] [V] [TRT] *************** Autotuning format combination: Int8(1568,196:32,14,1), Int8(1568,196:32,14,1) -> Int8(1568,196:32,14,1) ***************
[08/20/2024-19:31:52] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:52] [V] [TRT] *************** Autotuning format combination: Int8(50176,196,14,1) -> Int8(25088,49,7,1) ***************
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 (CaskFlattenConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 (CaskConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1) -> Int8(6272,49:4,7,1) ***************
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 (CudaDepthwiseConvolution)
[08/20/2024-19:31:52] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 (FusedConvActConvolution)
[08/20/2024-19:31:52] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 (CaskFlattenConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 (CaskConvolution)
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.054467
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.0639269
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.045968
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.0504686
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.0647665
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0xcc3c5501ab7b5867
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xcc3c5501ab7b5867 Time: 0.0414046
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0xe0658ca00f36ea3e
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xe0658ca00f36ea3e Time: 0.0659291
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.0439223
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0383291
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.0402343
[08/20/2024-19:31:52] [V] [TRT] Fastest Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0383291
[08/20/2024-19:31:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:52] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 (CaskFlattenConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 (CaskConvolution)
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 0x2cf0cc5b8a069ae7
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x2cf0cc5b8a069ae7 Time: 0.0657829
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 0x0da8f7df8cfd2e37
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x0da8f7df8cfd2e37 Time: 0.0413989
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.0503223
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.043776
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.0401554
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.0544183
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.0637318
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.0646583
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.045824
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.0382903
[08/20/2024-19:31:52] [V] [TRT] Fastest Tactic: 0xc911b61f7a5c0315 Time: 0.0382903
[08/20/2024-19:31:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:52] [V] [TRT] *************** Autotuning format combination: Int8(1568,196:32,14,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 (CudaGroupConvolution)
[08/20/2024-19:31:52] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 (CudaDepthwiseConvolution)
[08/20/2024-19:31:52] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 (FusedConvActConvolution)
[08/20/2024-19:31:52] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 (CaskFlattenConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 (CaskConvolution)
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd3f592fae61c7986 Time: 0.00852394
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x4cf18ad3e295ea18 Time: 0.0265021
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.0105349
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.0115903
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x4805f65acfc5cf25 Time: 0.0437029
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xef01fb6e433afa50 Time: 0.0149829
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.0342071
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x705baf38e41eee0b Time: 0.0125562
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x70ccdad7e8ced9ab Time: 0.010574
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.0267032
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.0111395
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.0193297
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.0189806
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.0149216
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.0265752
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x60edc1e1753cd5b8 Time: 0.026749
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x53554c607d072468 Time: 0.0121223
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.0266469
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x2f34f689bfca5071 Time: 0.00847032
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xf8d4389f60adfa3c Time: 0.0341723
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd30e9f770878c3fd Time: 0.0120492
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x028e842ce51fbd9d Time: 0.0117029
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x9d0f90e0cec890bb Time: 0.0148073
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.0151406
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xea88b51105501f96 Time: 0.0187423
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.0344649
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.0121295
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.0149943
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.0149504
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.0115228
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xf33711e7c9ed4673 Time: 0.0151991
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.00760253
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.0151849
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.0215876
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x4749124f62d8bd23 Time: 0.0071616
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd9f3bbc3e16b16ac Time: 0.0263802
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.0152137
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.0484206
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x9f6920f4a40549f4 Time: 0.0148626
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.0130701
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.00829638
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd3d41ef6de22d9b6 Time: 0.0189806
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x19b79d0c4ff629da Time: 0.0113213
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x9262f8f95beb428d Time: 0.0104699
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.00928914
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xbb88763c3b0e94d4 Time: 0.00850178
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x4f6730716f78f4a3 Time: 0.0148553
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.00993554
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd277f13d771603ee Time: 0.0148827
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.00826895
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x554e2e252e28b3fd Time: 0.0340315
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xeb9516439d87ac23 Time: 0.0206269
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.026624
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x671c943720ba8655 Time: 0.0101041
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.0131516
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.02028
[08/20/2024-19:31:52] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x8b2f6e180c235792 Time: 0.0264571
[08/20/2024-19:31:52] [V] [TRT] Fastest Tactic: 0x4749124f62d8bd23 Time: 0.0071616
[08/20/2024-19:31:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x4749124f62d8bd23
[08/20/2024-19:31:52] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:52] [V] [TRT] *************** Autotuning format combination: Int8(50176,196,14,1) -> Int8(25088,49,7,1) ***************
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 (CaskFlattenConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 (CaskConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1) -> Int8(6272,49:4,7,1) ***************
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 (CudaDepthwiseConvolution)
[08/20/2024-19:31:52] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 (FusedConvActConvolution)
[08/20/2024-19:31:52] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 (CaskFlattenConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 (CaskConvolution)
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0x5801cac4d6968e8f
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x5801cac4d6968e8f Time: 0.00846171
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.0107118
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.0113445
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.0088355
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.00991055
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.012069
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.00881452
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.00854239
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x576df6f0e1a2ad08
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x576df6f0e1a2ad08 Time: 0.0120442
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xd1d72dad018b082d
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd1d72dad018b082d Time: 0.00941572
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0x8a10449e6d8c189c
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x8a10449e6d8c189c Time: 0.00908686
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.00883953
[08/20/2024-19:31:52] [V] [TRT] Fastest Tactic: 0x5801cac4d6968e8f Time: 0.00846171
[08/20/2024-19:31:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x5801cac4d6968e8f
[08/20/2024-19:31:52] [V] [TRT] *************** Autotuning format combination: Int8(12544,196:4,14,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 (CaskFlattenConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 (CaskConvolution)
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.0165298
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.0167253
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_c32_nn_v1 Tactic: 0x27a2321ffe88b0d6
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x27a2321ffe88b0d6 Time: 0.0173257
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.0143653
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.0166847
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: 0x9fc2bcaa51428a78
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x9fc2bcaa51428a78 Time: 0.0135647
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.018176
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.012544
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 0x7a2c2a831965ff85
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x7a2c2a831965ff85 Time: 0.008998
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.00878575
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.00819429
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: 0xc27fa49e07d992c2
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xc27fa49e07d992c2 Time: 0.00826514
[08/20/2024-19:31:52] [V] [TRT] Fastest Tactic: 0xc911b61f7a5c0315 Time: 0.00819429
[08/20/2024-19:31:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:52] [V] [TRT] *************** Autotuning format combination: Int8(1568,196:32,14,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 (CudaGroupConvolution)
[08/20/2024-19:31:52] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 (CudaDepthwiseConvolution)
[08/20/2024-19:31:52] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 (FusedConvActConvolution)
[08/20/2024-19:31:52] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 (CaskFlattenConvolution)
[08/20/2024-19:31:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:52] [V] [TRT] --------------- Timing Runner: layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 (CaskConvolution)
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdfdddae7a4bcc830
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xdfdddae7a4bcc830 Time: 0.0175944
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.0148041
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.015141
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x932469cec5625217
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x932469cec5625217 Time: 0.0141349
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.0132064
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa5a7024b355e2bbc
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xa5a7024b355e2bbc Time: 0.00489356
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xd9c6b8a2f7935fa5
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xd9c6b8a2f7935fa5 Time: 0.00574025
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[08/20/2024-19:31:52] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.00735292
[08/20/2024-19:31:52] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.00581632
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfa5f2e15625aa266
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xfa5f2e15625aa266 Time: 0.00582583
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.00765883
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.00834159
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5947ea3454b6a27b
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x5947ea3454b6a27b Time: 0.00692223
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.00660472
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.0080166
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x601b41d38fc4645b
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x601b41d38fc4645b Time: 0.00759507
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.00715292
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x79a4e52543793dbe
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x79a4e52543793dbe Time: 0.006004
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x311b82feb19aef19
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x311b82feb19aef19 Time: 0.00587447
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.00688561
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.0086279
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.00553248
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x881d70ee6f8bc650 Time: 0.00555921
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x6106e2811713d7ee
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x6106e2811713d7ee Time: 0.00779669
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.00622267
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x18f10c3bd17f3940
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x18f10c3bd17f3940 Time: 0.00553442
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.00571974
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.00633779
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x65920facc9ae819d Time: 0.00643757
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x7247cc5dea3981f1
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x7247cc5dea3981f1 Time: 0.00936114
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.0120743
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xfac85bfa6e8a95c6
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xfac85bfa6e8a95c6 Time: 0.00535907
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x596666386c88024b
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x596666386c88024b Time: 0.00554057
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcddae68de84cc6ee
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xcddae68de84cc6ee Time: 0.00854669
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.00656852
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc6627e11680191d5
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xc6627e11680191d5 Time: 0.00762827
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.00681491
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x15fad4362e913239
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x15fad4362e913239 Time: 0.00671169
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.00687086
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.0146898
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xea7e3523ffa8ae75
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xea7e3523ffa8ae75 Time: 0.00775603
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.00623962
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.00423166
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x599d6bb582ecb830
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x599d6bb582ecb830 Time: 0.00516963
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x53604f016bff6d61
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x53604f016bff6d61 Time: 0.00876827
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.00963444
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc5f4c4b3e5ec8f6e
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xc5f4c4b3e5ec8f6e Time: 0.0058763
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.00785901
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x58e405fffd827823
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x58e405fffd827823 Time: 0.00687543
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.00935486
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xc29602984551b4e8
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xc29602984551b4e8 Time: 0.00845741
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xed8f60f5aa2efd98
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xed8f60f5aa2efd98 Time: 0.00490728
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.0075455
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x179c6422445ceb76
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x179c6422445ceb76 Time: 0.00577719
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x01bc9ada86b72c5f
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x01bc9ada86b72c5f Time: 0.0119996
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.00909314
[08/20/2024-19:31:53] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.00755994
[08/20/2024-19:31:53] [V] [TRT] Fastest Tactic: 0x955d593b1135a423 Time: 0.00423166
[08/20/2024-19:31:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x955d593b1135a423
[08/20/2024-19:31:53] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:53] [V] [TRT] *************** Autotuning format combination: Int8(25088,49,7,1), Int8(25088,49,7,1) -> Int8(25088,49,7,1) ***************
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 (CaskFlattenConvolution)
[08/20/2024-19:31:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 (CaskConvolution)
[08/20/2024-19:31:53] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:53] [V] [TRT] *************** Autotuning format combination: Int8(6272,49:4,7,1), Int8(6272,49:4,7,1) -> Int8(6272,49:4,7,1) ***************
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 (CaskFlattenConvolution)
[08/20/2024-19:31:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 (CaskConvolution)
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.112201
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.127854
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.0969989
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.0953943
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.125952
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0xcc3c5501ab7b5867
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xcc3c5501ab7b5867 Time: 0.0846263
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0xe0658ca00f36ea3e
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xe0658ca00f36ea3e Time: 0.130341
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.0887223
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0732891
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.0773851
[08/20/2024-19:31:53] [V] [TRT] Fastest Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0732891
[08/20/2024-19:31:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:53] [V] [TRT] *************** Autotuning format combination: Int8(6272,49:4,7,1), Int8(784,49:32,7,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 (CaskFlattenConvolution)
[08/20/2024-19:31:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 (CaskConvolution)
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 0x2cf0cc5b8a069ae7
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x2cf0cc5b8a069ae7 Time: 0.130341
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 0x0da8f7df8cfd2e37
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x0da8f7df8cfd2e37 Time: 0.08448
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.095232
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.0887177
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.0772389
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.112274
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.127781
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.125879
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.0969143
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.073216
[08/20/2024-19:31:53] [V] [TRT] Fastest Tactic: 0xc911b61f7a5c0315 Time: 0.073216
[08/20/2024-19:31:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:53] [V] [TRT] *************** Autotuning format combination: Int8(784,49:32,7,1), Int8(784,49:32,7,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 (CaskFlattenConvolution)
[08/20/2024-19:31:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 (CaskConvolution)
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xd3f592fae61c7986 Time: 0.0137571
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x4cf18ad3e295ea18 Time: 0.049152
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.0190886
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.018944
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x4805f65acfc5cf25 Time: 0.0743131
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xef01fb6e433afa50 Time: 0.0263314
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.0640244
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x705baf38e41eee0b Time: 0.0195309
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x70ccdad7e8ced9ab Time: 0.0156091
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.050371
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.0160752
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.0343543
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.0344942
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.026307
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.049149
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x60edc1e1753cd5b8 Time: 0.0489569
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x53554c607d072468 Time: 0.019348
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.0490545
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x2f34f689bfca5071 Time: 0.0124853
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xf8d4389f60adfa3c Time: 0.0639756
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xd30e9f770878c3fd Time: 0.018688
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x028e842ce51fbd9d Time: 0.0188429
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x9d0f90e0cec890bb Time: 0.0260678
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.0264777
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xea88b51105501f96 Time: 0.0338277
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.0642682
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.0187063
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.026381
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.0264777
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.0191451
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xf33711e7c9ed4673 Time: 0.026576
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.0112028
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.0263802
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.0385463
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x4749124f62d8bd23 Time: 0.0119828
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xd9f3bbc3e16b16ac Time: 0.0488594
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.0265265
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.0800914
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x9f6920f4a40549f4 Time: 0.026307
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.0198429
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.01874
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xd3d41ef6de22d9b6 Time: 0.0341431
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x19b79d0c4ff629da Time: 0.0181211
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x9262f8f95beb428d Time: 0.0155648
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.0149518
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xbb88763c3b0e94d4 Time: 0.0135697
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x4f6730716f78f4a3 Time: 0.0262095
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.01619
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xd277f13d771603ee Time: 0.0272099
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.0112056
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x554e2e252e28b3fd Time: 0.0640731
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xeb9516439d87ac23 Time: 0.0375611
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.049152
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x671c943720ba8655 Time: 0.0158801
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.0175695
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.0359131
[08/20/2024-19:31:53] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x8b2f6e180c235792 Time: 0.0490057
[08/20/2024-19:31:53] [V] [TRT] Fastest Tactic: 0xee2fce9480a52be7 Time: 0.0112028
[08/20/2024-19:31:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xee2fce9480a52be7
[08/20/2024-19:31:53] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:53] [V] [TRT] *************** Autotuning format combination: Int8(25088,49,7,1) -> Int8(25088,49,7,1) ***************
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 (CaskFlattenConvolution)
[08/20/2024-19:31:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 (CaskConvolution)
[08/20/2024-19:31:53] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:53] [V] [TRT] *************** Autotuning format combination: Int8(6272,49:4,7,1) -> Int8(6272,49:4,7,1) ***************
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 (CudaDepthwiseConvolution)
[08/20/2024-19:31:53] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 (FusedConvActConvolution)
[08/20/2024-19:31:53] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 (CaskFlattenConvolution)
[08/20/2024-19:31:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 (CaskConvolution)
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0x0270c2170caa55f8
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x0270c2170caa55f8 Time: 0.111397
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0xa49b04dbd5d9448a
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xa49b04dbd5d9448a Time: 0.126905
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0x1e2179aecb150578
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x1e2179aecb150578 Time: 0.0961097
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0x8846c5916f34f7e9
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x8846c5916f34f7e9 Time: 0.0943543
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0xf6833cac33ebf690
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xf6833cac33ebf690 Time: 0.124928
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 0xcc3c5501ab7b5867
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xcc3c5501ab7b5867 Time: 0.0835291
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 0xe0658ca00f36ea3e
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xe0658ca00f36ea3e Time: 0.129397
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0x50f6b3d3d5866716
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x50f6b3d3d5866716 Time: 0.0876983
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0723383
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x1f0263042c683192
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x1f0263042c683192 Time: 0.0763611
[08/20/2024-19:31:53] [V] [TRT] Fastest Tactic: 0x9aa46c15c2a1d8a7 Time: 0.0723383
[08/20/2024-19:31:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x9aa46c15c2a1d8a7
[08/20/2024-19:31:53] [V] [TRT] *************** Autotuning format combination: Int8(6272,49:4,7,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 (CaskFlattenConvolution)
[08/20/2024-19:31:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 (CaskConvolution)
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 0x2cf0cc5b8a069ae7
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x2cf0cc5b8a069ae7 Time: 0.129243
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 0x0da8f7df8cfd2e37
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x0da8f7df8cfd2e37 Time: 0.0833829
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 0x0f47434ace2a7d18
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x0f47434ace2a7d18 Time: 0.0941349
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 0x320c30eda409da30
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x320c30eda409da30 Time: 0.087552
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: 0xf3f27c40da3380fe
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xf3f27c40da3380fe Time: 0.0762149
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: 0xeb494e2e67f079d4
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xeb494e2e67f079d4 Time: 0.111397
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: 0xc4f09503ebafdf51
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xc4f09503ebafdf51 Time: 0.12683
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 0x3c0834dbcd849973
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x3c0834dbcd849973 Time: 0.124782
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: 0xd4d010e83172b290
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xd4d010e83172b290 Time: 0.0959017
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xc911b61f7a5c0315 Time: 0.0721874
[08/20/2024-19:31:53] [V] [TRT] Fastest Tactic: 0xc911b61f7a5c0315 Time: 0.0721874
[08/20/2024-19:31:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xc911b61f7a5c0315
[08/20/2024-19:31:53] [V] [TRT] *************** Autotuning format combination: Int8(784,49:32,7,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 (CudaGroupConvolution)
[08/20/2024-19:31:53] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 (CudaDepthwiseConvolution)
[08/20/2024-19:31:53] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 (FusedConvActConvolution)
[08/20/2024-19:31:53] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 (CaskFlattenConvolution)
[08/20/2024-19:31:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:53] [V] [TRT] --------------- Timing Runner: layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 (CaskConvolution)
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3f592fae61c7986
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xd3f592fae61c7986 Time: 0.0116033
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4cf18ad3e295ea18
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x4cf18ad3e295ea18 Time: 0.0485669
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x4b476758492c15b0
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x4b476758492c15b0 Time: 0.0158341
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3818ca0093333b50
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x3818ca0093333b50 Time: 0.0186149
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4805f65acfc5cf25
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x4805f65acfc5cf25 Time: 0.0718263
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xef01fb6e433afa50
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xef01fb6e433afa50 Time: 0.0260632
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x41b4640eb250ffd0
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x41b4640eb250ffd0 Time: 0.0634392
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x705baf38e41eee0b
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x705baf38e41eee0b Time: 0.0193114
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x70ccdad7e8ced9ab Time: 0.015328
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xa92dc4358ef627d4
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xa92dc4358ef627d4 Time: 0.0488107
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32 Tactic: 0xe37d64a29ca3101c
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xe37d64a29ca3101c Time: 0.0158574
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x204424cb4da28c02
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x204424cb4da28c02 Time: 0.0338798
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8d50646eff0cde6d
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x8d50646eff0cde6d Time: 0.0335872
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x0fbfd5fa9864ab49
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x0fbfd5fa9864ab49 Time: 0.0259413
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x256x64_stage3_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x4b860619b6031662
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x4b860619b6031662 Time: 0.0486156
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x96x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x60edc1e1753cd5b8
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x60edc1e1753cd5b8 Time: 0.0484663
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x53554c607d072468
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x53554c607d072468 Time: 0.0190537
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x623894f465c90f26
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x623894f465c90f26 Time: 0.0486644
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x2f34f689bfca5071 Time: 0.0128236
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf8d4389f60adfa3c
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xf8d4389f60adfa3c Time: 0.063488
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd30e9f770878c3fd
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xd30e9f770878c3fd Time: 0.0183589
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x028e842ce51fbd9d
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x028e842ce51fbd9d Time: 0.0186
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x9d0f90e0cec890bb Time: 0.0257455
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x2ff8bc85c8ced89e
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x2ff8bc85c8ced89e Time: 0.0261074
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xea88b51105501f96
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0xea88b51105501f96 Time: 0.033387
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x80cce6d8f75dc163
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x80cce6d8f75dc163 Time: 0.0638781
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x11b75d98d540ee52
[08/20/2024-19:31:53] [V] [TRT] Tactic: 0x11b75d98d540ee52 Time: 0.018432
[08/20/2024-19:31:53] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x87620679fb5f37df
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x87620679fb5f37df Time: 0.0260145
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32 Tactic: 0x2728bbf79375f71d
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x2728bbf79375f71d Time: 0.0260175
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5e1b696f91f572c0
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x5e1b696f91f572c0 Time: 0.0198766
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x128x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xf33711e7c9ed4673
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xf33711e7c9ed4673 Time: 0.0258194
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xee2fce9480a52be7 Time: 0.0132081
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x444f830f80ff098b
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x444f830f80ff098b Time: 0.0260389
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x89c1d75fe77808d5
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x89c1d75fe77808d5 Time: 0.03804
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x4749124f62d8bd23 Time: 0.0114314
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x128x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd9f3bbc3e16b16ac
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xd9f3bbc3e16b16ac Time: 0.048323
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x26a29d5b8b3f62af
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x26a29d5b8b3f62af Time: 0.0261608
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x048dc59a1807b5bb
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x048dc59a1807b5bb Time: 0.0772389
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9f6920f4a40549f4
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x9f6920f4a40549f4 Time: 0.0258949
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xeb33cf0799237780
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xeb33cf0799237780 Time: 0.0196583
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x955d593b1135a423 Time: 0.0124244
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd3d41ef6de22d9b6
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xd3d41ef6de22d9b6 Time: 0.0336722
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x19b79d0c4ff629da
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x19b79d0c4ff629da Time: 0.0167751
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x32x64_stage4_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9262f8f95beb428d
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x9262f8f95beb428d Time: 0.0153486
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xf56c0ac895d82363 Time: 0.0150368
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xbb88763c3b0e94d4 Time: 0.0133918
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4f6730716f78f4a3
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x4f6730716f78f4a3 Time: 0.025795
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x99901a83d7176ba9
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x99901a83d7176ba9 Time: 0.0161397
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x96x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xd277f13d771603ee
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xd277f13d771603ee Time: 0.0259459
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x8e1e9d670448aca7 Time: 0.0107318
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x554e2e252e28b3fd
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x554e2e252e28b3fd Time: 0.067584
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x192x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xeb9516439d87ac23
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xeb9516439d87ac23 Time: 0.0394971
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x0f6ba1e5b0320393
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x0f6ba1e5b0320393 Time: 0.0519802
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x671c943720ba8655 Time: 0.0167101
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x96x64_stage5_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x136c072084f41e49
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x136c072084f41e49 Time: 0.0181771
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x7dcb6d55062fd530
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x7dcb6d55062fd530 Time: 0.0378149
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x192x64_stage3_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x8b2f6e180c235792
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x8b2f6e180c235792 Time: 0.0517851
[08/20/2024-19:31:54] [V] [TRT] Fastest Tactic: 0x8e1e9d670448aca7 Time: 0.0107318
[08/20/2024-19:31:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8e1e9d670448aca7
[08/20/2024-19:31:54] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:54] [V] [TRT] *************** Autotuning format combination: Int8(25088,49,7,1), Int8(25088,49,7,1) -> Int8(25088,49,7,1) ***************
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: layer4.1.conv2.weight + QuantizeLinear_282 + Conv_284 + Add_292 + Relu_293 (CaskFlattenConvolution)
[08/20/2024-19:31:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: layer4.1.conv2.weight + QuantizeLinear_282 + Conv_284 + Add_292 + Relu_293 (CaskConvolution)
[08/20/2024-19:31:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:54] [V] [TRT] *************** Autotuning format combination: Int8(6272,49:4,7,1), Int8(6272,49:4,7,1) -> Int8(6272,49:4,7,1) ***************
[08/20/2024-19:31:54] [V] [TRT] *************** Autotuning format combination: Int8(6272,49:4,7,1), Int8(784,49:32,7,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:54] [V] [TRT] *************** Autotuning format combination: Int8(784,49:32,7,1), Int8(784,49:32,7,1) -> Int8(784,49:32,7,1) ***************
[08/20/2024-19:31:54] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:54] [V] [TRT] *************** Autotuning format combination: Int8(6272,49:4,7,1) -> Int8(128,1:4,1,1) ***************
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_300 (TiledPooling)
[08/20/2024-19:31:54] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_300 (CudaPooling)
[08/20/2024-19:31:54] [V] [TRT] CudaPooling has no valid tactics for this config, skipping
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_300 (CaskPooling)
[08/20/2024-19:31:54] [V] [TRT] GlobalAveragePool_300 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kAVERAGE_tP1_tQ1_tR7_tS7_tU1_tV1_tUnroll2_tThreads49 Tactic: 0xcf4fe88af059d783
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xcf4fe88af059d783 Time: 0.0053997
[08/20/2024-19:31:54] [V] [TRT] GlobalAveragePool_300 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kAVERAGE_tP1_tQ1_tR7_tS7_tU1_tV1_tUnroll3_tThreads49 Tactic: 0x237d2771d3ba3afe
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x237d2771d3ba3afe Time: 0.00475134
[08/20/2024-19:31:54] [V] [TRT] GlobalAveragePool_300 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kAVERAGE_tP1_tQ1_tR7_tS7_tU1_tV1_tUnroll5_tThreads49 Tactic: 0xfcba7617eae0767f
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xfcba7617eae0767f Time: 0.00533208
[08/20/2024-19:31:54] [V] [TRT] GlobalAveragePool_300 Set Tactic Name: sm50_xmma_pooling_CHWPacked_NCxHW4_kAVERAGE Tactic: 0xb4d3d3158ab4fbc4
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xb4d3d3158ab4fbc4 Time: 0.0104473
[08/20/2024-19:31:54] [V] [TRT] GlobalAveragePool_300 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kAVERAGE_tP1_tQ1_tR7_tS7_tU1_tV1_tUnroll8_tThreads49 Tactic: 0x3ddeb40b14b91c85
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x3ddeb40b14b91c85 Time: 0.00715246
[08/20/2024-19:31:54] [V] [TRT] GlobalAveragePool_300 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kAVERAGE_tP1_tQ1_tR7_tS7_tU1_tV1_tUnroll1_tThreads49 Tactic: 0x69c017ac3b73fe81
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x69c017ac3b73fe81 Time: 0.00494061
[08/20/2024-19:31:54] [V] [TRT] GlobalAveragePool_300 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kAVERAGE_tP1_tQ1_tR7_tS7_tU1_tV1_tUnroll4_tThreads49 Tactic: 0x1088b9ecc9039b02
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x1088b9ecc9039b02 Time: 0.00489006
[08/20/2024-19:31:54] [V] [TRT] GlobalAveragePool_300 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kAVERAGE_tP1_tQ1_tR7_tS7_tU1_tV1_tUnroll7_tThreads49 Tactic: 0xb60746ca0229b200
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xb60746ca0229b200 Time: 0.00652821
[08/20/2024-19:31:54] [V] [TRT] GlobalAveragePool_300 Set Tactic Name: sm50_xmma_pooling_tiled_INT8NCxHW4_kAVERAGE_tP1_tQ1_tR7_tS7_tU1_tV1_tUnroll6_tThreads49 Tactic: 0x5a35893121ca5f7d
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x5a35893121ca5f7d Time: 0.0073088
[08/20/2024-19:31:54] [V] [TRT] Fastest Tactic: 0x237d2771d3ba3afe Time: 0.00475134
[08/20/2024-19:31:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0x237d2771d3ba3afe
[08/20/2024-19:31:54] [V] [TRT] *************** Autotuning format combination: Int8(784,49:32,7,1) -> Int8(16,1:32,1,1) ***************
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_300 (TiledPooling)
[08/20/2024-19:31:54] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_300 (CudaPooling)
[08/20/2024-19:31:54] [V] [TRT] CudaPooling has no valid tactics for this config, skipping
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_300 (CaskPooling)
[08/20/2024-19:31:54] [V] [TRT] GlobalAveragePool_300 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_gap Tactic: 0xa3a1a62d21de759d
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xa3a1a62d21de759d Time: 0.0050136
[08/20/2024-19:31:54] [V] [TRT] GlobalAveragePool_300 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_generic_kAVERAGE Tactic: 0xd9375d43b61ffbcb
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xd9375d43b61ffbcb Time: 0.00803886
[08/20/2024-19:31:54] [V] [TRT] GlobalAveragePool_300 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_gapSyncCta Tactic: 0x1340e8758429064c
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x1340e8758429064c Time: 0.00997333
[08/20/2024-19:31:54] [V] [TRT] Fastest Tactic: 0xa3a1a62d21de759d Time: 0.0050136
[08/20/2024-19:31:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskPooling Tactic: 0xa3a1a62d21de759d
[08/20/2024-19:31:54] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:54] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1) -> Float(1000,1,1,1) ***************
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] (CudaDepthwiseConvolution)
[08/20/2024-19:31:54] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] (CaskFlattenConvolution)
[08/20/2024-19:31:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] (CaskConvolution)
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 0x14ef32afe5695907
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x14ef32afe5695907 Time: 0.0210651
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 0xb29abdd00304c881
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xb29abdd00304c881 Time: 0.0152137
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: 0xff6944b17d5b2e32
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xff6944b17d5b2e32 Time: 0.0140301
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: 0xfe80445f7bb61a99
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xfe80445f7bb61a99 Time: 0.0165333
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 0xc25454de2efcccdc
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xc25454de2efcccdc Time: 0.0143214
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 0xec391424db39a74f
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xec391424db39a74f Time: 0.0160361
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 0xe01ccc14da28fa6f
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xe01ccc14da28fa6f Time: 0.0174075
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 0x2cf4271504d30e29
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x2cf4271504d30e29 Time: 0.0209241
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm70_xmma_fprop_conv1x1_i8f32_f32_f32_nchw_vect_c_4kcrs_vect_c_4_nchw_simt_small_batch_bias_relu Tactic: 0xc073b0053ce90eac
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xc073b0053ce90eac Time: 0.00540055
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 0x4d9d0d03129bceb1
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x4d9d0d03129bceb1 Time: 0.0144997
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: 0xa4ae2d82115c3e83
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xa4ae2d82115c3e83 Time: 0.0156987
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 0x1db6e8cf1382fbe0
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x1db6e8cf1382fbe0 Time: 0.0207301
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 0x69c4e2ca38eadce2
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x69c4e2ca38eadce2 Time: 0.0148215
[08/20/2024-19:31:54] [V] [TRT] Fastest Tactic: 0xc073b0053ce90eac Time: 0.00540055
[08/20/2024-19:31:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xc073b0053ce90eac
[08/20/2024-19:31:54] [V] [TRT] *************** Autotuning format combination: Int8(16,1:32,1,1) -> Float(1000,1,1,1) ***************
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] (CaskFlattenConvolution)
[08/20/2024-19:31:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] (CaskConvolution)
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4 Tactic: 0xf04572b287451f42
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xf04572b287451f42 Time: 0.0110421
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize128x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_alignc4 Tactic: 0x733ba2a91a48d431
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x733ba2a91a48d431 Time: 0.0070043
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_alignc4 Tactic: 0x5e4f6d7c83746fd6
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x5e4f6d7c83746fd6 Time: 0.00732046
[08/20/2024-19:31:54] [V] [TRT] Fastest Tactic: 0x733ba2a91a48d431 Time: 0.0070043
[08/20/2024-19:31:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x733ba2a91a48d431
[08/20/2024-19:31:54] [V] [TRT] *************** Autotuning format combination: Int8(16,1:32,1,1) -> Float(32,1:32,1,1) ***************
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] (CaskFlattenConvolution)
[08/20/2024-19:31:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] (CaskConvolution)
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x9ec201b34455146e
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x9ec201b34455146e Time: 0.00600476
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x960e9baa2a6cad5b
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x960e9baa2a6cad5b Time: 0.00564097
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x33a5c6dd086942c1
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x33a5c6dd086942c1 Time: 0.00596838
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0xa2f15b0a75b7dcec
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xa2f15b0a75b7dcec Time: 0.0123509
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x91930a570b557437
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x91930a570b557437 Time: 0.0124221
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x1e55f8b415964e81
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x1e55f8b415964e81 Time: 0.00783013
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6d377e4222886190
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x6d377e4222886190 Time: 0.00617581
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xbeb5d91e1874a437
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xbeb5d91e1874a437 Time: 0.00786767
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x2468d082d0ff7c9a
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x2468d082d0ff7c9a Time: 0.00549679
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xa71946688cad8664
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xa71946688cad8664 Time: 0.00563306
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x84942841d92b0552
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x84942841d92b0552 Time: 0.00802057
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xdc1f355deb032b87
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xdc1f355deb032b87 Time: 0.00714405
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdf7e1bd6a496d667
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xdf7e1bd6a496d667 Time: 0.00791146
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x9003f5f7ff9b1aec
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x9003f5f7ff9b1aec Time: 0.0117254
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcd229658c16b33cd
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xcd229658c16b33cd Time: 0.011971
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_indexed_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x6986b0c6a136276e
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x6986b0c6a136276e Time: 0.00900943
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x271b998fe31732ef
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x271b998fe31732ef Time: 0.00730743
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8141573686849b61
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x8141573686849b61 Time: 0.00776084
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xe742f4598442d2f1
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xe742f4598442d2f1 Time: 0.0075585
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x7720f198395e7d3d
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x7720f198395e7d3d Time: 0.00725166
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x748f926574b7bdc4
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x748f926574b7bdc4 Time: 0.0138439
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xb86b920539eb9c79
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xb86b920539eb9c79 Time: 0.00821537
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x60b880e28fee7a0c
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x60b880e28fee7a0c Time: 0.0123002
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcf64a2ae51bf6b36
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xcf64a2ae51bf6b36 Time: 0.00578688
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x844ea9c00f711f19
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x844ea9c00f711f19 Time: 0.00746583
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x65fbe45b4cb1d8a5
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x65fbe45b4cb1d8a5 Time: 0.0053804
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x3f2b14dec582741e
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x3f2b14dec582741e Time: 0.00582949
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x445983715412fbda
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x445983715412fbda Time: 0.00537448
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x5bd8221bd57baf93
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x5bd8221bd57baf93 Time: 0.00584357
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0xb5f710b331ba8377
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xb5f710b331ba8377 Time: 0.0133386
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5f1a472d416ff35e
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x5f1a472d416ff35e Time: 0.00698427
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6e9c17a33c93d9b0
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x6e9c17a33c93d9b0 Time: 0.00674556
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x991db9fd58152c33
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x991db9fd58152c33 Time: 0.00810514
[08/20/2024-19:31:54] [V] [TRT] Fastest Tactic: 0x445983715412fbda Time: 0.00537448
[08/20/2024-19:31:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x445983715412fbda
[08/20/2024-19:31:54] [V] [TRT] *************** Autotuning format combination: Int8(16,1:32,1,1) -> Half(32,1:32,1,1) ***************
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] (CaskFlattenConvolution)
[08/20/2024-19:31:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] (CaskConvolution)
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_conv_fprop_smallk_i8f16_i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_warptilesize16x32_stage4_warpsize2x4x1_r1s1_u1v1_hw1_c512_scalebias Tactic: 0x35b622a5520914e9
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x35b622a5520914e9 Time: 0.0077262
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x1cfa820c55616892
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x1cfa820c55616892 Time: 0.00810032
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xccdb99df0646c7b3
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xccdb99df0646c7b3 Time: 0.0118713
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x7de8ad674a85e82a
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x7de8ad674a85e82a Time: 0.0163205
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x758f8b2079a95b2e
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x758f8b2079a95b2e Time: 0.0156722
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x43e3804f158e597d
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x43e3804f158e597d Time: 0.0180183
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x7524377e24bc511f
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x7524377e24bc511f Time: 0.0143086
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x5812ced7874b44d1
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x5812ced7874b44d1 Time: 0.0151927
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x3e116db8858d0d41
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x3e116db8858d0d41 Time: 0.0140758
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 0x8f07802f58d278c0
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x8f07802f58d278c0 Time: 0.0186514
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 0x264d83735b1cba13
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x264d83735b1cba13 Time: 0.0104803
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcf392eca056b8d88
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xcf392eca056b8d88 Time: 0.012555
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x4f8662a723b489e1
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x4f8662a723b489e1 Time: 0.00514678
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xaba07efc49c11a6c
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xaba07efc49c11a6c Time: 0.0124221
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x8e1dd2962c589dd4
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x8e1dd2962c589dd4 Time: 0.00564642
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xd7985d83133bcf37
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xd7985d83133bcf37 Time: 0.005972
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xb34706d47a62a016
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xb34706d47a62a016 Time: 0.00584521
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x8486adb55ae0ca6c
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x8486adb55ae0ca6c Time: 0.00795632
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x86d1488f426124e1
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x86d1488f426124e1 Time: 0.00582949
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xcba01f45d37a76a0
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xcba01f45d37a76a0 Time: 0.00734126
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x62a338704beec449
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x62a338704beec449 Time: 0.0123813
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x68f52f0a3f1c5b56
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x68f52f0a3f1c5b56 Time: 0.0072176
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0xdb3ae212a7704d44
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xdb3ae212a7704d44 Time: 0.00540766
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: 0x4e7f02f91ddf4673
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x4e7f02f91ddf4673 Time: 0.0151113
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xaceaca2c82ab40f3
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xaceaca2c82ab40f3 Time: 0.00571703
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0xaa30815cbd0f74b7
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xaa30815cbd0f74b7 Time: 0.0122385
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 0x6c336d1b7c64ffa3
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x6c336d1b7c64ffa3 Time: 0.00780102
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xb7a90e7097d64877
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0xb7a90e7097d64877 Time: 0.00695641
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x682fae8be946411d
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x682fae8be946411d Time: 0.0079487
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x70ffb5fe2e1321e3
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x70ffb5fe2e1321e3 Time: 0.00794057
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f16_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x27fb8661fea664b3
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x27fb8661fea664b3 Time: 0.00560563
[08/20/2024-19:31:54] [V] [TRT] Fastest Tactic: 0x4f8662a723b489e1 Time: 0.00514678
[08/20/2024-19:31:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x4f8662a723b489e1
[08/20/2024-19:31:54] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:54] [V] [TRT] *************** Autotuning format combination: Float(1000,1,1,1) -> Float(1000,1) ***************
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: copied_squeeze_after_(Unnamed Layer* 356) [ElementWise] (Shuffle)
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00438829
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0132285
[08/20/2024-19:31:54] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00438829
[08/20/2024-19:31:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[08/20/2024-19:31:54] [V] [TRT] *************** Autotuning format combination: Half(1000,1,1,1) -> Half(1000,1) ***************
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: copied_squeeze_after_(Unnamed Layer* 356) [ElementWise] (Shuffle)
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00434992
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x0000000000000001 Time: 0.0134583
[08/20/2024-19:31:54] [V] [TRT] Fastest Tactic: 0x0000000000000000 Time: 0.00434992
[08/20/2024-19:31:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000
[08/20/2024-19:31:54] [V] [TRT] =============== Computing costs for 
[08/20/2024-19:31:54] [V] [TRT] *************** Autotuning format combination: Float(1000,1) -> Float(1000,1) ***************
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: Softmax_312 (CudaSoftMax)
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00531522
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x00000000000003e9 Time: 0.0049629
[08/20/2024-19:31:54] [V] [TRT] Fastest Tactic: 0x00000000000003e9 Time: 0.0049629
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: Softmax_312 (CaskSoftMax)
[08/20/2024-19:31:54] [V] [TRT] CaskSoftMax has no valid tactics for this config, skipping
[08/20/2024-19:31:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaSoftMax Tactic: 0x00000000000003e9
[08/20/2024-19:31:54] [V] [TRT] *************** Autotuning format combination: Half(1000,1) -> Half(1000,1) ***************
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: Softmax_312 (CudaSoftMax)
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00702358
[08/20/2024-19:31:54] [V] [TRT] Tactic: 0x00000000000003e9 Time: 0.0051102
[08/20/2024-19:31:54] [V] [TRT] Fastest Tactic: 0x00000000000003e9 Time: 0.0051102
[08/20/2024-19:31:54] [V] [TRT] --------------- Timing Runner: Softmax_312 (CaskSoftMax)
[08/20/2024-19:31:54] [V] [TRT] CaskSoftMax has no valid tactics for this config, skipping
[08/20/2024-19:31:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaSoftMax Tactic: 0x00000000000003e9
[08/20/2024-19:31:54] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] (515) from Int8(16,1:32,1,1) to Int8(128,1:4,1,1)
[08/20/2024-19:31:54] [V] [TRT] For layer fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] a non-conforming implementation was chosen than was requested i.e. requested layer computation precision and output precision types were ignored because it resulted in faster network performance. Set BuilderFlag::kPREFER_PRECISION_CONSTRAINTS to encourage choosing a conforming implementation, or set BuilderFlag::kOBEY_PRECISION_CONSTRAINTS to require choosing a conforming implementation.
[08/20/2024-19:31:54] [V] [TRT] Formats and tactics selection completed in 6.146 seconds.
[08/20/2024-19:31:54] [V] [TRT] After reformat layers: 26 layers
[08/20/2024-19:31:54] [V] [TRT] Total number of blocks in pre-optimized block assignment: 26
[08/20/2024-19:31:54] [I] [TRT] Total Activation Memory: 8587253760
[08/20/2024-19:31:54] [I] [TRT] Detected 1 inputs and 1 output network tensors.
[08/20/2024-19:31:54] [V] [TRT] layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[08/20/2024-19:31:54] [V] [TRT] layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb
[08/20/2024-19:31:54] [V] [TRT] layer1.1.conv1.weight + QuantizeLinear_51 + Conv_53 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0xf56c0ac895d82363
[08/20/2024-19:31:54] [V] [TRT] layer1.1.conv2.weight + QuantizeLinear_63 + Conv_65 + Add_73 + Relu_74 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x9d0f90e0cec890bb
[08/20/2024-19:31:54] [V] [TRT] layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x671c943720ba8655
[08/20/2024-19:31:54] [V] [TRT] layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x65920facc9ae819d
[08/20/2024-19:31:54] [V] [TRT] layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[08/20/2024-19:31:54] [V] [TRT] layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[08/20/2024-19:31:54] [V] [TRT] layer2.1.conv2.weight + QuantizeLinear_136 + Conv_138 + Add_146 + Relu_147 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x70ccdad7e8ced9ab
[08/20/2024-19:31:54] [V] [TRT] layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 0xbb88763c3b0e94d4
[08/20/2024-19:31:54] [V] [TRT] layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 0x881d70ee6f8bc650
[08/20/2024-19:31:54] [V] [TRT] layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[08/20/2024-19:31:54] [V] [TRT] layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x2f34f689bfca5071
[08/20/2024-19:31:54] [V] [TRT] layer3.1.conv2.weight + QuantizeLinear_209 + Conv_211 + Add_219 + Relu_220 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[08/20/2024-19:31:54] [V] [TRT] layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 0x4749124f62d8bd23
[08/20/2024-19:31:54] [V] [TRT] layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0x955d593b1135a423
[08/20/2024-19:31:54] [V] [TRT] layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 0x8e1e9d670448aca7
[08/20/2024-19:31:54] [V] [TRT] layer4.1.conv2.weight + QuantizeLinear_282 + Conv_284 + Add_292 + Relu_293 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 0xee2fce9480a52be7
[08/20/2024-19:31:54] [V] [TRT] GlobalAveragePool_300 Set Tactic Name: sm72_xmma_pooling_IMMA_NCxHW32_gap Tactic: 0xa3a1a62d21de759d
[08/20/2024-19:31:54] [V] [TRT] fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set Tactic Name: sm70_xmma_fprop_conv1x1_i8f32_f32_f32_nchw_vect_c_4kcrs_vect_c_4_nchw_simt_small_batch_bias_relu Tactic: 0xc073b0053ce90eac
[08/20/2024-19:31:54] [V] [TRT] Layer: layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Layer: layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Layer: layer1.1.conv1.weight + QuantizeLinear_51 + Conv_53 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Layer: layer1.1.conv2.weight + QuantizeLinear_63 + Conv_65 + Add_73 + Relu_74 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Layer: layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Layer: layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Layer: layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Layer: layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Layer: layer2.1.conv2.weight + QuantizeLinear_136 + Conv_138 + Add_146 + Relu_147 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Layer: layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Layer: layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Layer: layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Layer: layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Layer: layer3.1.conv2.weight + QuantizeLinear_209 + Conv_211 + Add_219 + Relu_220 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Layer: layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Layer: layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Layer: layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Layer: layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Layer: layer4.1.conv2.weight + QuantizeLinear_282 + Conv_284 + Add_292 + Relu_293 Host Persistent: 2816 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Layer: GlobalAveragePool_300 Host Persistent: 1344 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Layer: fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Host Persistent: 2880 Device Persistent: 0 Scratch Memory: 0
[08/20/2024-19:31:54] [V] [TRT] Skipped printing memory information for 5 layers with 0 memory size i.e. Host Persistent + Device Persistent + Scratch Memory == 0.
[08/20/2024-19:31:54] [I] [TRT] Total Host Persistent Memory: 57728
[08/20/2024-19:31:54] [I] [TRT] Total Device Persistent Memory: 0
[08/20/2024-19:31:54] [I] [TRT] Total Scratch Memory: 0
[08/20/2024-19:31:54] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 59 MiB, GPU 13 MiB
[08/20/2024-19:31:54] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 25 steps to complete.
[08/20/2024-19:31:54] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.117246ms to assign 3 blocks to 25 nodes requiring 602112 bytes.
[08/20/2024-19:31:54] [V] [TRT] Total number of blocks in optimized block assignment: 3
[08/20/2024-19:31:54] [I] [TRT] Total Activation Memory: 602112
[08/20/2024-19:31:54] [V] [TRT] Finalize: layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22 Set kernel index: 0
[08/20/2024-19:31:54] [V] [TRT] Finalize: layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43 Set kernel index: 1
[08/20/2024-19:31:54] [V] [TRT] Finalize: layer1.1.conv1.weight + QuantizeLinear_51 + Conv_53 Set kernel index: 0
[08/20/2024-19:31:54] [V] [TRT] Finalize: layer1.1.conv2.weight + QuantizeLinear_63 + Conv_65 + Add_73 + Relu_74 Set kernel index: 1
[08/20/2024-19:31:54] [V] [TRT] Finalize: layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84 Set kernel index: 2
[08/20/2024-19:31:54] [V] [TRT] Finalize: layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107 Set kernel index: 3
[08/20/2024-19:31:54] [V] [TRT] Finalize: layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116 Set kernel index: 4
[08/20/2024-19:31:54] [V] [TRT] Finalize: layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126 Set kernel index: 4
[08/20/2024-19:31:54] [V] [TRT] Finalize: layer2.1.conv2.weight + QuantizeLinear_136 + Conv_138 + Add_146 + Relu_147 Set kernel index: 4
[08/20/2024-19:31:54] [V] [TRT] Finalize: layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157 Set kernel index: 5
[08/20/2024-19:31:54] [V] [TRT] Finalize: layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180 Set kernel index: 6
[08/20/2024-19:31:54] [V] [TRT] Finalize: layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189 Set kernel index: 7
[08/20/2024-19:31:54] [V] [TRT] Finalize: layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199 Set kernel index: 8
[08/20/2024-19:31:54] [V] [TRT] Finalize: layer3.1.conv2.weight + QuantizeLinear_209 + Conv_211 + Add_219 + Relu_220 Set kernel index: 7
[08/20/2024-19:31:54] [V] [TRT] Finalize: layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230 Set kernel index: 9
[08/20/2024-19:31:54] [V] [TRT] Finalize: layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253 Set kernel index: 7
[08/20/2024-19:31:54] [V] [TRT] Finalize: layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262 Set kernel index: 10
[08/20/2024-19:31:54] [V] [TRT] Finalize: layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272 Set kernel index: 11
[08/20/2024-19:31:54] [V] [TRT] Finalize: layer4.1.conv2.weight + QuantizeLinear_282 + Conv_284 + Add_292 + Relu_293 Set kernel index: 10
[08/20/2024-19:31:54] [V] [TRT] Finalize: GlobalAveragePool_300 Set kernel index: 12
[08/20/2024-19:31:54] [V] [TRT] Finalize: fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] Set kernel index: 13
[08/20/2024-19:31:54] [V] [TRT] Total number of generated kernels selected for the engine: 14
[08/20/2024-19:31:54] [V] [TRT] Kernel: 0 CASK_STATIC
[08/20/2024-19:31:54] [V] [TRT] Kernel: 1 CASK_STATIC
[08/20/2024-19:31:54] [V] [TRT] Kernel: 2 CASK_STATIC
[08/20/2024-19:31:54] [V] [TRT] Kernel: 3 CASK_STATIC
[08/20/2024-19:31:54] [V] [TRT] Kernel: 4 CASK_STATIC
[08/20/2024-19:31:54] [V] [TRT] Kernel: 5 CASK_STATIC
[08/20/2024-19:31:54] [V] [TRT] Kernel: 6 CASK_STATIC
[08/20/2024-19:31:54] [V] [TRT] Kernel: 7 CASK_STATIC
[08/20/2024-19:31:54] [V] [TRT] Kernel: 8 CASK_STATIC
[08/20/2024-19:31:54] [V] [TRT] Kernel: 9 CASK_STATIC
[08/20/2024-19:31:54] [V] [TRT] Kernel: 10 CASK_STATIC
[08/20/2024-19:31:54] [V] [TRT] Kernel: 11 CASK_STATIC
[08/20/2024-19:31:54] [V] [TRT] Kernel: 12 CASK_STATIC
[08/20/2024-19:31:54] [V] [TRT] Kernel: 13 CASK_STATIC
[08/20/2024-19:31:54] [V] [TRT] Disabling unused tactic source: CUDNN
[08/20/2024-19:31:54] [V] [TRT] Disabling unused tactic source: CUBLAS, CUBLAS_LT
[08/20/2024-19:31:54] [V] [TRT] Disabling unused tactic source: JIT_CONVOLUTIONS
[08/20/2024-19:31:54] [V] [TRT] Engine generation completed in 24.152 seconds.
[08/20/2024-19:31:54] [V] [TRT] Deleting timing cache: 112 entries, served 177 hits since creation.
[08/20/2024-19:31:54] [V] [TRT] Engine Layer Information:
Layer(Reformat): QuantizeLinear_2, Tactic: 0x00000000000003ea, inputs.1 (Float[1,3,224,224]) -> 176 (Int8[1,3,224,224])
Layer(ConvActPool): conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12, Tactic: 0x0000000000000461, 176 (Int8[1,3,224,224]) -> 191 (Int8[1,64:32,56,56])
Layer(CaskConvolution): layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22, Tactic: 0xf56c0ac895d82363, 191 (Int8[1,64:32,56,56]) -> 205 (Int8[1,64:32,56,56])
Layer(CaskConvolution): layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43, Tactic: 0x9d0f90e0cec890bb, 205 (Int8[1,64:32,56,56]), 191 (Int8[1,64:32,56,56]) -> 226 (Int8[1,64:32,56,56])
Layer(CaskConvolution): layer1.1.conv1.weight + QuantizeLinear_51 + Conv_53, Tactic: 0xf56c0ac895d82363, 226 (Int8[1,64:32,56,56]) -> 240 (Int8[1,64:32,56,56])
Layer(CaskConvolution): layer1.1.conv2.weight + QuantizeLinear_63 + Conv_65 + Add_73 + Relu_74, Tactic: 0x9d0f90e0cec890bb, 240 (Int8[1,64:32,56,56]), 226 (Int8[1,64:32,56,56]) -> 261 (Int8[1,64:32,56,56])
Layer(CaskConvolution): layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84, Tactic: 0x671c943720ba8655, 261 (Int8[1,64:32,56,56]) -> 275 (Int8[1,128:32,28,28])
Layer(CaskConvolution): layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107, Tactic: 0x65920facc9ae819d, 261 (Int8[1,64:32,56,56]) -> 301 (Int8[1,128:32,28,28])
Layer(CaskConvolution): layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116, Tactic: 0x70ccdad7e8ced9ab, 275 (Int8[1,128:32,28,28]), 301 (Int8[1,128:32,28,28]) -> 309 (Int8[1,128:32,28,28])
Layer(CaskConvolution): layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126, Tactic: 0x70ccdad7e8ced9ab, 309 (Int8[1,128:32,28,28]) -> 323 (Int8[1,128:32,28,28])
Layer(CaskConvolution): layer2.1.conv2.weight + QuantizeLinear_136 + Conv_138 + Add_146 + Relu_147, Tactic: 0x70ccdad7e8ced9ab, 323 (Int8[1,128:32,28,28]), 309 (Int8[1,128:32,28,28]) -> 344 (Int8[1,128:32,28,28])
Layer(CaskConvolution): layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157, Tactic: 0xbb88763c3b0e94d4, 344 (Int8[1,128:32,28,28]) -> 358 (Int8[1,256:32,14,14])
Layer(CaskConvolution): layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180, Tactic: 0x881d70ee6f8bc650, 344 (Int8[1,128:32,28,28]) -> 384 (Int8[1,256:32,14,14])
Layer(CaskConvolution): layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189, Tactic: 0x955d593b1135a423, 358 (Int8[1,256:32,14,14]), 384 (Int8[1,256:32,14,14]) -> 392 (Int8[1,256:32,14,14])
Layer(CaskConvolution): layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199, Tactic: 0x2f34f689bfca5071, 392 (Int8[1,256:32,14,14]) -> 406 (Int8[1,256:32,14,14])
Layer(CaskConvolution): layer3.1.conv2.weight + QuantizeLinear_209 + Conv_211 + Add_219 + Relu_220, Tactic: 0x955d593b1135a423, 406 (Int8[1,256:32,14,14]), 392 (Int8[1,256:32,14,14]) -> 427 (Int8[1,256:32,14,14])
Layer(CaskConvolution): layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230, Tactic: 0x4749124f62d8bd23, 427 (Int8[1,256:32,14,14]) -> 441 (Int8[1,512:32,7,7])
Layer(CaskConvolution): layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253, Tactic: 0x955d593b1135a423, 427 (Int8[1,256:32,14,14]) -> 467 (Int8[1,512:32,7,7])
Layer(CaskConvolution): layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262, Tactic: 0xee2fce9480a52be7, 441 (Int8[1,512:32,7,7]), 467 (Int8[1,512:32,7,7]) -> 475 (Int8[1,512:32,7,7])
Layer(CaskConvolution): layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272, Tactic: 0x8e1e9d670448aca7, 475 (Int8[1,512:32,7,7]) -> 489 (Int8[1,512:32,7,7])
Layer(CaskConvolution): layer4.1.conv2.weight + QuantizeLinear_282 + Conv_284 + Add_292 + Relu_293, Tactic: 0xee2fce9480a52be7, 489 (Int8[1,512:32,7,7]), 475 (Int8[1,512:32,7,7]) -> 510 (Int8[1,512:32,7,7])
Layer(CaskPooling): GlobalAveragePool_300, Tactic: 0xa3a1a62d21de759d, 510 (Int8[1,512:32,7,7]) -> 515 (Int8[1,512:32,1,1])
Layer(NoOp): Reformatting CopyNode for Input Tensor 0 to fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise], Tactic: 0x0000000000000000, 515 (Int8[1,512:32,1,1]) -> Reformatted Input Tensor 0 to fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] (Int8[1,512:4,1,1])
Layer(CaskConvolution): fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise], Tactic: 0xc073b0053ce90eac, Reformatted Input Tensor 0 to fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise] (Int8[1,512:4,1,1]) -> (Unnamed Layer* 356) [ElementWise]_out_tensor (Float[1,1000,1,1])
Layer(NoOp): copied_squeeze_after_(Unnamed Layer* 356) [ElementWise], Tactic: 0x0000000000000000, (Unnamed Layer* 356) [ElementWise]_out_tensor (Float[1,1000,1,1]) -> 527 (Float[1,1000])
Layer(CudaSoftMax): Softmax_312, Tactic: 0x00000000000003e9, 527 (Float[1,1000]) -> 528 (Float[1,1000])
[08/20/2024-19:31:54] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +11, GPU +12, now: CPU 11, GPU 12 (MiB)
[08/20/2024-19:31:54] [I] Engine built in 53.4699 sec.
[08/20/2024-19:31:54] [I] [TRT] Loaded engine size: 12 MiB
[08/20/2024-19:31:54] [V] [TRT] Deserialization required 10141 microseconds.
[08/20/2024-19:31:54] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +11, now: CPU 0, GPU 11 (MiB)
[08/20/2024-19:31:54] [I] Engine deserialized in 0.0102685 sec.
[08/20/2024-19:31:54] [V] [TRT] Total per-runner device persistent memory is 0
[08/20/2024-19:31:54] [V] [TRT] Total per-runner host persistent memory is 57728
[08/20/2024-19:31:54] [V] [TRT] Allocated activation device memory of size 602112
[08/20/2024-19:31:54] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 11 (MiB)
[08/20/2024-19:31:54] [I] Setting persistentCacheLimit to 0 bytes.
[08/20/2024-19:31:54] [V] Using enqueueV3.
[08/20/2024-19:31:54] [I] Using random values for input inputs.1
[08/20/2024-19:31:54] [I] Created input binding for inputs.1 with dimensions 1x3x224x224
[08/20/2024-19:31:54] [I] Using random values for output 528
[08/20/2024-19:31:54] [I] Created output binding for 528 with dimensions 1x1000
[08/20/2024-19:31:54] [I] Layer Information:
[08/20/2024-19:31:54] [I] Layers:
Name: QuantizeLinear_2, LayerType: Reformat, Inputs: [ { Name: inputs.1, Location: Device, Dimensions: [1,3,224,224], Format/Datatype: Row major linear FP32 }], Outputs: [ { Name: 176, Location: Device, Dimensions: [1,3,224,224], Format/Datatype: Row major Int8 format }], ParameterType: Reformat, Origin: QDQ, TacticValue: 0x00000000000003ea
Name: conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12, LayerType: ConvActPool, Inputs: [ { Name: 176, Location: Device, Dimensions: [1,3,224,224], Format/Datatype: Row major Int8 format }], Outputs: [ { Name: 191, Location: Device, Dimensions: [1,64,56,56], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: ConvActPool, ConvParameterType: Convolution, ConvKernel: [7,7], ConvPaddingMode: kEXPLICIT_ROUND_DOWN, ConvPrePadding: [3,3], ConvPostPadding: [3,3], ConvStride: [2,2], ConvDilation: [1,1], ConvOutMaps: 64, ConvGroups: 1, ConvWeights: {"Type": "Int8", "Count": 9408}, ConvBias: {"Type": "Float", "Count": 64}, ConvHasSparseWeights: 0, ConvHasDynamicFilter: 0, ConvHasDynamicBias: 0, ConvHasResidual: 0, ConvConvXAsActInputIdx: -1, ConvBiasAsActInputIdx: -1, ConvResAsActInputIdx: -1, ConvActivation: RELU, PoolingParameterType: Pooling, PoolingPoolingType: MAX, PoolingWindowSize: [3,3], PoolingPaddingMode: kEXPLICIT_ROUND_DOWN, PoolingPrePadding: [1,1], PoolingPostPadding: [1,1], PoolingStride: [2,2], PoolingBlendFactor: 0, PoolingAverageCountExcludesPadding: 1, TacticValue: 0x0000000000000461
Name: layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22, LayerType: CaskConvolution, Inputs: [ { Name: 191, Location: Device, Dimensions: [1,64,56,56], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 205, Location: Device, Dimensions: [1,64,56,56], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 64, Groups: 1, Weights: {"Type": "Int8", "Count": 36864}, Bias: {"Type": "Float", "Count": 64}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32, TacticValue: 0xf56c0ac895d82363
Name: layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43, LayerType: CaskConvolution, Inputs: [ { Name: 205, Location: Device, Dimensions: [1,64,56,56], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }, { Name: 191, Location: Device, Dimensions: [1,64,56,56], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 226, Location: Device, Dimensions: [1,64,56,56], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 64, Groups: 1, Weights: {"Type": "Int8", "Count": 36864}, Bias: {"Type": "Float", "Count": 64}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 1, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0x9d0f90e0cec890bb
Name: layer1.1.conv1.weight + QuantizeLinear_51 + Conv_53, LayerType: CaskConvolution, Inputs: [ { Name: 226, Location: Device, Dimensions: [1,64,56,56], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 240, Location: Device, Dimensions: [1,64,56,56], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 64, Groups: 1, Weights: {"Type": "Int8", "Count": 36864}, Bias: {"Type": "Float", "Count": 64}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32, TacticValue: 0xf56c0ac895d82363
Name: layer1.1.conv2.weight + QuantizeLinear_63 + Conv_65 + Add_73 + Relu_74, LayerType: CaskConvolution, Inputs: [ { Name: 240, Location: Device, Dimensions: [1,64,56,56], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }, { Name: 226, Location: Device, Dimensions: [1,64,56,56], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 261, Location: Device, Dimensions: [1,64,56,56], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 64, Groups: 1, Weights: {"Type": "Int8", "Count": 36864}, Bias: {"Type": "Float", "Count": 64}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 1, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0x9d0f90e0cec890bb
Name: layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84, LayerType: CaskConvolution, Inputs: [ { Name: 261, Location: Device, Dimensions: [1,64,56,56], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 275, Location: Device, Dimensions: [1,128,28,28], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [2,2], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 73728}, Bias: {"Type": "Float", "Count": 128}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize48x128x64_stage3_warpsize1x4x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0x671c943720ba8655
Name: layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107, LayerType: CaskConvolution, Inputs: [ { Name: 261, Location: Device, Dimensions: [1,64,56,56], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 301, Location: Device, Dimensions: [1,128,28,28], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [2,2], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 8192}, Bias: {"Type": "Float", "Count": 128}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize192x64x64_stage3_warpsize4x1x1_g1_tensor16x8x32_t1r1s1, TacticValue: 0x65920facc9ae819d
Name: layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116, LayerType: CaskConvolution, Inputs: [ { Name: 275, Location: Device, Dimensions: [1,128,28,28], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }, { Name: 301, Location: Device, Dimensions: [1,128,28,28], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 309, Location: Device, Dimensions: [1,128,28,28], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 1, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0x70ccdad7e8ced9ab
Name: layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126, LayerType: CaskConvolution, Inputs: [ { Name: 309, Location: Device, Dimensions: [1,128,28,28], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 323, Location: Device, Dimensions: [1,128,28,28], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0x70ccdad7e8ced9ab
Name: layer2.1.conv2.weight + QuantizeLinear_136 + Conv_138 + Add_146 + Relu_147, LayerType: CaskConvolution, Inputs: [ { Name: 323, Location: Device, Dimensions: [1,128,28,28], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }, { Name: 309, Location: Device, Dimensions: [1,128,28,28], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 344, Location: Device, Dimensions: [1,128,28,28], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Int8", "Count": 147456}, Bias: {"Type": "Float", "Count": 128}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 1, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize96x64x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0x70ccdad7e8ced9ab
Name: layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157, LayerType: CaskConvolution, Inputs: [ { Name: 344, Location: Device, Dimensions: [1,128,28,28], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 358, Location: Device, Dimensions: [1,256,14,14], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [2,2], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 294912}, Bias: {"Type": "Float", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0xbb88763c3b0e94d4
Name: layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180, LayerType: CaskConvolution, Inputs: [ { Name: 344, Location: Device, Dimensions: [1,128,28,28], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 384, Location: Device, Dimensions: [1,256,14,14], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [2,2], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 32768}, Bias: {"Type": "Float", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x96x64_stage3_warpsize2x2x1_g1_tensor16x8x32_t1r1s1, TacticValue: 0x881d70ee6f8bc650
Name: layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189, LayerType: CaskConvolution, Inputs: [ { Name: 358, Location: Device, Dimensions: [1,256,14,14], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }, { Name: 384, Location: Device, Dimensions: [1,256,14,14], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 392, Location: Device, Dimensions: [1,256,14,14], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 589824}, Bias: {"Type": "Float", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 1, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32, TacticValue: 0x955d593b1135a423
Name: layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199, LayerType: CaskConvolution, Inputs: [ { Name: 392, Location: Device, Dimensions: [1,256,14,14], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 406, Location: Device, Dimensions: [1,256,14,14], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 589824}, Bias: {"Type": "Float", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0x2f34f689bfca5071
Name: layer3.1.conv2.weight + QuantizeLinear_209 + Conv_211 + Add_219 + Relu_220, LayerType: CaskConvolution, Inputs: [ { Name: 406, Location: Device, Dimensions: [1,256,14,14], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }, { Name: 392, Location: Device, Dimensions: [1,256,14,14], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 427, Location: Device, Dimensions: [1,256,14,14], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Int8", "Count": 589824}, Bias: {"Type": "Float", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 1, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32, TacticValue: 0x955d593b1135a423
Name: layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230, LayerType: CaskConvolution, Inputs: [ { Name: 427, Location: Device, Dimensions: [1,256,14,14], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 441, Location: Device, Dimensions: [1,512,7,7], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [2,2], Dilation: [1,1], OutMaps: 512, Groups: 1, Weights: {"Type": "Int8", "Count": 1179648}, Bias: {"Type": "Float", "Count": 512}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3, TacticValue: 0x4749124f62d8bd23
Name: layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253, LayerType: CaskConvolution, Inputs: [ { Name: 427, Location: Device, Dimensions: [1,256,14,14], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 467, Location: Device, Dimensions: [1,512,7,7], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [2,2], Dilation: [1,1], OutMaps: 512, Groups: 1, Weights: {"Type": "Int8", "Count": 131072}, Bias: {"Type": "Float", "Count": 512}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32, TacticValue: 0x955d593b1135a423
Name: layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262, LayerType: CaskConvolution, Inputs: [ { Name: 441, Location: Device, Dimensions: [1,512,7,7], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }, { Name: 467, Location: Device, Dimensions: [1,512,7,7], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 475, Location: Device, Dimensions: [1,512,7,7], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 512, Groups: 1, Weights: {"Type": "Int8", "Count": 2359296}, Bias: {"Type": "Float", "Count": 512}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 1, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32, TacticValue: 0xee2fce9480a52be7
Name: layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272, LayerType: CaskConvolution, Inputs: [ { Name: 475, Location: Device, Dimensions: [1,512,7,7], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 489, Location: Device, Dimensions: [1,512,7,7], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 512, Groups: 1, Weights: {"Type": "Int8", "Count": 2359296}, Bias: {"Type": "Float", "Count": 512}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32, TacticValue: 0x8e1e9d670448aca7
Name: layer4.1.conv2.weight + QuantizeLinear_282 + Conv_284 + Add_292 + Relu_293, LayerType: CaskConvolution, Inputs: [ { Name: 489, Location: Device, Dimensions: [1,512,7,7], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }, { Name: 475, Location: Device, Dimensions: [1,512,7,7], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 510, Location: Device, Dimensions: [1,512,7,7], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 512, Groups: 1, Weights: {"Type": "Int8", "Count": 2359296}, Bias: {"Type": "Float", "Count": 512}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 1, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32, TacticValue: 0xee2fce9480a52be7
Name: GlobalAveragePool_300, LayerType: CaskPooling, Inputs: [ { Name: 510, Location: Device, Dimensions: [1,512,7,7], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: 515, Location: Device, Dimensions: [1,512,1,1], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], ParameterType: Pooling, PoolingType: AVERAGE, WindowSize: [7,7], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], BlendFactor: 0, AverageCountExcludesPadding: 1, TacticName: sm72_xmma_pooling_IMMA_NCxHW32_gap, TacticValue: 0xa3a1a62d21de759d
Name: Reformatting CopyNode for Input Tensor 0 to fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise], LayerType: NoOp, Inputs: [ { Name: 515, Location: Device, Dimensions: [1,512,1,1], Format/Datatype: Thirty-two wide channel vectorized row major Int8 format }], Outputs: [ { Name: Reformatted Input Tensor 0 to fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise], Location: Device, Dimensions: [1,512,1,1], Format/Datatype: Four wide channel vectorized row major Int8 format }], TacticValue: 0x0000000000000000
Name: fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise], LayerType: CaskConvolution, Inputs: [ { Name: Reformatted Input Tensor 0 to fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise], Location: Device, Dimensions: [1,512,1,1], Format/Datatype: Four wide channel vectorized row major Int8 format }], Outputs: [ { Name: (Unnamed Layer* 356) [ElementWise]_out_tensor, Location: Device, Dimensions: [1,1000,1,1], Format/Datatype: Row major linear FP32 }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 1000, Groups: 1, Weights: {"Type": "Int8", "Count": 512000}, Bias: {"Type": "Float", "Count": 1000}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm70_xmma_fprop_conv1x1_i8f32_f32_f32_nchw_vect_c_4kcrs_vect_c_4_nchw_simt_small_batch_bias_relu, TacticValue: 0xc073b0053ce90eac
Name: copied_squeeze_after_(Unnamed Layer* 356) [ElementWise], LayerType: NoOp, Inputs: [ { Name: (Unnamed Layer* 356) [ElementWise]_out_tensor, Location: Device, Dimensions: [1,1000,1,1], Format/Datatype: Row major linear FP32 }], Outputs: [ { Name: 527, Location: Device, Dimensions: [1,1000], Format/Datatype: Row major linear FP32 }], TacticValue: 0x0000000000000000
Name: Softmax_312, LayerType: CudaSoftMax, Inputs: [ { Name: 527, Location: Device, Dimensions: [1,1000], Format/Datatype: Row major linear FP32 }], Outputs: [ { Name: 528, Location: Device, Dimensions: [1,1000], Format/Datatype: Row major linear FP32 }], ParameterType: SoftMax, Axes: 2, HasLog: 0, TacticValue: 0x00000000000003e9

Bindings:
inputs.1
528
[08/20/2024-19:31:54] [I] Starting inference
[08/20/2024-19:31:57] [I] Warmup completed 1257 queries over 200 ms
[08/20/2024-19:31:57] [I] Timing trace has 21990 queries over 3.00022 s
[08/20/2024-19:31:57] [I] 
[08/20/2024-19:31:57] [I] === Trace details ===
[08/20/2024-19:31:57] [I] Trace averages of 10 runs:
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134042 ms - Host latency: 0.134042 ms (enqueue 0.00496979 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134042 ms - Host latency: 0.134042 ms (enqueue 0.00724945 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00484009 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134145 ms - Host latency: 0.134145 ms (enqueue 0.00314789 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134146 ms - Host latency: 0.134146 ms (enqueue 0.00422363 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134041 ms - Host latency: 0.134041 ms (enqueue 0.00318604 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133939 ms - Host latency: 0.133939 ms (enqueue 0.00315399 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.135988 ms - Host latency: 0.135988 ms (enqueue 0.00314941 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134042 ms - Host latency: 0.134042 ms (enqueue 0.00345917 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00403748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134145 ms - Host latency: 0.134145 ms (enqueue 0.0032196 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134042 ms - Host latency: 0.134042 ms (enqueue 0.00318909 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133836 ms - Host latency: 0.133836 ms (enqueue 0.0032486 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00325317 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00358887 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134041 ms - Host latency: 0.134041 ms (enqueue 0.00394745 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00580597 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134042 ms - Host latency: 0.134042 ms (enqueue 0.00410461 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00418091 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.135782 ms - Host latency: 0.135782 ms (enqueue 0.00517273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134145 ms - Host latency: 0.134145 ms (enqueue 0.0055069 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134245 ms - Host latency: 0.134245 ms (enqueue 0.00435944 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134041 ms - Host latency: 0.134041 ms (enqueue 0.00318909 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13394 ms - Host latency: 0.13394 ms (enqueue 0.0032608 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134041 ms - Host latency: 0.134041 ms (enqueue 0.00362244 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134349 ms - Host latency: 0.134349 ms (enqueue 0.0032486 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134145 ms - Host latency: 0.134145 ms (enqueue 0.00320435 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133836 ms - Host latency: 0.133836 ms (enqueue 0.0033493 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13445 ms - Host latency: 0.13445 ms (enqueue 0.00344696 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.167117 ms - Host latency: 0.167117 ms (enqueue 0.00344238 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.148891 ms - Host latency: 0.148891 ms (enqueue 0.00410767 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133836 ms - Host latency: 0.133836 ms (enqueue 0.00439606 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134145 ms - Host latency: 0.134145 ms (enqueue 0.00372009 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134349 ms - Host latency: 0.134349 ms (enqueue 0.00341949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134451 ms - Host latency: 0.134451 ms (enqueue 0.00371552 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134146 ms - Host latency: 0.134146 ms (enqueue 0.00570984 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134042 ms - Host latency: 0.134042 ms (enqueue 0.00308075 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00321045 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00305328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133838 ms - Host latency: 0.133838 ms (enqueue 0.00312805 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134248 ms - Host latency: 0.134248 ms (enqueue 0.00333099 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00355835 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00323791 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00335083 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00323486 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134244 ms - Host latency: 0.134244 ms (enqueue 0.00474854 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134344 ms - Host latency: 0.134344 ms (enqueue 0.00310669 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134152 ms - Host latency: 0.134152 ms (enqueue 0.00437927 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13414 ms - Host latency: 0.13414 ms (enqueue 0.00460205 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00321045 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00315247 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.135153 ms - Host latency: 0.135153 ms (enqueue 0.00415344 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134134 ms - Host latency: 0.134134 ms (enqueue 0.00337524 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00349426 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133838 ms - Host latency: 0.133838 ms (enqueue 0.00367432 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134146 ms - Host latency: 0.134146 ms (enqueue 0.00348206 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00341492 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.0104248 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133942 ms - Host latency: 0.133942 ms (enqueue 0.0107544 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134256 ms - Host latency: 0.134256 ms (enqueue 0.00345459 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.00323791 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.135999 ms - Host latency: 0.135999 ms (enqueue 0.0174133 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.0047821 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134048 ms - Host latency: 0.134048 ms (enqueue 0.0045929 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.0059967 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134036 ms - Host latency: 0.134036 ms (enqueue 0.00313721 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00320129 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134454 ms - Host latency: 0.134454 ms (enqueue 0.00310974 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134036 ms - Host latency: 0.134036 ms (enqueue 0.0032196 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13425 ms - Host latency: 0.13425 ms (enqueue 0.00328064 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00318298 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00335083 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134546 ms - Host latency: 0.134546 ms (enqueue 0.00873413 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13414 ms - Host latency: 0.13414 ms (enqueue 0.00371094 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133942 ms - Host latency: 0.133942 ms (enqueue 0.00439453 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00389404 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00328064 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134042 ms - Host latency: 0.134042 ms (enqueue 0.003479 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134042 ms - Host latency: 0.134042 ms (enqueue 0.00354004 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.0036377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.00349426 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00336609 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00341187 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134048 ms - Host latency: 0.134048 ms (enqueue 0.00342407 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134259 ms - Host latency: 0.134259 ms (enqueue 0.00364075 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134042 ms - Host latency: 0.134042 ms (enqueue 0.00370789 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13446 ms - Host latency: 0.13446 ms (enqueue 0.00481873 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134256 ms - Host latency: 0.134256 ms (enqueue 0.00350037 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134232 ms - Host latency: 0.134232 ms (enqueue 0.0033783 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134332 ms - Host latency: 0.134332 ms (enqueue 0.00415344 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00653381 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.135172 ms - Host latency: 0.135172 ms (enqueue 0.0241364 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134348 ms - Host latency: 0.134348 ms (enqueue 0.00340881 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134042 ms - Host latency: 0.134042 ms (enqueue 0.00309143 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134344 ms - Host latency: 0.134344 ms (enqueue 0.00309143 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.00326538 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134146 ms - Host latency: 0.134146 ms (enqueue 0.00317993 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134238 ms - Host latency: 0.134238 ms (enqueue 0.00310059 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134036 ms - Host latency: 0.134036 ms (enqueue 0.00316162 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13414 ms - Host latency: 0.13414 ms (enqueue 0.00327759 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13425 ms - Host latency: 0.13425 ms (enqueue 0.0031189 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134036 ms - Host latency: 0.134036 ms (enqueue 0.00395203 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00491638 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.138962 ms - Host latency: 0.138962 ms (enqueue 0.00766907 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134152 ms - Host latency: 0.134152 ms (enqueue 0.00387878 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134146 ms - Host latency: 0.134146 ms (enqueue 0.0032196 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00444946 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13425 ms - Host latency: 0.13425 ms (enqueue 0.00343018 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134152 ms - Host latency: 0.134152 ms (enqueue 0.00330505 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134152 ms - Host latency: 0.134152 ms (enqueue 0.00359497 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00340576 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00326538 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134146 ms - Host latency: 0.134146 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13425 ms - Host latency: 0.13425 ms (enqueue 0.00350647 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00342102 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134549 ms - Host latency: 0.134549 ms (enqueue 0.0032074 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.00360107 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134238 ms - Host latency: 0.134238 ms (enqueue 0.00417175 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134235 ms - Host latency: 0.134235 ms (enqueue 0.00366211 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134235 ms - Host latency: 0.134235 ms (enqueue 0.00390015 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.00340271 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134152 ms - Host latency: 0.134152 ms (enqueue 0.00347595 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134259 ms - Host latency: 0.134259 ms (enqueue 0.00349426 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00350647 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.00354614 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.00345459 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134348 ms - Host latency: 0.134348 ms (enqueue 0.00350952 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.00392456 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00781555 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134146 ms - Host latency: 0.134146 ms (enqueue 0.00605469 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134341 ms - Host latency: 0.134341 ms (enqueue 0.0032196 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134348 ms - Host latency: 0.134348 ms (enqueue 0.0032196 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133838 ms - Host latency: 0.133838 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.136191 ms - Host latency: 0.136191 ms (enqueue 0.00861206 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00330811 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134244 ms - Host latency: 0.134244 ms (enqueue 0.00328369 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134348 ms - Host latency: 0.134348 ms (enqueue 0.00343933 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00329285 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134036 ms - Host latency: 0.134036 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.0032074 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00331421 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.164456 ms - Host latency: 0.164456 ms (enqueue 0.00491333 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.148575 ms - Host latency: 0.148575 ms (enqueue 0.00446167 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.189847 ms - Host latency: 0.189847 ms (enqueue 0.0786804 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.136707 ms - Host latency: 0.136707 ms (enqueue 0.0179993 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134027 ms - Host latency: 0.134027 ms (enqueue 0.00440979 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.004953 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00448303 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134152 ms - Host latency: 0.134152 ms (enqueue 0.00411682 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13414 ms - Host latency: 0.13414 ms (enqueue 0.00409546 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134134 ms - Host latency: 0.134134 ms (enqueue 0.00418091 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00410767 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00317993 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00317078 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134238 ms - Host latency: 0.134238 ms (enqueue 0.00321045 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00326843 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00397644 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134344 ms - Host latency: 0.134344 ms (enqueue 0.00446777 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00426025 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13436 ms - Host latency: 0.13436 ms (enqueue 0.00731201 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00300598 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134335 ms - Host latency: 0.134335 ms (enqueue 0.00548706 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133841 ms - Host latency: 0.133841 ms (enqueue 0.00368958 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.138016 ms - Host latency: 0.138016 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00340271 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00325623 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.135373 ms - Host latency: 0.135373 ms (enqueue 0.00343628 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134152 ms - Host latency: 0.134152 ms (enqueue 0.00350037 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13414 ms - Host latency: 0.13414 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00329285 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134238 ms - Host latency: 0.134238 ms (enqueue 0.00325012 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134152 ms - Host latency: 0.134152 ms (enqueue 0.00410767 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134354 ms - Host latency: 0.134354 ms (enqueue 0.00465698 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133939 ms - Host latency: 0.133939 ms (enqueue 0.0048584 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134259 ms - Host latency: 0.134259 ms (enqueue 0.00362244 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13425 ms - Host latency: 0.13425 ms (enqueue 0.0052948 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134134 ms - Host latency: 0.134134 ms (enqueue 0.00507812 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133933 ms - Host latency: 0.133933 ms (enqueue 0.0106262 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00846863 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13403 ms - Host latency: 0.13403 ms (enqueue 0.00326843 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134238 ms - Host latency: 0.134238 ms (enqueue 0.00322876 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13425 ms - Host latency: 0.13425 ms (enqueue 0.00355835 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134146 ms - Host latency: 0.134146 ms (enqueue 0.0218445 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134244 ms - Host latency: 0.134244 ms (enqueue 0.0039856 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134244 ms - Host latency: 0.134244 ms (enqueue 0.00376282 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.0134521 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00457153 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133939 ms - Host latency: 0.133939 ms (enqueue 0.006604 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134558 ms - Host latency: 0.134558 ms (enqueue 0.0309448 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134146 ms - Host latency: 0.134146 ms (enqueue 0.0098114 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.138235 ms - Host latency: 0.138235 ms (enqueue 0.0132904 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13414 ms - Host latency: 0.13414 ms (enqueue 0.00897522 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134146 ms - Host latency: 0.134146 ms (enqueue 0.00802917 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134451 ms - Host latency: 0.134451 ms (enqueue 0.00822144 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134244 ms - Host latency: 0.134244 ms (enqueue 0.00508728 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00443115 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134454 ms - Host latency: 0.134454 ms (enqueue 0.00449219 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134036 ms - Host latency: 0.134036 ms (enqueue 0.00418701 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13414 ms - Host latency: 0.13414 ms (enqueue 0.00516357 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134134 ms - Host latency: 0.134134 ms (enqueue 0.00724487 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134457 ms - Host latency: 0.134457 ms (enqueue 0.00609131 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.144791 ms - Host latency: 0.144791 ms (enqueue 0.00752258 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00708618 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134457 ms - Host latency: 0.134457 ms (enqueue 0.00469055 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00514526 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00517883 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.141721 ms - Host latency: 0.141721 ms (enqueue 0.0216705 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.181461 ms - Host latency: 0.181461 ms (enqueue 0.0767365 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.00666809 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.0063324 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134244 ms - Host latency: 0.134244 ms (enqueue 0.00629883 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00621643 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134152 ms - Host latency: 0.134152 ms (enqueue 0.00616455 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13436 ms - Host latency: 0.13436 ms (enqueue 0.00523376 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00569153 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134354 ms - Host latency: 0.134354 ms (enqueue 0.00529175 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00529175 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134354 ms - Host latency: 0.134354 ms (enqueue 0.00465088 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134354 ms - Host latency: 0.134354 ms (enqueue 0.00658569 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00491333 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00637817 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134344 ms - Host latency: 0.134344 ms (enqueue 0.00397339 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00455322 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.00385132 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00388794 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.00360107 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.0036377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.00377197 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00372314 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00372925 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00369873 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00369263 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00430908 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00327759 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134259 ms - Host latency: 0.134259 ms (enqueue 0.00496826 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134259 ms - Host latency: 0.134259 ms (enqueue 0.00426025 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.0045105 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13446 ms - Host latency: 0.13446 ms (enqueue 0.00351562 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00349731 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00333862 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134344 ms - Host latency: 0.134344 ms (enqueue 0.00357056 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00339966 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134332 ms - Host latency: 0.134332 ms (enqueue 0.00387573 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134558 ms - Host latency: 0.134558 ms (enqueue 0.00402222 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00389404 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.0039978 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.17724 ms - Host latency: 0.17724 ms (enqueue 0.00379028 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134442 ms - Host latency: 0.134442 ms (enqueue 0.00342407 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00355835 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00332642 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.00356445 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134052 ms - Host latency: 0.134052 ms (enqueue 0.00326538 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134259 ms - Host latency: 0.134259 ms (enqueue 0.00326538 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.0034729 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134344 ms - Host latency: 0.134344 ms (enqueue 0.00336304 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134344 ms - Host latency: 0.134344 ms (enqueue 0.00444946 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00319824 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.003125 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00314941 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.00319214 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.003302 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00432129 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133948 ms - Host latency: 0.133948 ms (enqueue 0.00337524 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.0032898 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.00349731 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.00369873 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00415039 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134235 ms - Host latency: 0.134235 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.00350342 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134259 ms - Host latency: 0.134259 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00446777 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00634766 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00366821 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134235 ms - Host latency: 0.134235 ms (enqueue 0.00544434 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.0041687 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00394897 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00313721 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00314941 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00338745 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00386353 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00319214 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134259 ms - Host latency: 0.134259 ms (enqueue 0.00357666 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.003302 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00360107 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00330811 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00426025 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134259 ms - Host latency: 0.134259 ms (enqueue 0.0031311 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00379028 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134052 ms - Host latency: 0.134052 ms (enqueue 0.00326538 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134052 ms - Host latency: 0.134052 ms (enqueue 0.00331421 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00668945 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134027 ms - Host latency: 0.134027 ms (enqueue 0.00322876 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00308228 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00309448 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134259 ms - Host latency: 0.134259 ms (enqueue 0.003302 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00322266 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13446 ms - Host latency: 0.13446 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00336304 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00335083 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.00326538 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00383911 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134027 ms - Host latency: 0.134027 ms (enqueue 0.0031189 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134052 ms - Host latency: 0.134052 ms (enqueue 0.00324097 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134052 ms - Host latency: 0.134052 ms (enqueue 0.015802 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00734863 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00352173 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134344 ms - Host latency: 0.134344 ms (enqueue 0.00345459 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00308838 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.0031311 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00316772 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134259 ms - Host latency: 0.134259 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.0031311 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00324097 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00313721 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00333252 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134552 ms - Host latency: 0.134552 ms (enqueue 0.00376587 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00307007 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134052 ms - Host latency: 0.134052 ms (enqueue 0.00369873 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00319214 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134235 ms - Host latency: 0.134235 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.00350342 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00314941 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00317383 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00320435 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134344 ms - Host latency: 0.134344 ms (enqueue 0.0032898 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00357056 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.161884 ms - Host latency: 0.161884 ms (enqueue 0.00332642 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.148694 ms - Host latency: 0.148694 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134344 ms - Host latency: 0.134344 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00388794 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00369873 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.003302 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00324097 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134027 ms - Host latency: 0.134027 ms (enqueue 0.00338135 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00311279 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134259 ms - Host latency: 0.134259 ms (enqueue 0.00320435 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133948 ms - Host latency: 0.133948 ms (enqueue 0.00310059 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00384521 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00319214 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00311279 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.0031189 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00309448 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134259 ms - Host latency: 0.134259 ms (enqueue 0.003302 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00394287 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134052 ms - Host latency: 0.134052 ms (enqueue 0.00300903 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133923 ms - Host latency: 0.133923 ms (enqueue 0.00648193 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134332 ms - Host latency: 0.134332 ms (enqueue 0.00317383 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.135486 ms - Host latency: 0.135486 ms (enqueue 0.00386963 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00806885 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00419312 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00321045 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00333252 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00322876 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00366211 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00324097 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00369263 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00480957 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00308838 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134772 ms - Host latency: 0.134772 ms (enqueue 0.00487671 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134442 ms - Host latency: 0.134442 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.162708 ms - Host latency: 0.162708 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.148895 ms - Host latency: 0.148895 ms (enqueue 0.00341187 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.0279785 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00457153 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00458984 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.00403442 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.141193 ms - Host latency: 0.141193 ms (enqueue 0.0140503 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00622559 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00450439 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00724487 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.00316162 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00379639 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00343628 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00336304 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134344 ms - Host latency: 0.134344 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.0216858 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.0050354 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00305786 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00352173 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00331421 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.00357666 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00309448 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.00510864 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.0046875 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00447998 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.0045105 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134436 ms - Host latency: 0.134436 ms (enqueue 0.00450439 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.00470581 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134052 ms - Host latency: 0.134052 ms (enqueue 0.00474243 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00449219 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00492554 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134332 ms - Host latency: 0.134332 ms (enqueue 0.00438232 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00314941 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133948 ms - Host latency: 0.133948 ms (enqueue 0.00325317 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00332642 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00320435 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00337524 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00360718 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13454 ms - Host latency: 0.13454 ms (enqueue 0.00379028 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134344 ms - Host latency: 0.134344 ms (enqueue 0.00372314 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00331421 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00906372 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00436401 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.00518799 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134052 ms - Host latency: 0.134052 ms (enqueue 0.00466919 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.0038147 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00326538 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.136609 ms - Host latency: 0.136609 ms (enqueue 0.003125 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00299683 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00310059 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00332642 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00386353 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00306396 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00370483 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.00303345 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00370483 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134344 ms - Host latency: 0.134344 ms (enqueue 0.00318604 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134021 ms - Host latency: 0.134021 ms (enqueue 0.00305176 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134027 ms - Host latency: 0.134027 ms (enqueue 0.00336304 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00354614 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00337524 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00359497 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134442 ms - Host latency: 0.134442 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134259 ms - Host latency: 0.134259 ms (enqueue 0.00333252 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134052 ms - Host latency: 0.134052 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00363159 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.00368042 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134332 ms - Host latency: 0.134332 ms (enqueue 0.0034729 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00419312 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13446 ms - Host latency: 0.13446 ms (enqueue 0.00308228 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00400391 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134259 ms - Host latency: 0.134259 ms (enqueue 0.00355225 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.0046936 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133838 ms - Host latency: 0.133838 ms (enqueue 0.00449219 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00470581 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00464478 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00526733 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.0152405 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.0255432 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0273621 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134259 ms - Host latency: 0.134259 ms (enqueue 0.00726929 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00533447 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00447998 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00549927 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00498047 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134235 ms - Host latency: 0.134235 ms (enqueue 0.00506592 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134863 ms - Host latency: 0.134863 ms (enqueue 0.00308228 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00350952 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00320435 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13457 ms - Host latency: 0.13457 ms (enqueue 0.00324097 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.00306396 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00336304 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00393677 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.0036377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133948 ms - Host latency: 0.133948 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134442 ms - Host latency: 0.134442 ms (enqueue 0.00331421 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13374 ms - Host latency: 0.13374 ms (enqueue 0.00353394 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00446167 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.00391846 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00336304 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134235 ms - Host latency: 0.134235 ms (enqueue 0.00366821 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.00339966 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00358887 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134052 ms - Host latency: 0.134052 ms (enqueue 0.00333862 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.0034729 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134344 ms - Host latency: 0.134344 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134332 ms - Host latency: 0.134332 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00462647 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133942 ms - Host latency: 0.133942 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00469971 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00345459 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00549316 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00537109 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.162811 ms - Host latency: 0.162811 ms (enqueue 0.0062561 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.149091 ms - Host latency: 0.149091 ms (enqueue 0.00461426 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134235 ms - Host latency: 0.134235 ms (enqueue 0.00435791 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00545044 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00465698 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00450439 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.0045166 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00455322 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00481567 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00506592 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00480347 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00467529 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.00456543 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00441895 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00457153 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.00459595 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00440063 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00325928 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00314941 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.00315552 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133948 ms - Host latency: 0.133948 ms (enqueue 0.00346069 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00356445 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00374756 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00449829 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00311279 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.003125 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.003479 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.00341187 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.0034729 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00323486 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134222 ms - Host latency: 0.134222 ms (enqueue 0.00330811 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134235 ms - Host latency: 0.134235 ms (enqueue 0.00369263 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134235 ms - Host latency: 0.134235 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134344 ms - Host latency: 0.134344 ms (enqueue 0.00342407 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00357666 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.003479 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.00341187 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00331421 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13446 ms - Host latency: 0.13446 ms (enqueue 0.003302 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.00407715 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00375366 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00425415 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134235 ms - Host latency: 0.134235 ms (enqueue 0.00342407 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00346069 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00344849 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134515 ms - Host latency: 0.134515 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00361938 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00350952 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13446 ms - Host latency: 0.13446 ms (enqueue 0.00308228 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00367432 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00338135 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00377808 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.00325317 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134235 ms - Host latency: 0.134235 ms (enqueue 0.00368042 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00320435 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00311279 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00315552 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00317993 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00315552 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134344 ms - Host latency: 0.134344 ms (enqueue 0.00315552 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00358276 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00386353 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00359497 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133838 ms - Host latency: 0.133838 ms (enqueue 0.00387573 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13465 ms - Host latency: 0.13465 ms (enqueue 0.00314941 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00374756 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00476685 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134357 ms - Host latency: 0.134357 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00322266 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00317383 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134149 ms - Host latency: 0.134149 ms (enqueue 0.00360718 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13454 ms - Host latency: 0.13454 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00474854 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00313721 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00314331 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00707397 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133923 ms - Host latency: 0.133923 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134052 ms - Host latency: 0.134052 ms (enqueue 0.00371704 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.00337524 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00383911 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00333862 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134235 ms - Host latency: 0.134235 ms (enqueue 0.00370483 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134332 ms - Host latency: 0.134332 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00390015 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.00510254 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00449219 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00453491 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134247 ms - Host latency: 0.134247 ms (enqueue 0.00361938 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134039 ms - Host latency: 0.134039 ms (enqueue 0.00377197 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134137 ms - Host latency: 0.134137 ms (enqueue 0.0043457 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134027 ms - Host latency: 0.134027 ms (enqueue 0.00397339 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00376587 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13446 ms - Host latency: 0.13446 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.00372314 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00323486 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134119 ms - Host latency: 0.134119 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00333252 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00384521 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134619 ms - Host latency: 0.134619 ms (enqueue 0.00426025 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134473 ms - Host latency: 0.134473 ms (enqueue 0.00406494 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00371094 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134668 ms - Host latency: 0.134668 ms (enqueue 0.00501709 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.180334 ms - Host latency: 0.180334 ms (enqueue 0.00330811 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134021 ms - Host latency: 0.134021 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00318604 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134875 ms - Host latency: 0.134875 ms (enqueue 0.00323486 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134009 ms - Host latency: 0.134009 ms (enqueue 0.00343018 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.0036377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00396729 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00367432 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.136414 ms - Host latency: 0.136414 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00345459 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.135791 ms - Host latency: 0.135791 ms (enqueue 0.00412598 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00322266 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00406494 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00322266 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13446 ms - Host latency: 0.13446 ms (enqueue 0.00319824 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00340576 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13689 ms - Host latency: 0.13689 ms (enqueue 0.00396729 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00328369 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00316162 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00379639 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00308838 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00343018 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00352783 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00456543 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13446 ms - Host latency: 0.13446 ms (enqueue 0.00360107 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00410156 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133997 ms - Host latency: 0.133997 ms (enqueue 0.00344238 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00386963 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00377197 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134412 ms - Host latency: 0.134412 ms (enqueue 0.00411377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00362549 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.0043457 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00316162 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00601807 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00428467 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00362549 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00406494 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00386963 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00411377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.0036499 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00471191 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00319824 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00632324 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134021 ms - Host latency: 0.134021 ms (enqueue 0.00330811 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00568848 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00406494 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00592041 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.0123657 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134473 ms - Host latency: 0.134473 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00338135 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133948 ms - Host latency: 0.133948 ms (enqueue 0.00334473 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133923 ms - Host latency: 0.133923 ms (enqueue 0.00356445 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00333252 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00411377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00321045 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00318604 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00474854 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134839 ms - Host latency: 0.134839 ms (enqueue 0.00396729 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.135852 ms - Host latency: 0.135852 ms (enqueue 0.00362549 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00335693 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134167 ms - Host latency: 0.134167 ms (enqueue 0.00380859 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00335693 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134021 ms - Host latency: 0.134021 ms (enqueue 0.00345459 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134656 ms - Host latency: 0.134656 ms (enqueue 0.00472412 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134167 ms - Host latency: 0.134167 ms (enqueue 0.003125 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.0036499 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00321045 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.0039917 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134021 ms - Host latency: 0.134021 ms (enqueue 0.00335693 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00360107 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00313721 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.00318604 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00318604 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00335693 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00340576 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0038208 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00350342 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00335693 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133948 ms - Host latency: 0.133948 ms (enqueue 0.00345459 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00334473 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.0036499 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134521 ms - Host latency: 0.134521 ms (enqueue 0.00340576 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00360107 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.003479 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134021 ms - Host latency: 0.134021 ms (enqueue 0.00355225 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00354004 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00432129 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00350342 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.0039917 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00394287 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00430908 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134009 ms - Host latency: 0.134009 ms (enqueue 0.00351562 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00352783 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.00344238 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.0036377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.149792 ms - Host latency: 0.149792 ms (enqueue 0.00413818 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.163232 ms - Host latency: 0.163232 ms (enqueue 0.0038208 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00477295 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00325928 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00548096 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00411377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00367432 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00335693 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00333252 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.0036377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00343018 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00343018 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134021 ms - Host latency: 0.134021 ms (enqueue 0.00345459 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00343018 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.0041626 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00313721 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00345459 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00345459 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.0039917 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134021 ms - Host latency: 0.134021 ms (enqueue 0.00323486 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00356445 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00333252 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133948 ms - Host latency: 0.133948 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134473 ms - Host latency: 0.134473 ms (enqueue 0.00340576 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00506592 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00662842 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133948 ms - Host latency: 0.133948 ms (enqueue 0.00322266 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00377197 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00318604 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134119 ms - Host latency: 0.134119 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00460205 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00313721 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00328369 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133923 ms - Host latency: 0.133923 ms (enqueue 0.00333252 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00328369 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00344238 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00350342 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00389404 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.180115 ms - Host latency: 0.180115 ms (enqueue 0.00477295 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00471191 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00463867 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00465088 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00501709 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00345459 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134216 ms - Host latency: 0.134216 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134167 ms - Host latency: 0.134167 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00340576 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00374756 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134119 ms - Host latency: 0.134119 ms (enqueue 0.0036499 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00396729 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134485 ms - Host latency: 0.134485 ms (enqueue 0.0072998 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133948 ms - Host latency: 0.133948 ms (enqueue 0.00682373 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134119 ms - Host latency: 0.134119 ms (enqueue 0.00313721 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00350342 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00350342 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00357666 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134119 ms - Host latency: 0.134119 ms (enqueue 0.00357666 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134119 ms - Host latency: 0.134119 ms (enqueue 0.00480957 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.0041626 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133948 ms - Host latency: 0.133948 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00418701 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00338135 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00351562 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00350342 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00334473 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00330811 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134021 ms - Host latency: 0.134021 ms (enqueue 0.00351562 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00374756 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134021 ms - Host latency: 0.134021 ms (enqueue 0.00351562 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133923 ms - Host latency: 0.133923 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.00352783 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13396 ms - Host latency: 0.13396 ms (enqueue 0.00400391 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00322266 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.0041626 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13385 ms - Host latency: 0.13385 ms (enqueue 0.00354004 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00343018 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134119 ms - Host latency: 0.134119 ms (enqueue 0.00357666 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.135693 ms - Host latency: 0.135693 ms (enqueue 0.0043457 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00421143 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00441895 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00351562 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00535889 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134021 ms - Host latency: 0.134021 ms (enqueue 0.0067627 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00360107 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00371094 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00330811 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.003125 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133997 ms - Host latency: 0.133997 ms (enqueue 0.00308838 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134021 ms - Host latency: 0.134021 ms (enqueue 0.00330811 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00319824 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134436 ms - Host latency: 0.134436 ms (enqueue 0.00380859 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00307617 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00372314 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133948 ms - Host latency: 0.133948 ms (enqueue 0.00340576 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.003479 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133899 ms - Host latency: 0.133899 ms (enqueue 0.00726318 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00440674 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00421143 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.150208 ms - Host latency: 0.150208 ms (enqueue 0.00462647 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.16322 ms - Host latency: 0.16322 ms (enqueue 0.00469971 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00440674 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00450439 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13446 ms - Host latency: 0.13446 ms (enqueue 0.00423584 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00479736 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00461426 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00372314 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00311279 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13446 ms - Host latency: 0.13446 ms (enqueue 0.00430908 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134546 ms - Host latency: 0.134546 ms (enqueue 0.00369873 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00367432 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13396 ms - Host latency: 0.13396 ms (enqueue 0.0036499 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133899 ms - Host latency: 0.133899 ms (enqueue 0.00343018 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00351562 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00360107 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.0036377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.00507812 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00371094 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00367432 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134473 ms - Host latency: 0.134473 ms (enqueue 0.00411377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00384521 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00325928 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00340576 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134473 ms - Host latency: 0.134473 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134216 ms - Host latency: 0.134216 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134656 ms - Host latency: 0.134656 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134167 ms - Host latency: 0.134167 ms (enqueue 0.00408936 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00430908 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00466309 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133923 ms - Host latency: 0.133923 ms (enqueue 0.00322266 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00351562 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134216 ms - Host latency: 0.134216 ms (enqueue 0.00394287 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134924 ms - Host latency: 0.134924 ms (enqueue 0.00599365 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.00380859 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134473 ms - Host latency: 0.134473 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134216 ms - Host latency: 0.134216 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134521 ms - Host latency: 0.134521 ms (enqueue 0.00377197 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.0036499 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.136292 ms - Host latency: 0.136292 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00366211 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134021 ms - Host latency: 0.134021 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134839 ms - Host latency: 0.134839 ms (enqueue 0.00631104 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134009 ms - Host latency: 0.134009 ms (enqueue 0.00743408 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00435791 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134167 ms - Host latency: 0.134167 ms (enqueue 0.00357666 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00693359 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00340576 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00343018 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.135632 ms - Host latency: 0.135632 ms (enqueue 0.00386963 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134216 ms - Host latency: 0.134216 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00316162 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.003125 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134216 ms - Host latency: 0.134216 ms (enqueue 0.00344238 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00323486 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.003125 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134021 ms - Host latency: 0.134021 ms (enqueue 0.00352783 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13396 ms - Host latency: 0.13396 ms (enqueue 0.00367432 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00350342 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00426025 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.00313721 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00303955 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134167 ms - Host latency: 0.134167 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00314941 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00317383 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00328369 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00321045 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00335693 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00345459 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00371094 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00389404 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00489502 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00991211 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00313721 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134314 ms - Host latency: 0.134314 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00314941 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00322266 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00318604 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00303955 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00307617 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00301514 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.139233 ms - Host latency: 0.139233 ms (enqueue 0.00994873 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13407 ms - Host latency: 0.13407 ms (enqueue 0.00350342 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00396729 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134119 ms - Host latency: 0.134119 ms (enqueue 0.00357666 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00323486 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.162915 ms - Host latency: 0.162915 ms (enqueue 0.00386963 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.148499 ms - Host latency: 0.148499 ms (enqueue 0.00355225 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134216 ms - Host latency: 0.134216 ms (enqueue 0.00343018 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00334473 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00432129 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00554199 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00323486 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134412 ms - Host latency: 0.134412 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00343018 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00323486 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00314941 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134644 ms - Host latency: 0.134644 ms (enqueue 0.00313721 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00426025 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00335693 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00335693 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00323486 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134473 ms - Host latency: 0.134473 ms (enqueue 0.00344238 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00386963 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0039917 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.003125 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00334473 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.136902 ms - Host latency: 0.136902 ms (enqueue 0.00898437 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00354004 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00340576 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00351562 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134961 ms - Host latency: 0.134961 ms (enqueue 0.00362549 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134167 ms - Host latency: 0.134167 ms (enqueue 0.00410156 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00351562 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13446 ms - Host latency: 0.13446 ms (enqueue 0.003479 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00350342 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00966797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00446777 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00418701 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13446 ms - Host latency: 0.13446 ms (enqueue 0.00306396 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134656 ms - Host latency: 0.134656 ms (enqueue 0.00394287 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00340576 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00311279 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00325928 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00335693 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00338135 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00322266 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00358887 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00334473 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00330811 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00345459 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00424805 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00350342 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134119 ms - Host latency: 0.134119 ms (enqueue 0.00345459 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00323486 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00408936 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134119 ms - Host latency: 0.134119 ms (enqueue 0.00316162 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00314941 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134631 ms - Host latency: 0.134631 ms (enqueue 0.00323486 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00317383 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00319824 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00343018 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00428467 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00646973 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00563965 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00321045 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00317383 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00333252 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00318604 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00333252 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00328369 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00322266 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00330811 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00318604 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00571289 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134167 ms - Host latency: 0.134167 ms (enqueue 0.0036499 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00333252 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00371094 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00317383 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134167 ms - Host latency: 0.134167 ms (enqueue 0.00366211 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134314 ms - Host latency: 0.134314 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00366211 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.0038208 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00356445 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134558 ms - Host latency: 0.134558 ms (enqueue 0.00352783 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00321045 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00469971 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00401611 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00317383 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134167 ms - Host latency: 0.134167 ms (enqueue 0.00333252 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00582275 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00345459 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134119 ms - Host latency: 0.134119 ms (enqueue 0.00322266 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00344238 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134119 ms - Host latency: 0.134119 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133813 ms - Host latency: 0.133813 ms (enqueue 0.00330811 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134119 ms - Host latency: 0.134119 ms (enqueue 0.00460205 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00356445 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00343018 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00350342 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0036377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00445557 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00314941 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00428467 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00352783 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00384521 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00317383 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00369873 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00366211 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00358887 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00360107 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00394287 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00377197 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00360107 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00369873 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133948 ms - Host latency: 0.133948 ms (enqueue 0.00386963 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00404053 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00439453 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134021 ms - Host latency: 0.134021 ms (enqueue 0.00335693 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134167 ms - Host latency: 0.134167 ms (enqueue 0.00411377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00396729 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00377197 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00356445 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133948 ms - Host latency: 0.133948 ms (enqueue 0.0041626 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.0036377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00334473 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134009 ms - Host latency: 0.134009 ms (enqueue 0.00408936 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134546 ms - Host latency: 0.134546 ms (enqueue 0.00313721 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00391846 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00415039 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.153918 ms - Host latency: 0.153918 ms (enqueue 0.00369873 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.196716 ms - Host latency: 0.196716 ms (enqueue 0.00421143 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00351562 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.152576 ms - Host latency: 0.152576 ms (enqueue 0.00355225 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00366211 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00350342 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00360107 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00478516 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00638428 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133752 ms - Host latency: 0.133752 ms (enqueue 0.00404053 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00386963 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00345459 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00344238 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134119 ms - Host latency: 0.134119 ms (enqueue 0.00322266 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00351562 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00372314 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.0043457 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00328369 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13446 ms - Host latency: 0.13446 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00412598 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134314 ms - Host latency: 0.134314 ms (enqueue 0.00524902 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00367432 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134424 ms - Host latency: 0.134424 ms (enqueue 0.00311279 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00330811 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00343018 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134216 ms - Host latency: 0.134216 ms (enqueue 0.00335693 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00330811 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134192 ms - Host latency: 0.134192 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134314 ms - Host latency: 0.134314 ms (enqueue 0.00500488 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.003479 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00852051 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00474854 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00473633 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134009 ms - Host latency: 0.134009 ms (enqueue 0.00380859 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00422363 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00380859 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.0036377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134094 ms - Host latency: 0.134094 ms (enqueue 0.00371094 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.0036499 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00449219 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00384521 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00345459 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00350342 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00344238 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00351562 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00351562 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00354004 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00318604 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00410156 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13446 ms - Host latency: 0.13446 ms (enqueue 0.00396729 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00389404 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00317383 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00322266 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00340576 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00352783 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.179297 ms - Host latency: 0.179297 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134021 ms - Host latency: 0.134021 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134424 ms - Host latency: 0.134424 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00384521 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.00369873 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00454102 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134216 ms - Host latency: 0.134216 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.0036377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00413818 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00330811 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134216 ms - Host latency: 0.134216 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00354004 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00325928 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00333252 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00333252 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00366211 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134167 ms - Host latency: 0.134167 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134216 ms - Host latency: 0.134216 ms (enqueue 0.00319824 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00356445 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00429688 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.003125 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00328369 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13407 ms - Host latency: 0.13407 ms (enqueue 0.00318604 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00314941 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00340576 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134521 ms - Host latency: 0.134521 ms (enqueue 0.00325928 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134119 ms - Host latency: 0.134119 ms (enqueue 0.003479 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00384521 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00391846 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00310059 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00722656 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00366211 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00379639 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00340576 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134216 ms - Host latency: 0.134216 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00335693 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134216 ms - Host latency: 0.134216 ms (enqueue 0.00377197 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00343018 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00352783 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00343018 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.003479 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00307617 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00358887 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00319824 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00321045 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00319824 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00314941 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134021 ms - Host latency: 0.134021 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00319824 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134473 ms - Host latency: 0.134473 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00350342 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00362549 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134338 ms - Host latency: 0.134338 ms (enqueue 0.00360107 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00318604 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00305176 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134021 ms - Host latency: 0.134021 ms (enqueue 0.00302734 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00321045 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134216 ms - Host latency: 0.134216 ms (enqueue 0.00415039 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00311279 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00311279 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.003125 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00322266 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00377197 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.0095459 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.149097 ms - Host latency: 0.149097 ms (enqueue 0.00726318 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.173499 ms - Host latency: 0.173499 ms (enqueue 0.00410156 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134314 ms - Host latency: 0.134314 ms (enqueue 0.00314941 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00473633 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134656 ms - Host latency: 0.134656 ms (enqueue 0.00319824 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00318604 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133838 ms - Host latency: 0.133838 ms (enqueue 0.00345459 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00356445 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.00343018 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.163342 ms - Host latency: 0.163342 ms (enqueue 0.00506592 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00407715 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00362549 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00345459 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13396 ms - Host latency: 0.13396 ms (enqueue 0.00333252 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00620117 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134509 ms - Host latency: 0.134509 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00357666 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00360107 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.0036377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00374756 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00612793 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00362549 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00367432 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.0036499 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.0043335 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00461426 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00441895 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134009 ms - Host latency: 0.134009 ms (enqueue 0.00418701 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00325928 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134119 ms - Host latency: 0.134119 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00325928 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.003479 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134167 ms - Host latency: 0.134167 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134436 ms - Host latency: 0.134436 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00386963 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00314941 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00400391 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134143 ms - Host latency: 0.134143 ms (enqueue 0.00455322 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00323486 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134167 ms - Host latency: 0.134167 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00335693 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134167 ms - Host latency: 0.134167 ms (enqueue 0.00334473 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134424 ms - Host latency: 0.134424 ms (enqueue 0.00340576 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134265 ms - Host latency: 0.134265 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134021 ms - Host latency: 0.134021 ms (enqueue 0.00333252 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134045 ms - Host latency: 0.134045 ms (enqueue 0.00410156 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134119 ms - Host latency: 0.134119 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134363 ms - Host latency: 0.134363 ms (enqueue 0.00358887 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133997 ms - Host latency: 0.133997 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00319824 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134119 ms - Host latency: 0.134119 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134241 ms - Host latency: 0.134241 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134216 ms - Host latency: 0.134216 ms (enqueue 0.00338135 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00323486 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134216 ms - Host latency: 0.134216 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00319824 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00317383 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00334473 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00344238 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00537109 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00466309 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00351562 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00354004 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00354004 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00344238 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00354004 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00344238 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00410156 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00322266 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00439453 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13457 ms - Host latency: 0.13457 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00769043 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133911 ms - Host latency: 0.133911 ms (enqueue 0.00380859 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00371094 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00371094 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.00429688 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00410156 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134839 ms - Host latency: 0.134839 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00334473 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133838 ms - Host latency: 0.133838 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00351562 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00415039 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00366211 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00400391 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00366211 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00471191 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00424805 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134546 ms - Host latency: 0.134546 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13396 ms - Host latency: 0.13396 ms (enqueue 0.00354004 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13396 ms - Host latency: 0.13396 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00319824 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133813 ms - Host latency: 0.133813 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00344238 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.0036377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00319824 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00366211 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00437012 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00424805 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00366211 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00310059 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00314941 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00305176 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.00307617 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134619 ms - Host latency: 0.134619 ms (enqueue 0.00317383 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134473 ms - Host latency: 0.134473 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00507812 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00427246 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133984 ms - Host latency: 0.133984 ms (enqueue 0.00319824 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00319824 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134644 ms - Host latency: 0.134644 ms (enqueue 0.00410156 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.16543 ms - Host latency: 0.16543 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.149438 ms - Host latency: 0.149438 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134082 ms - Host latency: 0.134082 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13479 ms - Host latency: 0.13479 ms (enqueue 0.00871582 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.0129639 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.0100586 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00490723 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00683594 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00424805 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00927734 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.0036377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00334473 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00334473 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00344238 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00432129 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00354004 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134009 ms - Host latency: 0.134009 ms (enqueue 0.00671387 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00561523 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134082 ms - Host latency: 0.134082 ms (enqueue 0.00427246 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.0123291 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00437012 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00380859 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.0036377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00444336 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134668 ms - Host latency: 0.134668 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00327148 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00400391 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.136499 ms - Host latency: 0.136499 ms (enqueue 0.00483398 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.137402 ms - Host latency: 0.137402 ms (enqueue 0.0156982 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00334473 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134424 ms - Host latency: 0.134424 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00339355 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.00344238 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00334473 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134692 ms - Host latency: 0.134692 ms (enqueue 0.0097168 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00737305 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00441895 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134009 ms - Host latency: 0.134009 ms (enqueue 0.00424805 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00444336 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134473 ms - Host latency: 0.134473 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134595 ms - Host latency: 0.134595 ms (enqueue 0.0036377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00351562 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00742187 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00620117 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00344238 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00454102 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00351562 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00461426 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00427246 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00334473 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134009 ms - Host latency: 0.134009 ms (enqueue 0.00427246 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.137109 ms - Host latency: 0.137109 ms (enqueue 0.00812988 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00947266 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00366211 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00344238 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00354004 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.00344238 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00336914 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00720215 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13584 ms - Host latency: 0.13584 ms (enqueue 0.00898437 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00424805 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00349121 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00341797 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00358887 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133838 ms - Host latency: 0.133838 ms (enqueue 0.00344238 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00407715 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.140625 ms - Host latency: 0.140625 ms (enqueue 0.0111816 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.177661 ms - Host latency: 0.177661 ms (enqueue 0.00510254 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00419922 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00756836 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00734863 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00454102 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00473633 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134424 ms - Host latency: 0.134424 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00351562 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00356445 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00366211 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.0036377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.0045166 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00476074 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.0065918 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133765 ms - Host latency: 0.133765 ms (enqueue 0.00332031 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00324707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.0032959 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00334473 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.0036377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00576172 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0155273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00551758 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00690918 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00800781 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.140063 ms - Host latency: 0.140063 ms (enqueue 0.0161377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00517578 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134595 ms - Host latency: 0.134595 ms (enqueue 0.00371094 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00366211 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134424 ms - Host latency: 0.134424 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00371094 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00415039 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00522461 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00412598 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.0034668 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.0241699 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00380859 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00400391 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00366211 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00371094 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00498047 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00610352 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00603027 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00732422 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00637207 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134473 ms - Host latency: 0.134473 ms (enqueue 0.00449219 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00424805 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00427246 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00488281 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00427246 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00454102 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00415039 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00410156 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00476074 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134399 ms - Host latency: 0.134399 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00368652 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00407715 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00424805 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134082 ms - Host latency: 0.134082 ms (enqueue 0.00419922 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00598145 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00498047 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00419922 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00422363 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.0045166 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134546 ms - Host latency: 0.134546 ms (enqueue 0.0059082 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00400391 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134082 ms - Host latency: 0.134082 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00476074 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13396 ms - Host latency: 0.13396 ms (enqueue 0.00412598 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00456543 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134644 ms - Host latency: 0.134644 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.0043457 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00446777 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00546875 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133911 ms - Host latency: 0.133911 ms (enqueue 0.00556641 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00576172 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00527344 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00366211 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00380859 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00458984 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00422363 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00410156 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00444336 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00441895 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133984 ms - Host latency: 0.133984 ms (enqueue 0.00415039 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134424 ms - Host latency: 0.134424 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00424805 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.180713 ms - Host latency: 0.180713 ms (enqueue 0.00415039 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00424805 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00703125 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00380859 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.00412598 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134009 ms - Host latency: 0.134009 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134399 ms - Host latency: 0.134399 ms (enqueue 0.00410156 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00466309 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00366211 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00515137 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133984 ms - Host latency: 0.133984 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00410156 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134424 ms - Host latency: 0.134424 ms (enqueue 0.00400391 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.0098877 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00480957 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134082 ms - Host latency: 0.134082 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13396 ms - Host latency: 0.13396 ms (enqueue 0.00424805 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134497 ms - Host latency: 0.134497 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00361328 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00415039 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134399 ms - Host latency: 0.134399 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.163818 ms - Host latency: 0.163818 ms (enqueue 0.00463867 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.148071 ms - Host latency: 0.148071 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.0036377 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13479 ms - Host latency: 0.13479 ms (enqueue 0.00478516 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134473 ms - Host latency: 0.134473 ms (enqueue 0.00600586 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00422363 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00410156 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00412598 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0043457 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00422363 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00407715 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00498047 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.00463867 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00471191 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00446777 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00588379 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00805664 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00380859 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00466309 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00380859 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00710449 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.0048584 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00478516 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00942383 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00498047 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00449219 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00380859 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00541992 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00571289 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.0057373 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00498047 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00458984 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.165991 ms - Host latency: 0.165991 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.149072 ms - Host latency: 0.149072 ms (enqueue 0.00493164 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.0043457 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00427246 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00429688 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00449219 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00439453 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00424805 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00422363 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00427246 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00415039 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134009 ms - Host latency: 0.134009 ms (enqueue 0.00422363 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.138135 ms - Host latency: 0.138135 ms (enqueue 0.0164795 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134424 ms - Host latency: 0.134424 ms (enqueue 0.00466309 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.00415039 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.0043457 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00380859 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00466309 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00400391 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00427246 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00400391 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13396 ms - Host latency: 0.13396 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00454102 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13457 ms - Host latency: 0.13457 ms (enqueue 0.00598145 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00449219 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13396 ms - Host latency: 0.13396 ms (enqueue 0.00412598 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00505371 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00439453 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00422363 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00407715 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00427246 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.135034 ms - Host latency: 0.135034 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00522461 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.136108 ms - Host latency: 0.136108 ms (enqueue 0.0043457 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00466309 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13457 ms - Host latency: 0.13457 ms (enqueue 0.00422363 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134399 ms - Host latency: 0.134399 ms (enqueue 0.00512695 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00400391 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00541992 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134082 ms - Host latency: 0.134082 ms (enqueue 0.00407715 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00471191 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134521 ms - Host latency: 0.134521 ms (enqueue 0.00432129 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.0043457 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00759277 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00522461 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00568848 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00544434 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00578613 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.0106934 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133838 ms - Host latency: 0.133838 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00400391 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00380859 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134546 ms - Host latency: 0.134546 ms (enqueue 0.00427246 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00407715 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00424805 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134595 ms - Host latency: 0.134595 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00439453 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00749512 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134546 ms - Host latency: 0.134546 ms (enqueue 0.00510254 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.0050293 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134644 ms - Host latency: 0.134644 ms (enqueue 0.00498047 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00698242 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00507812 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00449219 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00461426 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0046875 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134595 ms - Host latency: 0.134595 ms (enqueue 0.00461426 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00449219 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.135034 ms - Host latency: 0.135034 ms (enqueue 0.00742187 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00466309 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00458984 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00463867 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00454102 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00463867 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00559082 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00490723 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00476074 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00593262 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00617676 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00412598 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.177515 ms - Host latency: 0.177515 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00407715 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00444336 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.0052002 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.0045166 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.0046875 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.155371 ms (enqueue 0.00825195 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00441895 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00483398 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00441895 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00422363 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00454102 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00415039 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00412598 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00410156 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00415039 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134668 ms - Host latency: 0.134668 ms (enqueue 0.0060791 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00444336 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00419922 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00546875 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00571289 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00563965 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00551758 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00915527 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.135767 ms - Host latency: 0.135767 ms (enqueue 0.0245117 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134692 ms - Host latency: 0.134692 ms (enqueue 0.0294434 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.151147 ms - Host latency: 0.151147 ms (enqueue 0.0937744 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.0210938 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00561523 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00559082 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00554199 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00651855 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133984 ms - Host latency: 0.133984 ms (enqueue 0.00551758 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134082 ms - Host latency: 0.134082 ms (enqueue 0.0246582 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134424 ms - Host latency: 0.134424 ms (enqueue 0.00593262 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.0057373 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00830078 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00595703 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00583496 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00708008 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00556641 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00544434 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00541992 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00546875 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00695801 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00581055 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00478516 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133716 ms - Host latency: 0.133716 ms (enqueue 0.00471191 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134546 ms - Host latency: 0.134546 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00400391 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133984 ms - Host latency: 0.133984 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00478516 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00454102 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00483398 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134619 ms - Host latency: 0.134619 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133838 ms - Host latency: 0.133838 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00375977 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00754395 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00556641 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00407715 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00446777 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00432129 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134082 ms - Host latency: 0.134082 ms (enqueue 0.00412598 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0079834 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00581055 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00424805 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00473633 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00380859 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00444336 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00410156 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00478516 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00407715 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00456543 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00471191 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00373535 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134424 ms - Host latency: 0.134424 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00385742 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.140625 ms - Host latency: 0.140625 ms (enqueue 0.00976562 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.151367 ms - Host latency: 0.151367 ms (enqueue 0.0215576 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.164355 ms - Host latency: 0.164355 ms (enqueue 0.00686035 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00793457 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.0119629 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00454102 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00407715 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00476074 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134473 ms - Host latency: 0.134473 ms (enqueue 0.00432129 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00571289 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00495605 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00400391 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134814 ms - Host latency: 0.134814 ms (enqueue 0.00715332 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00778809 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00595703 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00588379 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0059082 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134839 ms - Host latency: 0.134839 ms (enqueue 0.00695801 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134668 ms - Host latency: 0.134668 ms (enqueue 0.00617676 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00593262 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00583496 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00593262 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00849609 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00512695 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134473 ms - Host latency: 0.134473 ms (enqueue 0.00546875 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00427246 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133984 ms - Host latency: 0.133984 ms (enqueue 0.00419922 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134009 ms - Host latency: 0.134009 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00617676 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134424 ms - Host latency: 0.134424 ms (enqueue 0.00439453 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00422363 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00541992 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00539551 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134473 ms - Host latency: 0.134473 ms (enqueue 0.00439453 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00378418 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00407715 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.0103271 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133984 ms - Host latency: 0.133984 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13457 ms - Host latency: 0.13457 ms (enqueue 0.00507812 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00710449 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134399 ms - Host latency: 0.134399 ms (enqueue 0.0060791 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.136548 ms - Host latency: 0.136548 ms (enqueue 0.0217285 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00749512 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00576172 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00568848 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00649414 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.141382 ms - Host latency: 0.141382 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00415039 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134424 ms - Host latency: 0.134424 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134375 ms - Host latency: 0.134375 ms (enqueue 0.00410156 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00410156 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00500488 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00612793 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0043457 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00849609 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00571289 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00493164 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00390625 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00412598 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00407715 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.00400391 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00400391 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134204 ms - Host latency: 0.134204 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00388184 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00383301 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00981445 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134497 ms - Host latency: 0.134497 ms (enqueue 0.00480957 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134546 ms - Host latency: 0.134546 ms (enqueue 0.00524902 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00441895 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134448 ms - Host latency: 0.134448 ms (enqueue 0.00473633 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.0057373 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00407715 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134473 ms - Host latency: 0.134473 ms (enqueue 0.00410156 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00446777 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134546 ms - Host latency: 0.134546 ms (enqueue 0.00507812 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134424 ms - Host latency: 0.134424 ms (enqueue 0.00449219 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00437012 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00424805 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134473 ms - Host latency: 0.134473 ms (enqueue 0.00402832 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.0106689 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00515137 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133838 ms - Host latency: 0.133838 ms (enqueue 0.00424805 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00524902 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00427246 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00424805 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0046875 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00458984 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00424805 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00410156 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00432129 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.200781 ms - Host latency: 0.200781 ms (enqueue 0.00439453 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134497 ms - Host latency: 0.134497 ms (enqueue 0.00407715 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00415039 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.00498047 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134009 ms - Host latency: 0.134009 ms (enqueue 0.00397949 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00393066 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00507812 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.137134 ms - Host latency: 0.137134 ms (enqueue 0.00690918 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00507812 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.146582 ms - Host latency: 0.146582 ms (enqueue 0.00512695 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.00422363 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.133936 ms - Host latency: 0.133936 ms (enqueue 0.00449219 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00412598 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00415039 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.00419922 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00668945 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.138843 ms - Host latency: 0.138843 ms (enqueue 0.0234131 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134009 ms - Host latency: 0.134009 ms (enqueue 0.00439453 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134668 ms - Host latency: 0.134668 ms (enqueue 0.00458984 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.0374756 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00422363 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00524902 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13418 ms - Host latency: 0.13418 ms (enqueue 0.0050293 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00400391 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.00427246 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00405273 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00429688 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134253 ms - Host latency: 0.134253 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134106 ms - Host latency: 0.134106 ms (enqueue 0.00395508 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00949707 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134595 ms - Host latency: 0.134595 ms (enqueue 0.0162109 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134644 ms - Host latency: 0.134644 ms (enqueue 0.026416 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134351 ms - Host latency: 0.134351 ms (enqueue 0.0229492 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13396 ms - Host latency: 0.13396 ms (enqueue 0.00617676 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134058 ms - Host latency: 0.134058 ms (enqueue 0.00681152 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.0041748 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134155 ms - Host latency: 0.134155 ms (enqueue 0.00429688 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134033 ms - Host latency: 0.134033 ms (enqueue 0.00419922 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134131 ms - Host latency: 0.134131 ms (enqueue 0.00449219 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.13457 ms - Host latency: 0.13457 ms (enqueue 0.00454102 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134302 ms - Host latency: 0.134302 ms (enqueue 0.00507812 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00563965 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00561523 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00419922 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134277 ms - Host latency: 0.134277 ms (enqueue 0.00595703 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134229 ms - Host latency: 0.134229 ms (enqueue 0.00505371 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.0052002 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134326 ms - Host latency: 0.134326 ms (enqueue 0.00419922 ms)
[08/20/2024-19:31:57] [I] Average on 10 runs - GPU latency: 0.134399 ms - Host latency: 0.134399 ms (enqueue 0.00432129 ms)
[08/20/2024-19:31:57] [I] 
[08/20/2024-19:31:57] [I] === Performance summary ===
[08/20/2024-19:31:57] [I] Throughput: 7329.45 qps
[08/20/2024-19:31:57] [I] Latency: min = 0.133057 ms, max = 0.690186 ms, mean = 0.134851 ms, median = 0.134155 ms, percentile(90%) = 0.135132 ms, percentile(95%) = 0.135193 ms, percentile(99%) = 0.135254 ms
[08/20/2024-19:31:57] [I] Enqueue Time: min = 0.00256348 ms, max = 0.648438 ms, mean = 0.00444714 ms, median = 0.00357056 ms, percentile(90%) = 0.00488281 ms, percentile(95%) = 0.00634766 ms, percentile(99%) = 0.0244141 ms
[08/20/2024-19:31:57] [I] H2D Latency: min = 0 ms, max = 0 ms, mean = 0 ms, median = 0 ms, percentile(90%) = 0 ms, percentile(95%) = 0 ms, percentile(99%) = 0 ms
[08/20/2024-19:31:57] [I] GPU Compute Time: min = 0.133057 ms, max = 0.690186 ms, mean = 0.134851 ms, median = 0.134155 ms, percentile(90%) = 0.135132 ms, percentile(95%) = 0.135193 ms, percentile(99%) = 0.135254 ms
[08/20/2024-19:31:57] [I] D2H Latency: min = 0 ms, max = 0 ms, mean = 0 ms, median = 0 ms, percentile(90%) = 0 ms, percentile(95%) = 0 ms, percentile(99%) = 0 ms
[08/20/2024-19:31:57] [I] Total Host Walltime: 3.00022 s
[08/20/2024-19:31:57] [I] Total GPU Compute Time: 2.96537 s
[08/20/2024-19:31:57] [W] * GPU compute time is unstable, with coefficient of variance = 7.69863%.
[08/20/2024-19:31:57] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.
[08/20/2024-19:31:57] [I] Explanations of the performance metrics are printed in the verbose logs.
[08/20/2024-19:31:57] [V] 
[08/20/2024-19:31:57] [V] === Explanations of the performance metrics ===
[08/20/2024-19:31:57] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.
[08/20/2024-19:31:57] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.
[08/20/2024-19:31:57] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.
[08/20/2024-19:31:57] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.
[08/20/2024-19:31:57] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.
[08/20/2024-19:31:57] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.
[08/20/2024-19:31:57] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.
[08/20/2024-19:31:57] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.
[08/20/2024-19:31:57] [I] 
[08/20/2024-19:31:57] [I] Output Tensors:
[08/20/2024-19:31:57] [I] 528: (1x1000)
[08/20/2024-19:31:57] [I] 0.0019237 0.000413769 0.000548887 0.000597743 0.000392718 0.000554284 0.00381213 0.000901843 0.00100295 0.000798673 0.00160085 0.000362161 0.00026449 0.00130833 0.000140028 0.00326419 0.0013843 0.000438529 0.000852577 0.000321161 0.000264344 0.000684801 0.000123629 0.00239677 0.000606981 0.00113501 0.00133108 0.000522787 0.000314302 0.00039772 0.00120264 0.00131812 0.000896652 0.000711448 0.000458081 0.000476192 0.000910926 0.00102524 0.000369548 0.000387178 0.000978883 0.000423103 0.000747931 0.000212993 0.000321491 0.00020156 0.000425827 0.000675183 0.00101004 0.00242338 0.00242943 0.00220516 0.00100052 0.00104771 0.000469212 0.000930125 0.00151439 0.00222065 0.000196648 0.000377637 0.000682433 0.00110757 0.000792375 0.00042447 0.00106893 0.000730862 0.000236773 0.000931143 0.00123586 0.000919566 0.000710998 0.000471824 0.000455746 0.00173355 0.000989249 0.000734116 0.000165573 0.000923406 0.000760423 0.0018881 0.000937967 0.00031783 0.000251252 0.000496131 0.00119467 0.000371943 0.00164118 0.000526116 0.00424864 0.00115478 0.00136282 0.000710891 0.000598784 0.0036984 0.00161975 0.000905327 0.00205026 0.00071506 0.000853095 0.00275074 0.000128048 0.000355104 0.000447477 0.000572694 0.000753709 0.00116029 0.00092346 0.000739897 0.000363449 0.000446263 0.000614353 0.000918019 0.000342213 0.000762615 0.0016164 0.000946508 0.00133954 0.000585909 0.000715201 0.000677669 0.000654255 0.000901797 0.00138124 0.000525912 0.00183774 0.000727852 0.00122859 0.000311235 0.000541552 0.00209172 0.000732611 0.000533613 0.00110227 0.00248283 0.000557675 0.000833132 0.000478898 0.000810271 0.000628876 0.000829737 0.000326638 0.00308104 0.000822529 0.00140302 0.00135247 0.000708921 0.0008507 0.00162421 0.000826251 0.000675349 0.000829342 0.000393047 0.00315718 0.00193734 0.00033202 0.000372472 0.00113903 0.000358276 0.000434338 0.00357919 0.00155833 0.00154249 0.00101075 0.00103013 0.000601996 0.000520377 0.000223084 0.000373113 0.00045814 0.000480844 0.00092756 0.000662397 0.00222966 0.000824829 0.00145796 0.00218323 0.000417299 0.000441347 0.00102104 0.000289303 0.00233527 0.00137527 0.000433365 0.000850401 0.00141003 0.00106514 0.000919466 0.00371325 0.00184993 0.000808971 0.0015684 0.000298274 0.000822069 0.000536748 0.00102305 0.000941655 0.000197864 0.000312561 0.00147227 0.000820716 0.00159048 0.00108206 0.0012721 0.000874641 0.000829896 0.00122379 0.000577196 0.000433776 0.000535763 0.00116753 0.00033 0.000785174 0.00114135 0.000902549 0.000319741 0.00302653 0.00113819 0.000639878 0.000447364 0.000381156 0.000457137 0.000936354 0.000505284 0.000627045 0.000909001 0.00241073 0.000450605 0.000778747 0.000313603 0.000282291 0.000296907 0.00130925 0.000549238 0.000438902 0.00130906 0.000412597 0.000879487 0.00234258 0.001532 0.00133872 0.00116727 0.000509922 0.000107953 0.000648491 0.000534446 0.00636581 0.000724016 0.00015229 0.00102759 0.000937705 0.00221616 0.00142843 0.000650613 0.000368554 0.000983469 0.00095987 0.000436914 0.00167952 0.00052021 0.00168528 0.000717128 0.000539856 0.000716003 0.000773349 0.00332072 0.00184133 0.000466737 0.000719617 0.00120282 0.00108332 0.000807101 0.000245894 0.000911996 0.000544259 0.00075219 0.00227346 0.00120572 0.000923588 0.00130415 0.00137295 0.00159737 0.00129561 0.000385816 0.000413606 0.000582604 0.0016058 0.000542332 0.000269925 0.000326314 0.00278675 0.000518646 0.00054911 0.00183582 0.000694641 0.000445124 0.000424398 0.000517806 0.000650392 0.000833108 0.00202584 0.000686467 0.000193098 0.0008874 0.00173781 0.000621026 0.000426228 0.00046797 0.000514363 0.00118797 0.000357455 0.00117237 0.000253002 0.00174389 0.000423213 0.00140254 0.00031844 0.000358742 0.000215416 0.00149199 0.000929596 0.00171424 0.00110262 0.000676708 0.000688366 0.000289707 0.000643014 0.000176476 0.000682179 0.000264772 0.000545914 0.00295999 0.000332234 0.00039369 0.000118544 0.000810384 0.00115102 0.000375677 0.00124926 0.000714372 0.00143056 0.00128366 0.0011838 0.000804467 0.000699765 0.000513998 0.000413615 0.000227961 0.000569751 0.00132595 0.000515813 0.00078374 0.00191399 0.000485377 0.000817067 0.0015022 0.000510435 0.000975538 0.000632193 0.000851157 0.00191045 0.000456589 0.000400277 0.000606064 0.000744083 0.00204944 0.000861344 0.00124278 0.000754055 0.000736876 0.00245814 0.00161217 0.00322843 0.000219167 0.000192783 0.000447105 0.0011153 0.00185801 0.000997867 0.000617396 0.000895898 0.00169581 0.00107746 0.000782376 0.000732993 0.000630866 0.000272983 0.000310549 0.00192876 0.00054192 0.00275001 0.00421708 0.00102031 0.000416916 0.000505202 0.000861232 0.000660198 0.000643673 0.00013033 0.000532173 0.000701645 0.00181174 0.00109223 0.000622335 0.000206413 0.00274628 0.00065429 0.000865123 0.000610302 0.00032376 0.00320473 0.000597869 0.000241443 0.000708077 0.00191004 0.00089644 0.000322683 0.000997326 0.000610708 0.00086187 0.00102375 0.00148266 0.000333949 0.000843951 0.00253857 0.000518714 0.00138292 0.000630554 0.000817643 0.00061784 0.000587635 0.00136164 0.000155226 0.000703974 0.00223437 0.000403077 0.000890183 0.000575784 0.000931298 0.000430972 0.000912045 0.000317672 0.000834835 0.000245551 0.000632276 0.00140458 0.000602388 0.00198179 0.00131833 0.000697481 0.00293583 0.000351947 0.000280684 0.000222334 0.00100595 0.000436124 0.00126523 0.00130998 0.000554243 0.00069094 0.000625109 0.000713518 0.000921613 0.00109479 0.000524127 0.00121276 0.000776856 0.00144049 0.000551806 0.000618523 0.000447445 0.00131029 0.000458337 0.000585985 0.000254636 0.000411183 0.00123611 0.000778438 0.000601583 0.000947741 0.000656022 0.00169727 0.000116284 0.000878253 0.000831164 0.00115782 0.00100189 0.00122874 0.000557419 0.000680594 0.000583296 0.000559201 0.000489145 0.000731639 0.000643256 0.00118705 0.00166043 0.00113638 0.000567797 0.002458 0.00270124 0.00188938 0.00138778 0.0011221 0.00121756 0.000386947 0.000236872 0.00122204 0.000788033 0.000582973 0.000675876 0.000381066 0.000874849 0.000887523 0.000862355 0.000461052 0.00108305 0.000705018 0.00157819 0.00122449 0.00131112 0.00170494 0.0030254 0.00161628 0.00163392 0.000445665 0.00204304 0.00250929 0.00154309 0.00205439 0.000830422 0.000956922 0.00164762 0.00167099 0.000343321 0.000259787 0.000460908 0.00188449 0.000301571 0.002394 0.000388718 0.000881133 0.000797551 0.000608054 0.00135014 0.000258881 0.00222691 0.00109463 0.00039101 0.00108318 0.00253386 0.000609406 0.00226153 0.000278641 0.000798714 0.000910325 0.000611019 0.000762937 0.000798816 0.000287323 0.000839915 0.000177896 0.0011408 0.000966744 0.000419393 0.000615027 0.000601873 0.000710573 0.000768239 0.00171904 0.000691947 0.000726094 0.000359386 0.00120816 0.000532677 0.000757954 0.000263573 0.000776423 0.000555146 0.00332911 0.000381751 0.000457788 0.00121466 0.000781516 0.000868065 0.00172851 0.000913177 0.000779334 0.000554451 0.000495168 0.000784805 0.000830454 0.00174457 0.000381816 0.000653845 0.00142157 0.000572063 0.00123818 0.000345862 0.00185147 0.00162258 0.00135727 0.00340069 0.000270344 0.0034948 0.00132145 0.00120185 0.00141012 0.00265109 0.000794605 0.000481354 0.0020778 0.000481137 0.00188395 0.00102401 0.000994605 0.00120358 0.00191518 0.00090051 0.000716856 0.000581422 0.00154512 0.000742782 0.000759583 0.000354514 0.000697829 0.00109218 0.000490279 0.000734463 0.00159125 0.00028518 0.000442339 0.00156631 0.00175969 0.0010578 0.00168074 0.000411331 0.000146463 0.000325628 0.00111963 0.00116671 0.00116757 0.00179236 0.00152767 0.000397396 0.000486252 0.00162227 0.000681984 0.000630265 0.00231361 0.000846738 0.00188674 0.000227231 0.000675004 0.000828679 0.000573215 0.000697705 0.000866558 0.000501128 0.0018169 0.00110575 0.000724564 0.000872432 0.000662981 0.00291796 0.000860267 0.00101173 0.000511837 0.00195089 0.000386425 0.000475506 0.00052262 0.00160751 0.000831146 0.00156612 0.000702234 0.001166 0.000968001 0.000579277 0.000565413 0.000610594 0.000368072 0.00061509 0.00089963 0.00055063 0.00139966 0.000296628 0.00106972 0.00190778 0.00235449 0.000592168 0.000348625 0.00157119 0.00104445 0.00116578 0.000229702 0.00229803 0.00114412 0.00126944 0.000379232 0.000457645 0.000587395 0.00248143 0.000566323 0.000679341 0.000475195 0.000500589 0.000936054 0.0024407 0.000924508 0.00140534 0.000702634 0.00265673 0.000414064 0.0005359 0.000534815 0.000395673 0.000349477 0.00113799 0.000912502 0.000564086 0.000756157 0.00104383 0.000474943 0.000915158 0.00172476 0.000432855 0.00135109 0.00346142 0.000511559 0.00104389 0.000261649 0.00216618 0.000794739 0.0010431 0.00107715 0.000689538 0.00250973 0.000939082 0.00106247 0.00082537 0.00170324 0.000741244 0.001149 0.000367956 0.00106084 0.00116657 0.000694096 0.000438076 0.00113779 0.000352135 0.000355425 0.00211691 0.000273915 0.000324725 0.00113939 0.00214953 0.00130399 0.000769436 0.00136306 0.00260058 0.000403064 0.000926301 0.000144207 0.00151205 0.00145484 0.000222724 0.00174635 0.00169033 0.000459546 0.000495901 0.000590408 0.000968721 0.000976196 0.00209117 0.00254395 0.00123198 0.000608245 0.000477099 0.000554343 0.000502587 0.000968752 0.00115372 0.000550443 0.000427052 0.000461174 0.000446026 0.00158363 0.000437528 0.00193947 0.000611476 0.00126416 0.00197791 0.00182713 0.000429339 0.00029467 0.00155503 0.000375116 0.000528926 0.000149702 0.00031983 0.00111136 0.000445868 0.00110769 0.0005847 0.000702495 0.00057414 0.000431164 0.00114466 0.00108462 0.000641403 0.002201 0.00112746 0.00151011 0.00052442 0.00244172 0.000649755 0.000415462 0.000304155 0.000497405 0.000397594 0.000394983 0.00105991 0.000603377 0.000686145 0.00138739 0.000501682 0.00162309 0.00129819 0.000464457 0.000936827 0.00083726 0.000685598 0.00178463 0.0039849 0.000658089 0.00269087 0.000378261 0.000459728 0.000480225 0.000306124 0.000722494 0.00132554 0.000722678 0.00164949 0.000749939 0.000647631 0.00102616 0.00054471 0.000841719 0.000796135 0.000353101 0.00272496 0.00215391 0.000490537 0.00113447 0.00131565 0.000650182 0.000449297 0.00173569 0.00172444 0.000768083 0.0013851 0.00157224 0.00158348 0.000490785 0.000489978 0.00154503 0.000599876 0.00053845 0.000459374 0.000620513 0.00114512 0.000103115 0.000449635 0.000591825 0.00353804 0.000556183 0.0018467 0.00154592 0.00107765 0.000614551 0.000779509 0.000994589 0.00458321 0.000531861 0.000639492 0.000519377 0.000679879 0.000344647 0.000384262 0.000256274 0.00030974 0.000259935 0.000706311 0.000918228 0.00130872 0.00138738 0.00016022 0.000296147 0.00345524 0.000295202 0.000885195 0.00079945 0.00183548 0.0010542 0.00171278 0.00221358 0.00132816 0.00142468 0.00122035 0.000688011 0.00065039 0.00118627 0.00107118 0.000489291 0.00341301 0.000606478 0.00163334 0.000388897 0.000937617 0.000799013 0.000532329 0.00107228 0.00097133 0.000641617 0.000693015 0.000572605 0.00161499 0.000185747 0.00352224 0.00145064 0.00151244 0.00347525 0.00232783 0.00128726 0.00152883 0.000589265 0.000866272 0.00149655 0.000655793 0.00280278 0.00096961 0.000333273 0.000437956 0.000472767 0.000398462 0.000785215 0.000714005 0.00217461 0.000293472 0.000343196 0.0004207 0.001064 0.000938606 0.000464196 0.000374856 0.000504657 0.00151539 0.000432225 0.00357344 0.00214698 0.00152837 0.001503 0.000970274 0.000547611 0.00107945 0.000631574 0.00208528 0.000581345 0.000903015 0.00026213 0.000907663 0.000673643 0.00186955 0.00188166 0.000261382 0.000749878 0.000662988 0.000814777 0.00103441 0.000286602 0.00224286 0.000522457 0.00422452 0.000444412 0.000318246 0.00136488 0.000974095 0.000467932 0.000575058 0.00185231 0.000890026 0.000536387 0.000568795 0.000628581 0.000276987 0.000491478 0.000172355 0.000670063 0.000659296
[08/20/2024-19:31:57] [W] [TRT] Skip layer timing collection in CUDA graph capture mode.
[08/20/2024-19:31:57] [W] Failed to collect layer timing info from previous enqueueV3()
[08/20/2024-19:32:01] [I] 
[08/20/2024-19:32:01] [I] === Profile (7477 iterations ) ===
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                                                                                                    Layer   Time (ms)   Avg. Time (ms)   Median Time (ms)   Time %
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                                                                                         QuantizeLinear_2       85.71           0.0115             0.0079      3.2
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                                                    conv1.weight + QuantizeLinear_7 + Conv_9 + MaxPool_12      128.46           0.0172             0.0143      4.8
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                                                      layer1.0.conv1.weight + QuantizeLinear_20 + Conv_22       85.41           0.0114             0.0095      3.2
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                                   layer1.0.conv2.weight + QuantizeLinear_32 + Conv_34 + Add_42 + Relu_43      109.77           0.0147             0.0121      4.1
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                                                      layer1.1.conv1.weight + QuantizeLinear_51 + Conv_53      165.08           0.0221             0.0120      6.1
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                                   layer1.1.conv2.weight + QuantizeLinear_63 + Conv_65 + Add_73 + Relu_74      123.75           0.0166             0.0113      4.6
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                                                      layer2.0.conv1.weight + QuantizeLinear_82 + Conv_84       97.11           0.0130             0.0068      3.6
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                                             layer2.0.downsample.0.weight + QuantizeLinear_105 + Conv_107      100.35           0.0134             0.0061      3.7
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                                 layer2.0.conv2.weight + QuantizeLinear_94 + Conv_96 + Add_115 + Relu_116      107.73           0.0144             0.0082      4.0
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                                                    layer2.1.conv1.weight + QuantizeLinear_124 + Conv_126      105.49           0.0141             0.0080      3.9
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                               layer2.1.conv2.weight + QuantizeLinear_136 + Conv_138 + Add_146 + Relu_147      123.76           0.0166             0.0082      4.6
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                                                    layer3.0.conv1.weight + QuantizeLinear_155 + Conv_157      101.23           0.0135             0.0072      3.8
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                                             layer3.0.downsample.0.weight + QuantizeLinear_178 + Conv_180       88.99           0.0119             0.0059      3.3
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                               layer3.0.conv2.weight + QuantizeLinear_167 + Conv_169 + Add_188 + Relu_189      118.69           0.0159             0.0102      4.4
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                                                    layer3.1.conv1.weight + QuantizeLinear_197 + Conv_199      117.12           0.0157             0.0092      4.4
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                               layer3.1.conv2.weight + QuantizeLinear_209 + Conv_211 + Add_219 + Relu_220      124.21           0.0166             0.0102      4.6
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                                                    layer4.0.conv1.weight + QuantizeLinear_228 + Conv_230      118.71           0.0159             0.0082      4.4
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                                             layer4.0.downsample.0.weight + QuantizeLinear_251 + Conv_253       85.78           0.0115             0.0051      3.2
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                               layer4.0.conv2.weight + QuantizeLinear_240 + Conv_242 + Add_261 + Relu_262      134.72           0.0180             0.0123      5.0
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                                                    layer4.1.conv1.weight + QuantizeLinear_270 + Conv_272      127.75           0.0171             0.0113      4.7
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                               layer4.1.conv2.weight + QuantizeLinear_282 + Conv_284 + Add_292 + Relu_293      133.61           0.0179             0.0115      5.0
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                                                                                    GlobalAveragePool_300      100.07           0.0134             0.0045      3.7
[08/20/2024-19:32:01] [I]                                              fc.weight + QuantizeLinear_309 + transpose_before_Gemm_311 + Gemm_311 + fc.bias + (Unnamed Layer* 355) [Shuffle] + unsqueeze_node_after_fc.bias + (Unnamed Layer* 355) [Shuffle]_(Unnamed Layer* 355) [Shuffle]_output + (Unnamed Layer* 356) [ElementWise]       97.60           0.0131             0.0051      3.6
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                                                                                              Softmax_312      108.58           0.0145             0.0051      4.0
[08/20/2024-19:32:01] [I]                                                                                                                                                                                                                                                                                                    Total     2689.67           0.3597             0.3074    100.0
[08/20/2024-19:32:01] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8510] # trtexec --onnx=.//qat_resnet18_quant_after_calib.onnx --verbose --best --dumpProfile --separateProfileRun --saveEngine=qat_resnet18_quant_after_calib_x86_best.plan --dumpOutput --exportOutput=qat_resnet18_quant_after_calib.json --dumpLayerInfo --exportProfile=qat_resnet18_quant_after_calib_layinfo.json --noDataTransfers --useCudaGraph --useSpinWait --profilingVerbosity=detailed
